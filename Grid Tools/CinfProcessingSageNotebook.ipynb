{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import itertools as itools\n",
    "import networkx as nx\n",
    "import csv\n",
    "# import ast\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "#from sage.graphs.graph_decompositions.graph_products import is_cartesian_product\n",
    "import CodeModules.GFKTools as gfk\n",
    "from CodeModules.GridPermutations import *\n",
    "import time\n",
    "import pickle\n",
    "import CodeModules.perm as pr\n",
    "\n",
    "\n",
    "TIMERS = True\n",
    "PROCESSOR_COUNT = 12\n",
    "OUTPUTDIRECTORY = 'Outputs/'\n",
    "PRINT_PROGRESS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyManager(mp.managers.BaseManager):\n",
    "    \n",
    "    pass\n",
    "\n",
    "class grid_complex:\n",
    "    \n",
    "    #This is the data type that holds all the information and most of the functions and methods necessary\n",
    "    #to produce and manipulate the graded complex.\n",
    "    \n",
    "    def __init__(self, directed_graph, rng, sigx = None, sigo = None):\n",
    "    \n",
    "    #Initializing and setting default values. sigx and sigo should generally be provided - fail safes are included\n",
    "    #however if they're ever used then only the relative grading of the final object will be correct\n",
    "    \n",
    "        if type(directed_graph) != nx.DiGraph:\n",
    "            raise(\"!This data type only supports networkx digraphs!\")\n",
    "        \n",
    "        self.comp = directed_graph\n",
    "        self.ring = rng\n",
    "        self.min_gradings = {}\n",
    "        self.max_gradings = {}\n",
    "        self.max_grading_changes = {}\n",
    "        self.sigx = sigx\n",
    "        self.sigo = sigo\n",
    "        self.set_to_minus = False\n",
    "        \n",
    "        #From here the values necessary for the surgered manifold gradings are mapped out\n",
    "        \n",
    "        if (sigx != None) and (sigo != None):\n",
    "            self.size = len(sigx)\n",
    "            self.components = link_components(sigx, sigo)\n",
    "            for i in range(len(self.components)):\n",
    "\n",
    "                key = f'AGrading{i}'\n",
    "                self.min_gradings[key] = 0\n",
    "                self.max_gradings[key] = 0\n",
    "                self.max_grading_changes[key] = 0\n",
    "                key = f'UGrading{i}'\n",
    "                self.min_gradings[key] = 0\n",
    "                self.max_gradings[key] = 0\n",
    "                self.max_grading_changes[key] = 0\n",
    "                key = f'VGrading{i}'\n",
    "                self.min_gradings[key] = 0\n",
    "                self.max_gradings[key] = 0\n",
    "                self.max_grading_changes[key] = 0\n",
    "        else:\n",
    "            \n",
    "        #This is included in case the methods in the class are useful to another complex being loaded in\n",
    "        \n",
    "            self.components = None\n",
    "        \n",
    "        \n",
    "    def __repr__(self):\n",
    "        #If the object is called it will return the underlying digraph\n",
    "        return self.comp\n",
    "    \n",
    "    def subcomplex(self, subgraph):\n",
    "        #This is essentially just the subgraph - may not be an actual subcomplex if poor choice of vertices/edges are made\n",
    "        sub_copy = subgraph.copy()\n",
    "        result = grid_complex(sub_copy, self.ring)\n",
    "        \n",
    "    \n",
    "    def copy(self):\n",
    "        if self.sigx == None:\n",
    "            new_copy = grid_complex(self.comp.copy(), self.ring)\n",
    "        else:\n",
    "            new_copy = grid_complex(self.comp.copy(), self.ring, self.sigx.copy(), self.sigo.copy())\n",
    "        return new_copy\n",
    "    \n",
    "    def grid(self):        \n",
    "        #Adding functionality to return the original grid that produced the complex\n",
    "        return [self.sigx, self.sigo]\n",
    "\n",
    "    \n",
    "    def graph(self):\n",
    "        return self.comp\n",
    "    \n",
    "    def ring(self):\n",
    "        return self.ring\n",
    "    \n",
    "    \n",
    "    \n",
    "    def to_hat(self):\n",
    "\n",
    "        print(\"setting Ui's and Vi's = 0\")\n",
    "        gens = self.ring.gens()\n",
    "        size = len(gens)/2    \n",
    "        for edge in self.comp.edges():\n",
    "\n",
    "            for i in range(2*size):\n",
    "\n",
    "                src = edge[0]\n",
    "                tar = edge[1]\n",
    "                self.comp[src][tar]['diffweight'] = self.comp[src][tar]['diffweight'].subs({gens[i]:0})\n",
    "\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def to_minus(self):\n",
    "    #Substitutes U0 for all the Ui and 1 for Vi\n",
    "        self.set_to_minus = True\n",
    "        print(\"normalizing Ui's and setting Vi = 1\")\n",
    "        gens = self.ring.gens()\n",
    "        size = len(gens)/2    \n",
    "        for edge in self.comp.edges():\n",
    "\n",
    "            for component in self.components:\n",
    "                for i in component:\n",
    "\n",
    "#                     if i == component[0]: continue\n",
    "                    setting_var = component[0] - 1\n",
    "                    src = edge[0]\n",
    "                    tar = edge[1]\n",
    "                    self.comp[src][tar]['diffweight'] = self.comp[src][tar]['diffweight'].subs({gens[i-1]:gens[setting_var]})\n",
    "                    self.comp[src][tar]['diffweight'] = self.comp[src][tar]['diffweight'].subs({gens[i+size-1]:1})\n",
    "\n",
    "        self.remove_zeros()\n",
    "        return\n",
    "\n",
    "    def link_normalize(self):\n",
    "    #Substitutes Ucomp for all the Ui associated to that component\n",
    "\n",
    "        gens = self.ring.gens()\n",
    "        size = len(gens)/2    \n",
    "        for edge in self.comp.edges():\n",
    "\n",
    "            for component in self.components:\n",
    "                for i in component:\n",
    "\n",
    "                    if i == component[0]: continue\n",
    "                    setting_var = component[0] - 1\n",
    "                    src = edge[0]\n",
    "                    tar = edge[1]\n",
    "                    self.comp[src][tar]['diffweight'] = self.comp[src][tar]['diffweight'].subs({gens[i-1]:gens[setting_var]})\n",
    "                    self.comp[src][tar]['diffweight'] = self.comp[src][tar]['diffweight'].subs({gens[i+size-1]:gens[size+setting_var]})\n",
    "\n",
    "        self.remove_zeros()\n",
    "        return\n",
    "\n",
    "    \n",
    "#     def normalize(self):\n",
    "#     #Substitutes U0 for all the Ui and V0 for all Vi\n",
    "\n",
    "#         gens = self.field.gens()\n",
    "#         size = len(gens)/2    \n",
    "#         for edge in self.comp.edges():\n",
    "\n",
    "#             for i in range(size):\n",
    "\n",
    "#                 src = edge[0]\n",
    "#                 tar = edge[1]\n",
    "#                 self.comp[src][tar]['diffweight'] = self.comp[src][tar]['diffweight'].subs({gens[i]:gens[0]})\n",
    "#                 self.comp[src][tar]['diffweight'] = self.comp[src][tar]['diffweight'].subs({gens[i+size]:gens[size]})\n",
    "\n",
    "#         self.remove_zeros()\n",
    "#         return\n",
    "\n",
    "    def remove_zeros(self):\n",
    "\n",
    "        elist = list(self.comp.edges())\n",
    "        for x,y in elist:\n",
    "\n",
    "            if self.comp[x][y]['diffweight'] == 0:\n",
    "\n",
    "                self.comp.remove_edge(x,y)\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "    def split_by_grading(self, partition_list, key):\n",
    "    #partition list is supposed to be of the form matching the partition function's output\n",
    "        result = []\n",
    "        \n",
    "        for data in partition_list:\n",
    "            gens = [vert for vert in self.comp.nodes() if ((self.comp.nodes()[vert][key] >= data[0]) and (self.comp.nodes()[vert][key] <= data[4])) ]\n",
    "            subg = self.comp.subgraph(gens)\n",
    "            result.append(subg)\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    \n",
    "    def graph_red_search(self, started = False, timerstart = None): \n",
    "    #searches through a cfk inf complex for reducible edges and calling\n",
    "    #the reduction function to eliminate the pair according to the reduction algorithm\n",
    "    #     dict_graph = nx.to_dict_of_dicts(given_graph)\n",
    "        \n",
    "        if not started:\n",
    "            timerstart = time.time()    \n",
    "            print(\"Reducing complex...\")\n",
    "        \n",
    "        print(len([source for source, target, weight in self.comp.edges(data = 'diffweight') if weight == 1]))\n",
    "        while True:\n",
    "#             count = (count + 1)%\n",
    "            try:\n",
    "                red_target = next((source, target) for source, target, weight in self.comp.edges(data = 'diffweight') if weight == 1)\n",
    "#                 print(self.comp.edges[red_target])\n",
    "                self.graph_reduction(red_target[0], red_target[1])\n",
    "                continue\n",
    "            except:\n",
    "                (\"StopIteration\")\n",
    "            break\n",
    "                \n",
    "#         for key in self.comp:\n",
    "\n",
    "#             for target in self.comp[key]:\n",
    "\n",
    "#                 if self.comp[key][target]['diffweight'] == 1:\n",
    "#                     self.graph_reduction(key, target)\n",
    "#                     return self.graph_red_search(True, timerstart)\n",
    "\n",
    "        timerstop = time.time()\n",
    "        print('Time to reduce complex: ' + str(timerstop - timerstart))\n",
    "\n",
    "        return\n",
    "\n",
    "    def graph_reduction(self, key, target):\n",
    "    #Deletes edge specified from graph_red_search and adds in edges according to the\n",
    "    #reduction algorithm\n",
    "        for x in self.comp.predecessors(target):\n",
    "\n",
    "            if x == key: continue\n",
    "            for y in self.comp.successors(key):\n",
    "\n",
    "                if y == target: continue\n",
    "                x_weight = self.comp[x][target]['diffweight']\n",
    "                y_weight = self.comp[key][y]['diffweight']\n",
    "                red_weight = x_weight * y_weight\n",
    "                if self.comp.has_edge(x,y):\n",
    "                    old_weight = self.comp[x][y]['diffweight']\n",
    "                    red_weight = red_weight + old_weight\n",
    "                self.comp.add_edge(x,y,diffweight=red_weight)\n",
    "\n",
    "        self.comp.remove_node(key)\n",
    "        self.comp.remove_node(target)\n",
    "        return\n",
    "\n",
    "    def grade_link_complex(self):\n",
    "\n",
    "        #Input: given_graph a networkx directed graph with 'diffweight' attribute on edges\n",
    "        #       given_field the laurent polynomial field associated to the grid graph\n",
    "        #       gridX a list representing the vertex to be graded 0 in U V and Alexander gradings\n",
    "        #\n",
    "        #Output: given_graph with new attributes on the vertices for U V and Alexander gradings\n",
    "        #        also an attribute HasBeenGraded as an artifact\n",
    "\n",
    "\n",
    "        #If the positions of the Xs aren't provided we'll initialize around whatever\n",
    "        #state happens to appear first in the digraph structure - This will mean the complex's absolute grading will be off\n",
    "        if self.sigx == None:\n",
    "\n",
    "            gridX = list(self.comp.nodes())[0]\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            gridX = self.sigx\n",
    "\n",
    "        if self.sigo == None:\n",
    "\n",
    "            gridO = list(self.comp.nodes())[0]\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            gridO = self.sigo\n",
    "            \n",
    "        gens = self.ring.gens()\n",
    "        size = len(gens)/2 \n",
    "\n",
    "        print(\"grading complex...\")\n",
    "\n",
    "        comp_set = len(self.components)\n",
    "\n",
    "        #Adding an attribute to all nodes to keep track of if they've been assigned gradings\n",
    "        for i in range(comp_set):\n",
    "            nx.set_node_attributes(self.comp, False, f\"HasBeenGraded{i}\")\n",
    "\n",
    "        #The gradings are relative so we're declaring one to be in U, V, and Alexander grading 0\n",
    "        #this block initializes those balues\n",
    "        for i in range(comp_set):\n",
    "#             self.comp.nodes()[str(gridX)][f'HasBeenGraded{i}'] = True\n",
    "            self.comp.nodes()[str(gridX)][f'AGrading{i}'] = 0\n",
    "#             self.comp.nodes()[str(gridX)][f'UGrading{i}'] = 0\n",
    "#             self.comp.nodes()[str(gridX)][f'VGrading{i}'] = 0\n",
    "\n",
    "        if TIMERS: timerstart = time.time()\n",
    "\n",
    "        #Built in function to find a spanning tree\n",
    "        #span = nx.algorithms.tree.branchings.greedy_branching(given_graph)\n",
    "\n",
    "        tree = nx.algorithms.minimum_spanning_tree( self.comp.to_undirected()  )\n",
    "        eds = set(tree.edges())  # optimization\n",
    "        spanset = []\n",
    "\n",
    "        for edge in eds:\n",
    "\n",
    "            if edge in self.comp.edges():\n",
    "                spanset.append(edge)\n",
    "\n",
    "            else:\n",
    "                spanset.append((edge[1],edge[0]))\n",
    "\n",
    "        span = self.comp.edge_subgraph(spanset)\n",
    "\n",
    "        if TIMERS:\n",
    "\n",
    "            timerstop = time.time()\n",
    "            print(\"Time to find arborescence:\" + str(timerstop - timerstart))\n",
    "\n",
    "        #Bit of baseball terminology for the following nested loops, the active data is essentially at bat, the list we're working\n",
    "        #through is called on_deck, and then we're building up the follow up as in_the_hole which will turn into\n",
    "        #on deck on the following loop\n",
    "        #\n",
    "        #On deck holds the edges to be iterated through\n",
    "        on_deck = [str(gridX)]\n",
    "\n",
    "        #In the hole holds the ones to be iterated through once on_deck is cleared\n",
    "        in_the_hole = []\n",
    "\n",
    "        if TIMERS: timerstart = time.time()\n",
    "\n",
    "            \n",
    "        comp_count = len(self.components)\n",
    "            \n",
    "        #Grading Loops Start:\n",
    "        ####################\n",
    "        \n",
    "        self.componentwise_relative_grading_loop(\"UGrading\", gridX, self.virtual_U_gradings_succ, self.virtual_U_gradings_pred, span, comp_count)\n",
    "        self.componentwise_relative_grading_loop(\"VGrading\", gridX, self.virtual_V_gradings_succ, self.virtual_V_gradings_pred, span, comp_count)\n",
    "        self.relative_grading_loop(\"UGrading\", gridX, self.maslov_U_succ, self.maslov_U_pred, span, comp_count)\n",
    "        self.relative_grading_loop(\"VGrading\", gridX, self.maslov_V_succ, self.maslov_V_pred, span, comp_count)\n",
    "        \n",
    "        ####################\n",
    "        #Grading Loops End\n",
    "\n",
    "        for vert in self.comp.nodes():\n",
    "            self.comp.nodes()[vert]['AGrading'] = 0          \n",
    "            for i in range(len(self.components)):\n",
    "                stab_count = len(self.components[i])\n",
    "                self.comp.nodes()[vert][f'AGrading{i}'] = (1/2)*(self.comp.nodes()[vert][f'VGrading{i}']-self.comp.nodes()[vert][f'UGrading{i}'])-(1/2)*(stab_count - 1)\n",
    "                self.comp.nodes()[vert]['AGrading'] += self.comp.nodes()[vert][f'AGrading{i}']\n",
    "        if TIMERS:\n",
    "\n",
    "            timerstop = time.time()\n",
    "            print('Time to grade complex (given arborescence): ' + str(timerstop - timerstart))\n",
    "\n",
    "        return\n",
    "\n",
    "    def gml_export(self, filename = 'PleaseNameMe.gml'):\n",
    "\n",
    "#         if component_length == -1:\n",
    "#             return(\"!!! Unknown number of components for export !!!\")\n",
    "\n",
    "        component_length = len(self.components)\n",
    "        \n",
    "        if component_length == 0:\n",
    "            raise(\"Error finding number of components\")\n",
    "        \n",
    "        nxG = self.comp.copy()\n",
    "\n",
    "        if filename == 'PleaseNameMe.gml':\n",
    "            print(\"You didn't name your output! It's been named PleaseNameMe.gml\")\n",
    "\n",
    "        if filename[-4:] != \".gml\":\n",
    "            filename += \".gml\"\n",
    "\n",
    "        for x,y in nxG.edges():\n",
    "\n",
    "            nxG[x][y]['diffweight'] = str(nxG[x][y]['diffweight'])\n",
    "\n",
    "        for node in nxG.nodes():\n",
    "\n",
    "            #print(str((nxG.nodes()[node]['UGrading'],nxG.nodes()[node]['VGrading'],nxG.nodes()[node]['AGrading'])))\n",
    "            try:\n",
    "                nxG.nodes[node]['UGrading'] = int(nxG.nodes[node]['UGrading'])\n",
    "                nxG.nodes[node]['VGrading'] = int(nxG.nodes[node]['VGrading'])\n",
    "                nxG.nodes[node]['AGrading'] = int(nxG.nodes[node]['AGrading'])\n",
    "            except:\n",
    "                nxG.nodes[node]['UGrading'] = int(-99)\n",
    "                nxG.nodes[node]['VGrading'] = int(-99)\n",
    "                nxG.nodes[node]['AGrading'] = int(-99)\n",
    "            for i in range(component_length):\n",
    "                try:\n",
    "                    nxG.nodes[node][f'AGrading{i}'] = int(nxG.nodes[node][f'AGrading{i}']) \n",
    "                    nxG.nodes[node][f'UGrading{i}'] = int(nxG.nodes[node][f'UGrading{i}'])\n",
    "                    nxG.nodes[node][f'VGrading{i}'] = int(nxG.nodes[node][f'VGrading{i}'])\n",
    "                except:\n",
    "                    nxG.nodes[node][f'AGrading{i}'] = int(-99)\n",
    "                    nxG.nodes[node][f'UGrading{i}'] = int(-99)\n",
    "                    nxG.nodes[node][f'VGrading{i}'] = int(-99)\n",
    "\n",
    "        print(\"writing to \" + OUTPUTDIRECTORY + str(filename))\n",
    "        nx.write_gml(nxG, OUTPUTDIRECTORY + filename)\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "    \n",
    "    def find_grading_ranges(self, key = \"AGrading\"):\n",
    "\n",
    "        self.min_gradings[key] = 0\n",
    "        self.max_gradings[key] = 0\n",
    "        \n",
    "        for vert in self.comp.nodes():\n",
    "\n",
    "            if self.comp.nodes[vert][key] < self.min_gradings[key]:\n",
    "\n",
    "                self.min_gradings[key] = self.comp.nodes[vert][key]\n",
    "\n",
    "            if self.comp.nodes[vert][key] > self.max_gradings[key]:\n",
    "\n",
    "                self.max_gradings[key] = self.comp.nodes[vert][key]\n",
    "\n",
    "        return\n",
    "\n",
    "    \n",
    "    def comp_truncate(self, grading_cutoff):\n",
    "    #Grading cutoff should be a tuple of values, this function will\n",
    "    #I've only considered this for calling after converting to minus complex\n",
    "        generators = self.ring.gens()\n",
    "        for i in range(len(self.components)):\n",
    "            for vert in self.comp:\n",
    "\n",
    "                if self.comp.nodes()[vert][f\"AGrading{i}\"] >= grading_cutoff[i]:\n",
    "                    self.comp.nodes()[vert][f\"AGrading{i}\"] += 1\n",
    "                    self.comp.nodes()[vert][f\"UGrading{i}\"] += -2\n",
    "\n",
    "                    for targ in self.comp.successors(vert):\n",
    "\n",
    "                        self.comp[vert][targ]['diffweight'] = self.comp[vert][targ]['diffweight']*generators[i]\n",
    "\n",
    "                    for pred in self.comp.predecessors(vert):\n",
    "\n",
    "                        self.comp[pred][vert]['diffweight'] = self.comp[pred][vert]['diffweight']*(generators[i]^(-1))\n",
    "\n",
    "        return\n",
    "    \n",
    "    def surgery(self, grading_list = None, target_grading = None):\n",
    "\n",
    "        if grading_list == None:\n",
    "            \n",
    "            grading_list = []\n",
    "            \n",
    "            for i in range(len(self.components)):\n",
    "                self.find_grading_ranges(f\"AGrading{i}\")\n",
    "\n",
    "            for i in range(len(self.components)):\n",
    "                grading_list.append(self.max_gradings[f\"AGrading{i}\"])\n",
    "                        \n",
    "        if target_grading == None:\n",
    "            \n",
    "            target_grading = []\n",
    "            for i in range(len(self.components)):\n",
    "                target_grading.append(self.min_gradings[f\"AGrading{i}\"])\n",
    "        \n",
    "        print(\"target gradings = \" + str(target_grading))\n",
    "        print(\"max gradings = \" + str(grading_list))\n",
    "        if self.set_to_minus == False:\n",
    "            \n",
    "            print(\"This complex hasn't been converted to minus. Making a copy of the complex and converting it to the minus complex\")\n",
    "            minus_copy = self.copy()\n",
    "            minus_copy.to_minus()\n",
    "            minus_copy.surgery(grading_list, target_grading)\n",
    "            print(\"uhh didn't expect to be here...\")\n",
    "    \n",
    "        grading_ranges = []\n",
    "        \n",
    "        for i in range(len(target_grading)):\n",
    "            \n",
    "            grading_ranges.append(list(range(target_grading[i], grading_list[i]+1)))\n",
    "        \n",
    "        sub_gradings = itools.product(*grading_ranges)\n",
    "        \n",
    "        for grading in sub_gradings:\n",
    "            \n",
    "            specimen = self.copy()\n",
    "            specimen.comp_truncate(grading)\n",
    "            specimen.graph_red_search()\n",
    "            specimen.remove_zeros()\n",
    "            specimen.gml_export(str(self.sigx) + str(self.sigo) + \"surgery\" + str(grading))\n",
    "        \n",
    "        return\n",
    "\n",
    "    \n",
    "    def relative_grading_loop(self, grading_key, base_vertex, fn1, fn2, span = None, grading_multiplicity = 1):\n",
    "\n",
    "        if span == None:\n",
    "            \n",
    "            span = self.comp\n",
    "        \n",
    "\n",
    "        nx.set_node_attributes(self.comp, False, \"HasBeenGraded\")\n",
    "        self.comp.nodes()[str(base_vertex)][f'HasBeenGraded'] = True\n",
    "        self.comp.nodes()[str(base_vertex)][f'{grading_key}'] = 0\n",
    "\n",
    "        on_deck = [str(base_vertex)]\n",
    "        \n",
    "        in_the_hole = []\n",
    "\n",
    "        while len(on_deck) > 0: \n",
    "\n",
    "            for vert in on_deck:\n",
    "\n",
    "                #Every vertex in on_deck should be graded. The loops iterate through the neighbors of each of these\n",
    "                #vertices, grading them and then adding them to in_the_hole, ignoring vertices that have already been graded.\n",
    "                #\n",
    "                #The loop is broken into two halves since we have two flavors of neighbor in a directed graph, successors and\n",
    "                #predecessors, named accordingly. These flavors differ in relative grading change by a sign.\n",
    "                for i, component_columns in enumerate(self.components):\n",
    "                    for succ in span.successors(vert): \n",
    "\n",
    "                        #skip the vertex if its already been graded\n",
    "                        if self.comp.nodes()[succ]['HasBeenGraded']: continue\n",
    "                        \n",
    "                        in_the_hole.append(succ)\n",
    "                        \n",
    "                        fn1(succ, vert)\n",
    "\n",
    "                        self.comp.nodes()[succ]['HasBeenGraded'] = True\n",
    "\n",
    "                    for pred in span.predecessors(vert):\n",
    "\n",
    "                        if self.comp.nodes()[pred]['HasBeenGraded']: continue\n",
    "                        \n",
    "                        in_the_hole.append(pred)\n",
    "                        \n",
    "                        fn2(pred, vert)\n",
    "\n",
    "                        self.comp.nodes()[pred][f'HasBeenGraded'] = True\n",
    "                        \n",
    "            on_deck = in_the_hole\n",
    "            in_the_hole = []\n",
    "                                                \n",
    "        return\n",
    "\n",
    "    \n",
    "    def componentwise_relative_grading_loop(self, grading_key, base_vertex, fn1, fn2, span = None, grading_multiplicity = 1):\n",
    "\n",
    "        if span == None:\n",
    "            \n",
    "            span = self.comp\n",
    "        \n",
    "        for i in range(grading_multiplicity):\n",
    "\n",
    "            nx.set_node_attributes(self.comp, False, f\"HasBeenGraded{i}\")\n",
    "            self.comp.nodes()[str(base_vertex)][f'HasBeenGraded{i}'] = True\n",
    "            self.comp.nodes()[str(base_vertex)][f'{grading_key}{i}'] = 0\n",
    "\n",
    "        on_deck = [str(base_vertex)]\n",
    "        \n",
    "        in_the_hole =[]\n",
    "\n",
    "        while len(on_deck) > 0: \n",
    "\n",
    "            for vert in on_deck:\n",
    "\n",
    "                #Every vertex in on_deck should be graded. The loops iterate through the neighbors of each of these\n",
    "                #vertices, grading them and then adding them to in_the_hole, ignoring vertices that have already been graded.\n",
    "                #\n",
    "                #The loop is broken into two halves since we have two flavors of neighbor in a directed graph, successors and\n",
    "                #predecessors, named accordingly. These flavors differ in relative grading change by a sign.\n",
    "                for i, component_columns in enumerate(self.components):\n",
    "                    for succ in span.successors(vert): \n",
    "\n",
    "                        #skip the vertex if its already been graded\n",
    "                        if self.comp.nodes()[succ][f'HasBeenGraded{i}']: continue\n",
    "                        \n",
    "                        in_the_hole.append(succ)\n",
    "                        \n",
    "                        fn1(i, succ, vert, component_columns)\n",
    "\n",
    "                        self.comp.nodes()[succ][f'HasBeenGraded{i}'] = True\n",
    "\n",
    "                    for pred in span.predecessors(vert):\n",
    "\n",
    "                        if self.comp.nodes()[pred][f'HasBeenGraded{i}']: continue\n",
    "                        \n",
    "                        in_the_hole.append(pred)\n",
    "                        \n",
    "                        fn2(i, pred, vert, component_columns)\n",
    "\n",
    "                        self.comp.nodes()[pred][f'HasBeenGraded{i}'] = True\n",
    "                        \n",
    "            on_deck = in_the_hole\n",
    "            in_the_hole = []\n",
    "                        \n",
    "        return\n",
    "\n",
    "    def virtual_U_gradings_pred(self, i, pred, vert, component_columns):\n",
    "\n",
    "        ed_weight = self.comp[pred][vert]['diffweight']\n",
    "\n",
    "        Upows = link_U_deg(ed_weight, self.ring, component_columns)\n",
    "        self.comp.nodes()[pred][f'UGrading{i}'] = self.comp.nodes()[vert][f'UGrading{i}'] + 1 - 2*Upows\n",
    "        \n",
    "        return\n",
    "\n",
    "    def virtual_U_gradings_succ(self, i, succ, vert, component_columns):        \n",
    "        \n",
    "        ed_weight = self.comp[vert][succ]['diffweight']\n",
    "\n",
    "        Upows = link_U_deg(ed_weight, self.ring, component_columns)\n",
    "        self.comp.nodes()[succ][f'UGrading{i}'] = self.comp.nodes()[vert][f'UGrading{i}'] - 1 + 2*Upows\n",
    "    \n",
    "        return\n",
    "\n",
    "    def virtual_V_gradings_pred(self, i, pred, vert, component_columns):\n",
    "\n",
    "        ed_weight = self.comp[pred][vert]['diffweight']\n",
    "\n",
    "        Vpows = link_V_deg(ed_weight, self.ring, component_columns)\n",
    "        self.comp.nodes()[pred][f'VGrading{i}'] = self.comp.nodes()[vert][f'VGrading{i}'] + 1 - 2*Vpows\n",
    "        \n",
    "        return\n",
    "\n",
    "    def virtual_V_gradings_succ(self, i, succ, vert, component_columns):        \n",
    "        \n",
    "        ed_weight = self.comp[vert][succ]['diffweight']\n",
    "\n",
    "        Vpows = link_V_deg(ed_weight, self.ring, component_columns)\n",
    "        self.comp.nodes()[succ][f'VGrading{i}'] = self.comp.nodes()[vert][f'VGrading{i}'] - 1 + 2*Vpows\n",
    "              \n",
    "        return\n",
    "            \n",
    "    def maslov_U_pred(self, pred, vert):\n",
    "\n",
    "        ed_weight = self.comp[pred][vert]['diffweight']\n",
    "        \n",
    "        component_columns = self.sigx\n",
    "        \n",
    "        Upows = link_U_deg(ed_weight, self.ring, component_columns)\n",
    "        self.comp.nodes()[pred]['UGrading'] = self.comp.nodes()[vert]['UGrading'] + 1 - 2*Upows        \n",
    "        \n",
    "        return\n",
    "        \n",
    "    def maslov_U_succ(self, succ, vert):\n",
    "        \n",
    "        ed_weight = self.comp[vert][succ]['diffweight']\n",
    "\n",
    "        component_columns = self.sigx\n",
    "        \n",
    "        Upows = link_U_deg(ed_weight, self.ring, component_columns)\n",
    "        self.comp.nodes()[succ]['UGrading'] = self.comp.nodes()[vert]['UGrading'] - 1 + 2*Upows\n",
    "\n",
    "        return\n",
    "        \n",
    "    def maslov_V_pred(self, pred, vert):\n",
    "\n",
    "        ed_weight = self.comp[pred][vert]['diffweight']\n",
    "\n",
    "        component_columns = self.sigo\n",
    "        \n",
    "        Vpows = link_U_deg(ed_weight, self.ring, component_columns)\n",
    "        self.comp.nodes()[pred]['VGrading'] = self.comp.nodes()[vert]['VGrading'] + 1 - 2*Vpows        \n",
    "        \n",
    "        return\n",
    "        \n",
    "    def maslov_V_succ(self, succ, vert):\n",
    "        \n",
    "        ed_weight = self.comp[vert][succ]['diffweight']\n",
    "\n",
    "        component_columns = self.sigo\n",
    "        \n",
    "        Vpows = link_U_deg(ed_weight, self.ring, component_columns)\n",
    "        self.comp.nodes()[succ]['VGrading'] = self.comp.nodes()[vert]['VGrading'] - 1 + 2*Vpows\n",
    "\n",
    "        return\n",
    "    \n",
    "    def find_max_difference(self, key_set):\n",
    "    #For a given set of keys this function iterates through the graph and finds the largest difference. This could be improvable\n",
    "    #speed-wise by considering edges instead but as it stands the grading would have to be recomputed since that data is\n",
    "    #recorded in  the vertices instead. So in its current state that would be more expensive in processing and this is cheaper\n",
    "    #memory wise regardless.\n",
    "    \n",
    "        if type(key_set) == str:\n",
    "            key_set = [key_set]\n",
    "        \n",
    "        for key in key_set:\n",
    "            self.max_grading_changes[key] = 0\n",
    "        \n",
    "        result = 0\n",
    "        for vert in self.comp.nodes():\n",
    "            for nb in self.comp.neighbors(vert):\n",
    "                for key in key_set:\n",
    "                    if (abs(self.comp.nodes()[vert][key] - self.comp.nodes()[nb][key])) > self.max_grading_changes[key]:\n",
    "                        print(\"setting value\")\n",
    "                        self.max_grading_changes[key] = abs(self.comp.nodes()[vert][key] - self.comp.nodes()[nb][key])\n",
    "    \n",
    "        return\n",
    "    \n",
    "    def parallel_graph_single_split(self, key, split_count, split_blocks = None):\n",
    "        \n",
    "    #WARNING: !!!split count should be passed at most one lower than the actual number of cores available, this is because of \n",
    "    #ceilings being a part of the function - it means it can return a set with more blocks than the given split count!!! \n",
    "  \n",
    "        self.find_max_difference(key)\n",
    "        \n",
    "        max_step = self.max_grading_changes[key]\n",
    "\n",
    "        self.find_grading_ranges(key)\n",
    "        \n",
    "        if split_blocks == None:\n",
    "            \n",
    "            split_blocks = degree_partition(max_step, math.ceil(self.min_gradings[key]), math.ceil(self.max_gradings[key]), split_count)\n",
    "    \n",
    "        if split_blocks == None:\n",
    "            \n",
    "            return None\n",
    "        \n",
    "        result = []\n",
    "        \n",
    "        for split in split_blocks:\n",
    "            \n",
    "            current_subgraph = []\n",
    "            vertex_set = []\n",
    "            vertex_set = [vert for vert in self.comp.nodes() if ((self.comp.nodes()[vert][key] >= split[0]) and (self.comp.nodes()[vert][key] <= split[-1]))]\n",
    "            current_subgraph = self.comp.subgraph(vertex_set).copy()\n",
    "            result.append([current_subgraph, split])\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def parallel_reduction_helper(self, subgraph_set, overwrite = True):\n",
    "        \n",
    "        print(\"running parallel_reduction_helper\")\n",
    "        process_dict = {}\n",
    "        for count, subgraph in enumerate(subgraph_set):\n",
    "            \n",
    "            process_dict[count] = mp.Process(target = subgraph[0].range_graph_red_search(), args = subgraph[1] )\n",
    "            process_dict[count].start()\n",
    "        \n",
    "        for proc in process_dict:\n",
    "            \n",
    "            proc.join()\n",
    "        \n",
    "        result = subgraph_set[0][0]\n",
    "        \n",
    "        for subgraph in subgraph_set:\n",
    "            \n",
    "            result = nx.compose(result, subgraph)\n",
    "        \n",
    "        if overwrite:\n",
    "            \n",
    "            self.comp = result\n",
    "            return\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            return result\n",
    "    \n",
    "    \n",
    "    def grading_parallel_graph_red_search(self, proc_count = 2, splitting_key = \"AGrading\"):\n",
    "        \n",
    "        key = splitting_key\n",
    "        \n",
    "        subgraph_set = self.parallel_graph_single_split(splitting_key, proc_count - 1)\n",
    "        \n",
    "        if subgraph_set == None:\n",
    "            \n",
    "            self.graph_red_search()\n",
    "            return\n",
    "        \n",
    "        step = parallel_active_range(self.max_grading_changes[key], math.ceil(self.min_gradings[key]), math.ceil(self.max_gradings[key]), proc_count)\n",
    "        \n",
    "        target_loop = math.ceil((1+self.max_gradings[key]-self.min_gradings[key])/step)\n",
    "        print(str(target_loop) + str(\" target number of loops\"))\n",
    "        \n",
    "        partition = subgraph_set[:][1]\n",
    "        \n",
    "        for i in range(target_loop):\n",
    "            \n",
    "            self.parallel_reduction_helper(subgraph_set)\n",
    "            \n",
    "            partition_block_iterator(partition, step)\n",
    "            \n",
    "            subgraph_set = self.parallel_graph_single_split(splitting_key, proc_count - 1, split_blocks = partition)\n",
    "#             iterate the split\n",
    "            \n",
    "        return\n",
    "\n",
    "    \n",
    "\n",
    "    def ego_parallel_red_search(self, cutoff = 1, proc_count = 2):\n",
    "        \n",
    "        if len([source for source, target, weight in self.comp.edges(data = 'diffweight') if weight == 1]) > cutoff:\n",
    "            print(\"entering parallel reduction\")\n",
    "        while len([source for source, target, weight in self.comp.edges(data = 'diffweight') if weight == 1]) > cutoff:\n",
    "               print(str(len([source for source, target, weight in self.comp.edges(data = 'diffweight') if weight == 1])) + \"reducible edges remaining\")\n",
    "               reducible_edge = next((source for source, target, weight in self.comp.edges(data = 'diffweight') if weight == 1))\n",
    "               \n",
    "               self.ego_parallel_sweep(reducible_edge, proc_count)\n",
    "        print(\"parallel reduction complete\")\n",
    "        self.graph_red_search()\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def ego_parallel_sweep(self, start_vert = None, proc_count = 2):\n",
    "        \n",
    "        if start_vert == None:\n",
    "            \n",
    "            start_vert = self.comp.nodes()[0]\n",
    "        \n",
    "        size = len(list(self.comp.nodes)[0])\n",
    "#         (self.comp.nodes[0])\n",
    "        ego_bands = ego_split(self.comp, start_vert, size)\n",
    "        \n",
    "        partition_data = ego_region_partition(size)\n",
    "        \n",
    "        parallel_subgraph_packer(self.comp, ego_bands, partition_data, self.ring)\n",
    "        \n",
    "        region_count = len(partition_data)\n",
    "        count = 0 \n",
    "        MyManager.register('list', list)\n",
    "        with MyManager() as manager:\n",
    "            processed_subgraphs = manager.list()\n",
    "            while count < region_count:\n",
    "\n",
    "                process_dict = {}\n",
    "\n",
    "                for i in range(proc_count):\n",
    "\n",
    "                    if count < region_count:\n",
    "\n",
    "#                         processed_subgraphs = []\n",
    "                        process_dict[count] = mp.Process(target = subgraph_red_search, args = (partition_data[f\"block{count}\"]['total_region'],partition_data[f\"block{count}\"]['search_region'], processed_subgraphs))\n",
    "                        process_dict[count].start()\n",
    "                        count += 1\n",
    "\n",
    "                print(\"Assigned parallel jobs, waiting for them to finish\")\n",
    "                for proc in process_dict:\n",
    "                    print(proc)\n",
    "                    process_dict[proc].join()\n",
    "\n",
    "                print(\"count = \" + str(count) + \"region_count = \" + str(region_count))     \n",
    "            processed_subgraphs = processed_subgraphs._getvalue()    \n",
    "    #     if len(processed_subgraphs) > 0:\n",
    "            print(\"replacing parent graph...\")\n",
    "            result = processed_subgraphs[0].comp\n",
    "        \n",
    "#         else:\n",
    "#             print(\"no changes\")\n",
    "#             return\n",
    "        for element in processed_subgraphs:\n",
    "            \n",
    "            result = nx.compose(result, element.comp)\n",
    "        \n",
    "        print('reduced total graph from ' +  str(len(self.comp.nodes())), end = \"\")\n",
    "        \n",
    "        self.comp = result\n",
    "        print(' to ' +  str(len(self.comp.nodes())))\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "def subgraph_red_search(subg, search_reg, result_list):\n",
    "#     print(search_region)\n",
    "    print(type(search_reg))\n",
    "    subgraph = subg.copy()\n",
    "    search_region = search_reg.copy()\n",
    "    og_size = len(subgraph.comp.nodes())\n",
    "    for ed in [edge for edge in search_region.comp.edges() if search_region.comp.edges[edge]['diffweight'] == 1]:\n",
    "#         print(\"identified edge \" + str(ed) + \" for reduction\")\n",
    "#         print(\"nodes of subg\" + str(subgraph.comp.nodes()))\n",
    "#         print(\"nodes of search region\" + str(search_region.comp.nodes()))\n",
    "        \n",
    "        if ed in subgraph.comp.edges():\n",
    "#             print(\"reducing an edge\")\n",
    "            subgraph.graph_reduction(ed[0], ed[1])\n",
    "        \n",
    "    f_size = len(subgraph.comp.nodes())\n",
    "    print(\"reduced subgraph from size \" + str(og_size) + \" to \" + str(f_size))\n",
    "    result_list.append(subgraph)\n",
    "#     print(\"running change result length = \" + str(len(result_list)))\n",
    "            \n",
    "    return\n",
    "    \n",
    "    \n",
    "# def scatter(permutation):\n",
    "    \n",
    "#     p = pr.perm(permutation)\n",
    "#     size = len(p)\n",
    "#     result = []\n",
    "#     cycle = pr.full_cycle(size)\n",
    "#     for i in range(size):\n",
    "#         result.append(p)\n",
    "#         p = cycle*p\n",
    "        \n",
    "#     return result\n",
    "\n",
    "# def scatter_graph(permutation, graph):\n",
    "    \n",
    "\n",
    "def ego_split(graph, vertex, n):\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        result.append(nx.ego_graph(graph, vertex, i))\n",
    "        \n",
    "    for i in range(n-1, 0, -1):\n",
    "        \n",
    "        result[i].remove_nodes_from(result[i-1].nodes())\n",
    "        \n",
    "    return result\n",
    "\n",
    "def ego_region_partition(n):\n",
    "    \n",
    "    result = {}\n",
    "    \n",
    "    split_count = math.ceil(n/4)\n",
    "    \n",
    "    result[\"block0\"] = {\"search_region\": [0,1] , \"reserved_region\": [2]}\n",
    "    \n",
    "    for i in range(1,split_count):\n",
    "        \n",
    "        result[f\"block{i}\"] = {\"search_region\" : [3*i, 3*i+1], \"reserved_region\" : [3*i-1,3*i+2]}\n",
    "        \n",
    "    return result\n",
    "\n",
    "def parallel_subgraph_packer(graph, subgraphs, region_data, ring):\n",
    "    #region_data should be a dict of dicts with inner dict data labeled \"search_region\" and \"reserved_region\"\n",
    "    #the outer data should be labeled f\"block{i}\". See ego_region_partition for an example function that works\n",
    "    #with this\n",
    "    \n",
    "    #subgraphs should be a list of subgraphs corresponding to the region data specified above\n",
    "    \n",
    "    for data in region_data:\n",
    "#         print(region_data[data])\n",
    "        \n",
    "        region_nodes = []\n",
    "        \n",
    "        #unpacking the indices of the subgraphs we were passed - so we need to unpack 3\n",
    "        #layers deep in total\n",
    "        \n",
    "        for region in region_data[data]:    \n",
    "            for i in region_data[data][region]:\n",
    "#                 print(type(subgraphs[i]))\n",
    "\n",
    "                region_nodes += (list(subgraphs[i].nodes()))\n",
    "        \n",
    "        packed_subgraph = graph.subgraph(region_nodes)\n",
    "        \n",
    "        region_data[data]['total_region'] = grid_complex(packed_subgraph, ring)\n",
    "    \n",
    "    \n",
    "    for data in region_data:\n",
    "        \n",
    "        region_nodes = []\n",
    "        \n",
    "        for i in region_data[data]['search_region']:\n",
    "        \n",
    "            region_nodes += list(subgraphs[i].nodes())\n",
    "            \n",
    "        packed_subgraph = graph.subgraph(region_nodes)\n",
    "        \n",
    "        region_data[data]['search_region'] = grid_complex(packed_subgraph, ring)\n",
    "    \n",
    "    return region_data\n",
    "    \n",
    "\n",
    "def subgraph_neighborhood(graph, subgraph):\n",
    "    #Output: subgraph induced by the given subgraph and any neighbors it has in graph\n",
    "    result_nodes = set(subgraph.nodes())\n",
    "    for node in subgraph.nodes():\n",
    "        \n",
    "        for neighbor in graph.neighbors(node):\n",
    "            \n",
    "            result_nodes.add(neighbor)\n",
    "    \n",
    "    result = graph.subgraph(result_nodes)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def partition_block_iterator(blocks, step_size):\n",
    "    \n",
    "    for count, block in enumerate(blocks):\n",
    "        \n",
    "        if count == 0:\n",
    "            \n",
    "            for i in range(1, len(block)):\n",
    "                \n",
    "                blocks[i] += step_size\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            for i in range(len(block)):\n",
    "                \n",
    "                blocks[i] += step_size\n",
    "    \n",
    "    return\n",
    "    \n",
    "def name_some_vars(letters, num):\n",
    "    \n",
    "# Accepts a collection of strings, and an integer. Passing \"U\" and 3 for example returns \"U0, U1, U2\"\n",
    "    \n",
    "    result = []\n",
    "    num = int(num)\n",
    "    for letter in letters:\n",
    "        \n",
    "        for i in range(num):\n",
    "            new_var = f\"{letter}{i}\"\n",
    "            #print(new_var)\n",
    "            result.append(new_var)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def construct_cinf(g, sigx, sigo, size = -1): #Construct CFKinf complex from graph data - essentially just changing weights to polynomials\n",
    "                                  #Only works for grid diagrams *not* Latin Squares\n",
    "    print('constructing cinf...')\n",
    "    if size == -1:\n",
    "        size = len(g.get_edge_data(list(g.edges())[0][0],list(g.edges())[0][1])['diffweight'][0])  #kind of a mess - just turning the edges\n",
    "        print(\"Grid size is \" + str(size/2))\n",
    "        n = size/2                                                                              #into a list and checking the length of#the weight of the first edge\n",
    "    else:\n",
    "        n = size\n",
    "    timerstart = time.time()\n",
    "    F,Vars = cinf_coeff(n)\n",
    "    resG = nx.DiGraph()\n",
    "    for edge in g.edges:\n",
    "        \n",
    "        start = edge[0]\n",
    "        end = edge[1]\n",
    "        poly = F(0)\n",
    "        \n",
    "        \n",
    "        for subweight in g[edge[0]][edge[1]]['diffweight']:\n",
    "            \n",
    "            i = 0\n",
    "            polychange = F(1)\n",
    "#             print(str(subweight) + str(edge))\n",
    "            for entry in subweight:\n",
    "                \n",
    "                polychange = polychange*(Vars[i])**entry\n",
    "                i = i + 1\n",
    "                \n",
    "            poly += polychange\n",
    "#             print(str(edge) + str(poly))\n",
    "        resG.add_edge(start,end,diffweight = poly)\n",
    "    \n",
    "    timerend = time.time()\n",
    "    elap = timerend - timerstart\n",
    "    print('Time to construct cinf '+ str(elap))\n",
    "    return grid_complex(resG, F, sigx, sigo)\n",
    "        \n",
    "    \n",
    "def cinf_coeff(size):\n",
    "    \n",
    "# Takes size as an argument and returns the Laurent polynomial ring over Z2 with coefficients U0,...Usize-1,V0,...Vsize-1\n",
    "    \n",
    "    n = size\n",
    "    varis = name_some_vars(['U','V'],n)\n",
    "    F = LaurentPolynomialRing(GF(2), varis)\n",
    "    F.inject_variables()\n",
    "  \n",
    "    return F,list(F.gens())\n",
    "\n",
    "\n",
    "def range_skip_entry(n, skip):\n",
    "    \n",
    "# Acts similarly to standard range(n) but omits the \"skip\"th entry\n",
    "\n",
    "    u = []\n",
    "    for i in range(0, skip): u.append(i)\n",
    "    for j in range(skip+1, n): u.append(j)       \n",
    "    return u\n",
    "\n",
    "\n",
    "def link_GFC(sigx, sigo, filename = None):\n",
    "    \n",
    "    if filename == None:\n",
    "        filename = \"X\"\n",
    "        for pos in sigx:\n",
    "            filename = filename + str(pos)\n",
    "        filename = filename + \"O\"\n",
    "        for pos in sigo:\n",
    "            filename = filename + str(pos)\n",
    "        filename = filename + \".gml\"\n",
    "    \n",
    "    components = link_components(sigx, sigo)\n",
    "    link_count = len(components)\n",
    "    raw_complex = gfk.build_cinf([sigx, sigo])\n",
    "    comp = construct_cinf(raw_complex, sigx, sigo)\n",
    "    \n",
    "    comp.grade_link_complex()\n",
    "    print(\"passing to parallel reducer\")\n",
    "    comp.ego_parallel_red_search(proc_count = PROCESSOR_COUNT)\n",
    "#     comp.parallel_graph_red_search(PROCESSOR_COUNT, split_key)\n",
    "    print(\"completed parallel reducer function\")\n",
    "    comp.gml_export(filename)\n",
    "\n",
    "    comp.link_normalize()\n",
    "    \n",
    "#     comp.parallel_graph_red_search(PROCESSOR_COUNT)\n",
    "    \n",
    "    filename = \"Normalized\" + filename\n",
    "    comp.gml_export(filename)\n",
    "    \n",
    "    for i in range(len(comp.components)):\n",
    "        comp.find_grading_ranges(f'AGrading{i}')\n",
    "    \n",
    "    return comp\n",
    "\n",
    "\n",
    "def link_components(sigx, sigo):\n",
    "    \n",
    "    xperm = pr.perm(sigx)\n",
    "    operm = pr.perm(sigo)\n",
    "    comps = xperm*operm**(-1)\n",
    "    result = comps.cycles()\n",
    "    \n",
    "    return result\n",
    "\n",
    "def link_U_deg(poly, ring, component_columns):\n",
    "\n",
    "    #Input: poly a laurent polynomial in field a laurent polynomial ring\n",
    "    #\n",
    "    #Output: The total sum of powers of Ui in poly\n",
    "    \n",
    "    gens = ring.gens()\n",
    "    size = len(gens)/2\n",
    "    degree = 0\n",
    "    \n",
    "    if type(poly) == sage.rings.finite_rings.integer_mod.IntegerMod_int: return 0\n",
    "    \n",
    "    powers = poly.exponents()   \n",
    "    \n",
    "    #len(powers) tells you how many terms the polynomial has\n",
    "#     if len(powers) > 1:\n",
    "        \n",
    "#         print(poly)\n",
    "        \n",
    "#         raise Exception(\"Ran into a non-homogoneous degree change - polynomial wasn't a monomial\")\n",
    "\n",
    "    if len(powers) == 0:\n",
    "        \n",
    "        return 0    \n",
    "    \n",
    "    #powers is a list of lists since its intended for more than just monomials, since we are only care about the leading\n",
    "    #term we pull that one out\n",
    "    powers = powers[0]\n",
    "    \n",
    "    for i in component_columns:\n",
    "        \n",
    "        degree = degree + powers[i-1]\n",
    "    \n",
    "    return degree\n",
    "\n",
    "\n",
    "def link_V_deg(poly, ring, component_columns):\n",
    "\n",
    "    #Input: poly a laurent polynomial in \"ring\" a laurent polynomial ring\n",
    "    #\n",
    "    #Output: The total sum of powers of Ui in poly    \n",
    "    \n",
    "    gens = ring.gens()\n",
    "    size = len(gens)/2\n",
    "    degree = 0\n",
    "    \n",
    "    if type(poly) == sage.rings.finite_rings.integer_mod.IntegerMod_int: return 0\n",
    "    \n",
    "    powers = poly.exponents()   \n",
    "    \n",
    "    #len(powers) tells you how many terms the polynomial has    \n",
    "#     if len(powers) > 1:\n",
    "        \n",
    "#         print(poly)\n",
    "#         raise Exception(\"Ran into a non-homogoneous degree change - polynomial wasn't a monomial\")\n",
    "\n",
    "    if len(powers) == 0:\n",
    "        \n",
    "        return 0    \n",
    "    \n",
    "    #powers is a list of lists since its intended for more than just monomials, since we are only care about the leading\n",
    "    #term we pull that one out\n",
    "    powers = powers[0]\n",
    "    for i in component_columns:\n",
    "        \n",
    "        degree = degree + powers[size + i-1]\n",
    "    \n",
    "    return degree\n",
    "\n",
    "def parallel_active_range(max_grading_step, lower_range, upper_range, split_count):\n",
    "    \n",
    "    block_size = math.floor((upper_range - lower_range)/split_count)\n",
    "    \n",
    "    result = block_size - 2*max_grading_step\n",
    "\n",
    "    return result\n",
    "    \n",
    "    \n",
    "def degree_partition(max_grading_step, lower_range, upper_range, split_count):\n",
    "    #output = list of lists\n",
    "       \n",
    "    if split_count == 0:\n",
    "        raise Exception(\"Cannot split the graph into 0 pieces - check function arguments\")\n",
    "    \n",
    "    first_round = []\n",
    "    \n",
    "    block_size = math.floor((upper_range - lower_range)/split_count)\n",
    "    \n",
    "    active_range = block_size - 2*max_grading_step\n",
    "    print(\"active range \" + str(active_range))\n",
    "    \n",
    "    if ((active_range <= 0) and (split_count > 1)) :\n",
    "        \n",
    "        print(str((max_grading_step, lower_range, upper_range, split_count - 1)))\n",
    "        print(\"Cannot partition the graph into this many pieces! Parititioning into a smaller number of pieces\")\n",
    "        return degree_partition(max_grading_step, lower_range, upper_range, split_count - 1)\n",
    "    \n",
    "    if split_count == 1:\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    block = []\n",
    "    \n",
    "    max_grading_step += -1\n",
    "    \n",
    "    trailing_edge = lower_range - 1 - max_grading_step\n",
    "    leading_edge = trailing_edge \n",
    "\n",
    "    while trailing_edge < upper_range:\n",
    "        \n",
    "        block = []\n",
    "        block.append(leading_edge)\n",
    "        leading_edge += 1\n",
    "        block.append(leading_edge)\n",
    "        leading_edge += max_grading_step\n",
    "        block.append(leading_edge)\n",
    "        leading_edge += active_range\n",
    "        block.append(leading_edge)\n",
    "        leading_edge += max_grading_step\n",
    "        block.append(leading_edge)\n",
    "        leading_edge += 1\n",
    "        block.append(leading_edge)\n",
    "        first_round.append(block)\n",
    "        trailing_edge = leading_edge\n",
    "        \n",
    "    print(first_round)\n",
    "    return first_round\n",
    "\n",
    "#End of main code block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructing cinf...\n",
      "Grid size is 8\n",
      "Defining U0, U1, U2, U3, U4, U5, U6, U7, V0, V1, V2, V3, V4, V5, V6, V7\n",
      "Time to construct cinf 22.505719661712646\n",
      "grading complex...\n",
      "Time to find arborescence:12.181475400924683\n",
      "Time to grade complex (given arborescence): 12.525959968566895\n",
      "passing to parallel reducer\n",
      "entering parallel reduction\n",
      "155856reducible edges remaining\n",
      "<class '__main__.grid_complex'><class '__main__.grid_complex'>\n",
      "\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 207 to 205\n",
      "\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 11 to 11\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "reduced subgraph from size 967 to 863\n",
      "reduced subgraph from size 10118 to 8338\n",
      "2\n",
      "3\n",
      "reduced subgraph from size 12335 to 9131\n",
      "4\n",
      "5\n",
      "count = 6region_count = 6\n",
      "replacing parent graph...\n",
      "reduced total graph from 40320 to 1069\n",
      "parallel reduction complete\n",
      "Reducing complex...\n",
      "999\n",
      "Time to reduce complex: 2.9697000980377197\n",
      "completed parallel reducer function\n",
      "writing to Outputs/X83465127O45237681.gml\n",
      "writing to Outputs/NormalizedX83465127O45237681.gml\n"
     ]
    }
   ],
   "source": [
    "comp = link_GFC(*link_dict[''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(comp.comp.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructing cinf...\n",
      "Grid size is 5\n",
      "Defining U0, U1, U2, U3, U4, V0, V1, V2, V3, V4\n",
      "Time to construct cinf 0.024700164794921875\n",
      "grading complex...\n",
      "Time to find arborescence:0.012299776077270508\n",
      "Time to grade complex (given arborescence): 0.010512828826904297\n",
      "passing to parallel reducer\n",
      "entering parallel reduction\n",
      "150reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 32 to 30\n",
      "\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 112 to 68\n",
      "\n",
      "reduced subgraph from size 8 to 8\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "count = 4region_count = 4\n",
      "replacing parent graph...\n",
      "reduced total graph from 120 to 74\n",
      "29reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 54 to 52\n",
      "\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 55 to 55\n",
      "\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "count = 4region_count = 4\n",
      "replacing parent graph...\n",
      "reduced total graph from 74 to 72\n",
      "26reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 48 to 46\n",
      "\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 56 to 52\n",
      "\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "count = 4region_count = 4\n",
      "replacing parent graph...\n",
      "reduced total graph from 72 to 66\n",
      "20reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 51 to 49\n",
      "\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 47 to 47\n",
      "\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "count = 4region_count = 4\n",
      "replacing parent graph...\n",
      "reduced total graph from 66 to 64\n",
      "16reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 21 to 19\n",
      "\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 61 to 53\n",
      "\n",
      "reduced subgraph from size 1 to 1\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "count = 4region_count = 4\n",
      "replacing parent graph...\n",
      "reduced total graph from 64 to 54\n",
      "6reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 20 to 18\n",
      "\n",
      "reduced subgraph from size 51 to 51\n",
      "\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "count = 4region_count = 4\n",
      "replacing parent graph...\n",
      "reduced total graph from 54 to 52\n",
      "4reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 27 to 25\n",
      "\n",
      "<class '__main__.grid_complex'>\n",
      "\n",
      "reduced subgraph from size 46 to 46reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "count = 4region_count = 4\n",
      "replacing parent graph...\n",
      "reduced total graph from 52 to 50\n",
      "2reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 26 to 24\n",
      "\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 44 to 44\n",
      "\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "count = 4region_count = 4\n",
      "replacing parent graph...\n",
      "reduced total graph from 50 to 48\n",
      "parallel reduction complete\n",
      "Reducing complex...\n",
      "0\n",
      "Time to reduce complex: 0.008759737014770508\n",
      "completed parallel reducer function\n",
      "writing to Outputs/k3_1.gml\n",
      "writing to Outputs/Normalizedk3_1.gml\n",
      "constructing cinf...\n",
      "Grid size is 5\n",
      "Defining U0, U1, U2, U3, U4, V0, V1, V2, V3, V4\n",
      "Time to construct cinf 0.024329185485839844\n",
      "grading complex...\n",
      "Time to find arborescence:0.013330698013305664\n",
      "Time to grade complex (given arborescence): 0.010248184204101562\n",
      "passing to parallel reducer\n",
      "entering parallel reduction\n",
      "150reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 32 to 30\n",
      "\n",
      "\n",
      "\n",
      "reduced subgraph from size 112 to 72<class '__main__.grid_complex'>reduced subgraph from size 8 to 8\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "count = 4region_count = 4\n",
      "replacing parent graph...\n",
      "reduced total graph from 120 to 78\n",
      "53reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 53 to 51\n",
      "\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 60 to 58\n",
      "\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "count = 4region_count = 4\n",
      "replacing parent graph...\n",
      "reduced total graph from 78 to 73\n",
      "45reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 55 to 53\n",
      "\n",
      "reduced subgraph from size 54 to 54<class '__main__.grid_complex'>\n",
      "\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "count = 4region_count = 4\n",
      "replacing parent graph...\n",
      "reduced total graph from 73 to 71\n",
      "38reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 21 to 19\n",
      "\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 67 to 57\n",
      "\n",
      "reduced subgraph from size 2 to 2\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "count = 4region_count = 4\n",
      "replacing parent graph...\n",
      "reduced total graph from 71 to 59\n",
      "17reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 16 to 14\n",
      "\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 54 to 48\n",
      "\n",
      "reduced subgraph from size 1 to 1\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "count = 4region_count = 4\n",
      "replacing parent graph...\n",
      "reduced total graph from 59 to 50\n",
      "6reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 21 to 19\n",
      "\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 44 to 44\n",
      "\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "count = 4region_count = 4\n",
      "replacing parent graph...\n",
      "reduced total graph from 50 to 48\n",
      "2reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 21 to 19\n",
      "\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 45 to 45\n",
      "\n",
      "reduced subgraph from size 1 to 1\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "count = 4region_count = 4\n",
      "replacing parent graph...\n",
      "reduced total graph from 48 to 46\n",
      "parallel reduction complete\n",
      "Reducing complex...\n",
      "0\n",
      "Time to reduce complex: 0.007233858108520508\n",
      "completed parallel reducer function\n",
      "writing to Outputs/mk3_1.gml\n",
      "writing to Outputs/Normalizedmk3_1.gml\n",
      "constructing cinf...\n",
      "Grid size is 6\n",
      "Defining U0, U1, U2, U3, U4, U5, V0, V1, V2, V3, V4, V5\n",
      "Time to construct cinf 0.20998406410217285\n",
      "grading complex...\n",
      "Time to find arborescence:0.10922074317932129\n",
      "Time to grade complex (given arborescence): 0.07125163078308105\n",
      "passing to parallel reducer\n",
      "entering parallel reduction\n",
      "1380reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 64 to 62\n",
      "\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 275 to 251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "reduced subgraph from size 1 to 1\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "reduced subgraph from size 622 to 388\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "count = 5region_count = 5\n",
      "replacing parent graph...\n",
      "reduced total graph from 720 to 460\n",
      "621reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 188 to 186\n",
      "\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 6 to 6<class '__main__.grid_complex'>\n",
      "\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "reduced subgraph from size 440 to 346\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "count = 5region_count = 5\n",
      "replacing parent graph...\n",
      "reduced total graph from 460 to 363\n",
      "373reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 124 to 122\n",
      "\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 5 to 5<class '__main__.grid_complex'>\n",
      "\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "reduced subgraph from size 354 to 298\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "count = 5region_count = 5\n",
      "replacing parent graph...\n",
      "reduced total graph from 363 to 301\n",
      "236reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 89 to 87\n",
      "\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 26 to 26<class '__main__.grid_complex'>\n",
      "\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "reduced subgraph from size 294 to 270\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "count = 5region_count = 5\n",
      "replacing parent graph...\n",
      "reduced total graph from 301 to 274\n",
      "168reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 68 to 66\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 23 to 23<class '__main__.grid_complex'>\n",
      "\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "reduced subgraph from size 269 to 245\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "count = 5region_count = 5\n",
      "replacing parent graph...\n",
      "reduced total graph from 274 to 247\n",
      "117reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 76 to 74\n",
      "\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 12 to 12<class '__main__.grid_complex'>reduced subgraph from size 244 to 238\n",
      "\n",
      "\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "count = 5region_count = 5\n",
      "replacing parent graph...\n",
      "reduced total graph from 247 to 239\n",
      "105reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 64 to 62\n",
      "\n",
      "\n",
      "<class '__main__.grid_complex'><class '__main__.grid_complex'>\n",
      "reduced subgraph from size 18 to 18\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "reduced subgraph from size 236 to 226\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "count = 5region_count = 5\n",
      "replacing parent graph...\n",
      "reduced total graph from 239 to 227\n",
      "86reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 58 to 56\n",
      "\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 30 to 30<class '__main__.grid_complex'>reduced subgraph from size 222 to 222\n",
      "\n",
      "\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "count = 5region_count = 5\n",
      "replacing parent graph...\n",
      "reduced total graph from 227 to 225\n",
      "83reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 117 to 115\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 208 to 206\n",
      "\n",
      "reduced subgraph from size 1 to 1\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "count = 5region_count = 5\n",
      "replacing parent graph...\n",
      "reduced total graph from 225 to 221\n",
      "78reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 79 to 77\n",
      "\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 8 to 8reduced subgraph from size 215 to 215<class '__main__.grid_complex'>\n",
      "\n",
      "\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "count = 5region_count = 5\n",
      "replacing parent graph...\n",
      "reduced total graph from 221 to 219\n",
      "73reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 70 to 68<class '__main__.grid_complex'>\n",
      "\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 215 to 213reduced subgraph from size 11 to 11\n",
      "<class '__main__.grid_complex'>\n",
      "\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "count = 5region_count = 5\n",
      "replacing parent graph...\n",
      "reduced total graph from 219 to 215\n",
      "67reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 69 to 67\n",
      "\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 6 to 6reduced subgraph from size 212 to 212\n",
      "\n",
      "\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "count = 5region_count = 5\n",
      "replacing parent graph...\n",
      "reduced total graph from 215 to 213\n",
      "63reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 87 to 85<class '__main__.grid_complex'>\n",
      "\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 203 to 203\n",
      "\n",
      "reduced subgraph from size 5 to 5\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "count = 5region_count = 5\n",
      "replacing parent graph...\n",
      "reduced total graph from 213 to 211\n",
      "61reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 36 to 34<class '__main__.grid_complex'>\n",
      "\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 47 to 47reduced subgraph from size 199 to 191<class '__main__.grid_complex'>\n",
      "\n",
      "\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "count = 5region_count = 5\n",
      "replacing parent graph...\n",
      "reduced total graph from 211 to 201\n",
      "44reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 82 to 80\n",
      "\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 193 to 193\n",
      "\n",
      "reduced subgraph from size 2 to 2\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "count = 5region_count = 5\n",
      "replacing parent graph...\n",
      "reduced total graph from 201 to 199\n",
      "43reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 37 to 35\n",
      "\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 187 to 187\n",
      "\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 44 to 44\n",
      "\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "count = 5region_count = 5\n",
      "replacing parent graph...\n",
      "reduced total graph from 199 to 197\n",
      "41reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 46 to 44\n",
      "\n",
      "<class '__main__.grid_complex'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reduced subgraph from size 13 to 13<class '__main__.grid_complex'>reduced subgraph from size 194 to 194\n",
      "\n",
      "\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "count = 5region_count = 5\n",
      "replacing parent graph...\n",
      "reduced total graph from 197 to 195\n",
      "39reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 44 to 42\n",
      "\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 13 to 13reduced subgraph from size 192 to 192<class '__main__.grid_complex'>\n",
      "\n",
      "\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "count = 5region_count = 5\n",
      "replacing parent graph...\n",
      "reduced total graph from 195 to 193\n",
      "37reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 51 to 49\n",
      "\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 12 to 12<class '__main__.grid_complex'>reduced subgraph from size 189 to 187\n",
      "\n",
      "\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "count = 5region_count = 5\n",
      "replacing parent graph...\n",
      "reduced total graph from 193 to 189\n",
      "31reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 71 to 69\n",
      "\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 183 to 183\n",
      "reduced subgraph from size 4 to 4<class '__main__.grid_complex'>\n",
      "\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "count = 5region_count = 5\n",
      "replacing parent graph...\n",
      "reduced total graph from 189 to 187\n",
      "28reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 92 to 90\n",
      "\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 175 to 175\n",
      "\n",
      "reduced subgraph from size 0 to 0<class '__main__.grid_complex'>\n",
      "\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "count = 5region_count = 5\n",
      "replacing parent graph...\n",
      "reduced total graph from 187 to 185\n",
      "27reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 55 to 53\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 180 to 180reduced subgraph from size 9 to 9<class '__main__.grid_complex'>reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "count = 5region_count = 5\n",
      "replacing parent graph...\n",
      "reduced total graph from 185 to 183\n",
      "27reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 54 to 52\n",
      "\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 178 to 178reduced subgraph from size 9 to 9\n",
      "<class '__main__.grid_complex'>\n",
      "\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "count = 5region_count = 5\n",
      "replacing parent graph...\n",
      "reduced total graph from 183 to 181\n",
      "19reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 98 to 96\n",
      "\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 166 to 166\n",
      "\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "count = 5region_count = 5\n",
      "replacing parent graph...\n",
      "reduced total graph from 181 to 179\n",
      "17reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 66 to 64\n",
      "\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 173 to 173\n",
      "\n",
      "reduced subgraph from size 4 to 4\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "count = 5region_count = 5\n",
      "replacing parent graph...\n",
      "reduced total graph from 179 to 177\n",
      "16reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 76 to 74\n",
      "\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 171 to 171\n",
      "\n",
      "reduced subgraph from size 1 to 1<class '__main__.grid_complex'>\n",
      "\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "count = 5region_count = 5\n",
      "replacing parent graph...\n",
      "reduced total graph from 177 to 175\n",
      "15reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 53 to 51\n",
      "\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 170 to 170\n",
      "\n",
      "reduced subgraph from size 9 to 9<class '__main__.grid_complex'>\n",
      "\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "count = 5region_count = 5\n",
      "replacing parent graph...\n",
      "reduced total graph from 175 to 173\n",
      "13reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 41 to 39<class '__main__.grid_complex'>\n",
      "\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 10 to 10reduced subgraph from size 169 to 169\n",
      "<class '__main__.grid_complex'>\n",
      "\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "count = 5region_count = 5\n",
      "replacing parent graph...\n",
      "reduced total graph from 173 to 171\n",
      "10reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 97 to 95\n",
      "\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 148 to 148\n",
      "\n",
      "reduced subgraph from size 1 to 1<class '__main__.grid_complex'>\n",
      "\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "count = 5region_count = 5\n",
      "replacing parent graph...\n",
      "reduced total graph from 171 to 169\n",
      "9reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 36 to 34\n",
      "\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 11 to 11<class '__main__.grid_complex'>reduced subgraph from size 166 to 166\n",
      "\n",
      "\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "count = 5region_count = 5\n",
      "replacing parent graph...\n",
      "reduced total graph from 169 to 167\n",
      "7reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 47 to 45\n",
      "\n",
      "reduced subgraph from size 162 to 162<class '__main__.grid_complex'>\n",
      "\n",
      "reduced subgraph from size 8 to 8<class '__main__.grid_complex'>\n",
      "\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "count = 5region_count = 5\n",
      "replacing parent graph...\n",
      "reduced total graph from 167 to 165\n",
      "4reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 38 to 36<class '__main__.grid_complex'>\n",
      "\n",
      "reduced subgraph from size 161 to 161<class '__main__.grid_complex'>\n",
      "\n",
      "reduced subgraph from size 16 to 16<class '__main__.grid_complex'>\n",
      "\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "count = 5region_count = 5\n",
      "replacing parent graph...\n",
      "reduced total graph from 165 to 163\n",
      "2reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 23 to 21\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 16 to 16<class '__main__.grid_complex'>reduced subgraph from size 160 to 160\n",
      "\n",
      "\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "count = 5region_count = 5\n",
      "replacing parent graph...\n",
      "reduced total graph from 163 to 161\n",
      "parallel reduction complete\n",
      "Reducing complex...\n",
      "0\n",
      "Time to reduce complex: 0.053571462631225586\n",
      "completed parallel reducer function\n",
      "writing to Outputs/k4_1.gml\n",
      "writing to Outputs/Normalizedk4_1.gml\n",
      "constructing cinf...\n",
      "Grid size is 7\n",
      "Defining U0, U1, U2, U3, U4, U5, U6, V0, V1, V2, V3, V4, V5, V6\n",
      "Time to construct cinf 1.9899773597717285\n",
      "grading complex...\n",
      "Time to find arborescence:1.0279428958892822\n",
      "Time to grade complex (given arborescence): 0.6615374088287354\n",
      "passing to parallel reducer\n",
      "entering parallel reduction\n",
      "13176reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 119 to 117<class '__main__.grid_complex'>\n",
      "\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 2 to 2\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "reduced subgraph from size 355 to 323\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "reduced subgraph from size 2785 to 2035\n",
      "2\n",
      "reduced subgraph from size 3509 to 2323\n",
      "3\n",
      "4\n",
      "5\n",
      "count = 6region_count = 6\n",
      "replacing parent graph...\n",
      "reduced total graph from 5040 to 3070\n",
      "7574reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 66 to 64\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 126 to 126\n",
      "\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "reduced subgraph from size 1957 to 1361\n",
      "2\n",
      "reduced subgraph from size 1974 to 1574\n",
      "3\n",
      "4\n",
      "5\n",
      "count = 6region_count = 6\n",
      "replacing parent graph...\n",
      "reduced total graph from 3070 to 2070\n",
      "3852reducible edges remaining\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 87 to 85\n",
      "\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>\n",
      "<class '__main__.grid_complex'>reduced subgraph from size 26 to 26\n",
      "\n",
      "reduced subgraph from size 0 to 0\n",
      "<class '__main__.grid_complex'>\n",
      "reduced subgraph from size 0 to 0\n",
      "Assigned parallel jobs, waiting for them to finish\n",
      "0\n",
      "1\n",
      "reduced subgraph from size 762 to 646\n",
      "reduced subgraph from size 1790 to 1194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-30621:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_1117/3654360764.py\", line 873, in subgraph_red_search\n",
      "    result_list.append(subgraph)\n",
      "  File \"<string>\", line 2, in append\n",
      "  File \"/usr/lib/python3.10/multiprocessing/managers.py\", line 818, in _callmethod\n",
      "    kind, result = conn.recv()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 383, in _recv\n",
      "    raise EOFError\n",
      "EOFError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "count = 6region_count = 6\n"
     ]
    },
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[Errno 111] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3.10/multiprocessing/managers.py\u001b[0m in \u001b[0;36m_callmethod\u001b[0;34m(self, methodname, args, kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m             \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ForkAwareLocal' object has no attribute 'connection'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1117/1347206553.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mknot_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mcomp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlink_GFC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mknot_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#     gfk.pickle_it(comp, (link + \"gfk.p\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1117/3654360764.py\u001b[0m in \u001b[0;36mlink_GFC\u001b[0;34m(sigx, sigo, filename)\u001b[0m\n\u001b[1;32m   1088\u001b[0m     \u001b[0mcomp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrade_link_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"passing to parallel reducer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m     \u001b[0mcomp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mego_parallel_red_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPROCESSOR_COUNT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m \u001b[0;31m#     comp.parallel_graph_red_search(PROCESSOR_COUNT, split_key)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"completed parallel reducer function\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1117/3654360764.py\u001b[0m in \u001b[0;36mego_parallel_red_search\u001b[0;34m(self, cutoff, proc_count)\u001b[0m\n\u001b[1;32m    789\u001b[0m                \u001b[0mreducible_edge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'diffweight'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mego_parallel_sweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreducible_edge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproc_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"parallel reduction complete\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_red_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1117/3654360764.py\u001b[0m in \u001b[0;36mego_parallel_sweep\u001b[0;34m(self, start_vert, proc_count)\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"count = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"region_count = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregion_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m             \u001b[0mprocessed_subgraphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessed_subgraphs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m     \u001b[0;31m#     if len(processed_subgraphs) > 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"replacing parent graph...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/multiprocessing/managers.py\u001b[0m in \u001b[0;36m_getvalue\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0mGet\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreferent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         '''\n\u001b[0;32m--> 839\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'#GETVALUE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_incref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/multiprocessing/managers.py\u001b[0m in \u001b[0;36m_callmethod\u001b[0;34m(self, methodname, args, kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m             util.debug('thread %r does not own a connection',\n\u001b[1;32m    813\u001b[0m                        threading.current_thread().name)\n\u001b[0;32m--> 814\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m             \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/multiprocessing/managers.py\u001b[0m in \u001b[0;36m_connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'MainThread'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'|'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_token\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_authkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m         \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'accept_connection'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSocketClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mauthkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mSocketClient\u001b[0;34m(address)\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetblocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mConnection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused"
     ]
    }
   ],
   "source": [
    "for link in knot_dict:\n",
    "    comp = link_GFC(*knot_dict[link], link)\n",
    "#     gfk.pickle_it(comp, (link + \"gfk.p\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp.gml_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_partition(2, -3, 12, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp.find_max_difference(\"AGrading1\")\n",
    "comp.max_grading_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for knot in knot_dict:\n",
    "#     comp = link_GFC(*knot_dict[knot], knot)\n",
    "#     gfk.pickle_it(comp, (knot + \"gfk.p\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "comp = link_GFC(*knot_dict['k4_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = comp.parallel_single_split('AGrading', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp.find_max_difference('AGrading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp.max_grading_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp.find_grading_ranges('AGrading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp.max_gradings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp.min_gradings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict = {}\n",
    "mydict[\"test\"] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge in comp.comp.nodes():\n",
    "    print(comp.comp.nodes()[edge])\n",
    "    input(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "comp.comp.nodes()['[8, 2, 3, 7, 1, 5, 4, 6]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testcomp = comp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testcomp.grade_link_complex()\n",
    "input(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next((source, target, weight) for source, target, weight in comp.comp.edges(data = 'agrading0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfk.pickle_it(comp, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comp.surgery()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "comp = link_GFC([7,2,3,4,5,6,1],[2,3,4,5,6,7,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comp.surgery()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comp.to_minus()\n",
    "comp.graph_red_search()\n",
    "comp.remove_zeros()\n",
    "comp.gml_export(\"HopefullyS3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(trefoil_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for knot specific variations - should be unnecessary\n",
    "\n",
    "def gml_export_weighted(self, filename = 'PleaseNameMe.gml'):\n",
    "\n",
    "    nxG = self.comp.copy()\n",
    "\n",
    "    if filename == 'PleaseNameMe.gml':\n",
    "        print(\"You didn't name your output! It's been named PleaseNameMe.gml\")\n",
    "\n",
    "    if filename[-4:] != \".gml\":\n",
    "        filename += \".gml\"\n",
    "\n",
    "    for x,y in nxG.edges():\n",
    "\n",
    "        nxG[x][y]['diffweight'] = str(nxG[x][y]['diffweight'])\n",
    "\n",
    "    for node in nxG.nodes():\n",
    "\n",
    "        #print(str((nxG.nodes()[node]['UGrading'],nxG.nodes()[node]['VGrading'],nxG.nodes()[node]['AGrading'])))\n",
    "\n",
    "        try:\n",
    "            nxG.nodes[node]['AGrading'] = int(nxG.nodes[node]['AGrading']) \n",
    "            nxG.nodes[node]['UGrading'] = int(nxG.nodes[node]['UGrading'])\n",
    "            nxG.nodes[node]['VGrading'] = int(nxG.nodes[node]['VGrading'])\n",
    "        except:\n",
    "            nxG.nodes[node]['AGrading'] = int(-99)\n",
    "            nxG.nodes[node]['UGrading'] = int(-99)\n",
    "            nxG.nodes[node]['VGrading'] = int(-99)\n",
    "\n",
    "    nx.write_gml(nxG, filename)\n",
    "\n",
    "    return\n",
    "\n",
    "def grade_complex(given_graph, given_field, gridX = -1):\n",
    "    \n",
    "    #Input: given_graph a networkx directed graph with 'diffweight' attribute on edges\n",
    "    #       given_field the laurent polynomial field associated to the grid graph\n",
    "    #       gridX a list representing the vertex to be graded 0 in U V and Alexander gradings\n",
    "    #\n",
    "    #Output: given_graph with new attributes on the vertices for U V and Alexander gradings\n",
    "    #        also an attribute HasBeenGraded as an artifact\n",
    "    \n",
    "    \n",
    "    #If the positions of the Xs aren't provided we'll initialize around whatever\n",
    "    #state happens to appear first in the digraph structure\n",
    "    if gridX == -1:\n",
    "        \n",
    "        gridX = list(given_graph.nodes())[0]\n",
    "    \n",
    "    gens = given_field.gens()\n",
    "    size = len(gens)/2 \n",
    "\n",
    "    print(\"grading complex...\")\n",
    "    \n",
    "    #Adding an attribute to all nodes to keep track of if they've been assigned gradings\n",
    "    nx.set_node_attributes(given_graph, False, \"HasBeenGraded\")\n",
    "    \n",
    "    #The gradings are relative so we're declaring one to be in U, V, and Alexander grading 0\n",
    "    #this block initializes those balues\n",
    "    given_graph.nodes()[str(gridX)]['HasBeenGraded'] = True\n",
    "    given_graph.nodes()[str(gridX)]['AGrading'] = 0\n",
    "    given_graph.nodes()[str(gridX)]['UGrading'] = 0\n",
    "    given_graph.nodes()[str(gridX)]['VGrading'] = 0\n",
    "    \n",
    "    if TIMERS: timerstart = time.time()\n",
    "\n",
    "    #Built in function to find a spanning tree\n",
    "    #span = nx.algorithms.tree.branchings.greedy_branching(given_graph)\n",
    "    \n",
    "    tree = nx.algorithms.minimum_spanning_tree( given_graph.to_undirected()  )\n",
    "    eds = set(tree.edges())  # Issues with functions finding directed spanning set - insteada we find an undirected one then direct it\n",
    "    spanset = []\n",
    "    \n",
    "    for edge in eds:\n",
    "        \n",
    "        if edge in given_graph.edges():\n",
    "            spanset.append(edge)\n",
    "            \n",
    "        else:\n",
    "            spanset.append((edge[1],edge[0]))\n",
    "        \n",
    "    span = given_graph.edge_subgraph(spanset)\n",
    "        \n",
    "    if TIMERS:\n",
    "        \n",
    "        timerstop = time.time()\n",
    "        print(\"Time to find arborescence:\" + str(timerstop - timerstart))\n",
    "    \n",
    "    #Bit of baseball terminology for the following nested loops, the active data is essentially at bat, the list we're working\n",
    "    #through is called on_deck, and then we're building up the follow up as in_the_hole which will turn into\n",
    "    #on deck on the following loop\n",
    "    #\n",
    "    #On deck holds the edges to be iterated through\n",
    "    on_deck = [str(gridX)]\n",
    "    \n",
    "    #In the hole holds the ones to be iterated through once on_deck is cleared\n",
    "    in_the_hole = []\n",
    "    \n",
    "    if TIMERS: timerstart = time.time()\n",
    "    \n",
    "    while len(on_deck) > 0: \n",
    "               \n",
    "        for vert in on_deck:\n",
    "\n",
    "            #Every vertex in on_deck should be graded. The loops iterate through the neighbors of each of these\n",
    "            #vertices, grading them and then adding them to in_the_hole, ignoring vertices that have already been graded.\n",
    "            #\n",
    "            #The loop is broken into two halves since we have two flavors of neighbor in a directed graph, successors and\n",
    "            #predecessors, named accordingly. These flavors differ in relative grading change by a sign.\n",
    "            for succ in span.successors(vert): \n",
    "                \n",
    "                #skip the vertex if its already been graded\n",
    "                if given_graph.nodes()[succ]['HasBeenGraded']: continue\n",
    "                    \n",
    "                in_the_hole.append(succ)\n",
    "                \n",
    "                ed_weight = given_graph[vert][succ]['diffweight']\n",
    "                \n",
    "                #set the maslov (homological) gradings\n",
    "                Upows = U_deg(ed_weight, given_field)\n",
    "                given_graph.nodes()[succ]['UGrading'] = given_graph.nodes()[vert]['UGrading'] - 1 + 2*Upows\n",
    "\n",
    "                Vpows = V_deg(ed_weight, given_field)\n",
    "                given_graph.nodes()[succ]['VGrading'] = given_graph.nodes()[vert]['VGrading'] - 1 + 2*Vpows\n",
    "\n",
    "                #Alexander grading is a function of the U and V grading, set here\n",
    "                given_graph.nodes()[succ]['AGrading'] = (1/2)*(given_graph.nodes()[succ]['UGrading']-given_graph.nodes()[succ]['VGrading'])\n",
    "\n",
    "                given_graph.nodes()[succ]['HasBeenGraded'] = True\n",
    "\n",
    "            for pred in span.predecessors(vert):\n",
    "                \n",
    "                if given_graph.nodes()[pred]['HasBeenGraded']: continue\n",
    "                in_the_hole.append(pred)\n",
    "                ed_weight = given_graph[pred][vert]['diffweight']\n",
    "                \n",
    "                #set the maslov (homological) gradings, note the negative grading change since we're following an arrow backwards.\n",
    "                Upows = U_deg(ed_weight, given_field)\n",
    "                given_graph.nodes()[pred]['UGrading'] = given_graph.nodes()[vert]['UGrading'] + 1 - 2*Upows       \n",
    "\n",
    "                Vpows = V_deg(ed_weight, given_field)\n",
    "                given_graph.nodes()[pred]['VGrading'] = given_graph.nodes()[vert]['VGrading'] + 1 - 2*Vpows\n",
    "\n",
    "                given_graph.nodes()[pred]['AGrading'] = (1/2)*(given_graph.nodes()[pred]['UGrading']-given_graph.nodes()[pred]['VGrading'])\n",
    "                given_graph.nodes()[pred]['HasBeenGraded'] = True\n",
    "                \n",
    "        on_deck = in_the_hole\n",
    "        in_the_hole =[]\n",
    "        \n",
    "    if TIMERS:\n",
    "        \n",
    "        timerstop = time.time()\n",
    "        print('Time to grade complex (given arborescence): ' + str(timerstop - timerstart))\n",
    "    \n",
    "    return given_graph\n",
    "            \n",
    "\n",
    "    \n",
    "def U_deg(poly, field):\n",
    "    \n",
    "    #Input: poly a laurent polynomial (must be  a monomial) in field a laurent polynomial ring\n",
    "    #\n",
    "    #Output: The total sum of powers of Ui in poly\n",
    "    \n",
    "    gens = field.gens()\n",
    "    size = len(gens)/2\n",
    "    degree = 0\n",
    "    \n",
    "    if type(poly) == sage.rings.finite_rings.integer_mod.IntegerMod_int: return 0\n",
    "    \n",
    "    powers = poly.exponents()   \n",
    "    \n",
    "    #len(powers) tells you how many terms the polynomial has\n",
    "#     if len(powers) > 1:\n",
    "        \n",
    "#         print(poly)\n",
    "        \n",
    "#         raise Exception(\"Ran into a non-homogoneous degree change - polynomial wasn't a monomial\")\n",
    "\n",
    "    if len(powers) == 0:\n",
    "        \n",
    "        return 0    \n",
    "    \n",
    "    #powers is a list of lists since its intended for more than just monomials, since we are guaranteeing\n",
    "    #a monomial at this point we'll just lift that inner list out\n",
    "    powers = powers[0]\n",
    "    \n",
    "    for i in range(size):\n",
    "        \n",
    "        degree = degree + powers[i]\n",
    "    \n",
    "    return degree\n",
    "\n",
    "    \n",
    "def V_deg(poly, field):\n",
    "    \n",
    "    #Input: poly a laurent polynomial (must be  a monomial) in field a laurent polynomial ring\n",
    "    #\n",
    "    #Output: The total sum of powers of Ui in poly    \n",
    "    \n",
    "    gens = field.gens()\n",
    "    size = len(gens)/2\n",
    "    degree = 0\n",
    "    \n",
    "    if type(poly) == sage.rings.finite_rings.integer_mod.IntegerMod_int: return 0\n",
    "    \n",
    "    powers = poly.exponents()   \n",
    "    \n",
    "    #len(powers) tells you how many terms the polynomial has    \n",
    "#     if len(powers) > 1:\n",
    "        \n",
    "#         print(poly)\n",
    "#         raise Exception(\"Ran into a non-homogoneous degree change - polynomial wasn't a monomial\")\n",
    "\n",
    "    if len(powers) == 0:\n",
    "        \n",
    "        return 0    \n",
    "    \n",
    "    #powers is a list of lists since its intended for more than just monomials, since we are guaranteeing\n",
    "    #a monomial at this point we'll just lift that inner list out    \n",
    "    powers = powers[0]\n",
    "    for i in range(size):\n",
    "        \n",
    "        degree = degree + powers[size + i]\n",
    "    \n",
    "    return degree    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GFC(sigx, sigo, filename = None):\n",
    "    \n",
    "    if filename == None:\n",
    "        filename = \"X\"\n",
    "        for pos in sigx:\n",
    "            filename = filename + str(pos)\n",
    "        filename = filename + \"O\"\n",
    "        for pos in sigo:\n",
    "            filename = filename + str(pos)\n",
    "        filename = filename + \".gml\"\n",
    "    \n",
    "    components = link_components(sigx, sigo)\n",
    "    link_count = len(components)\n",
    "    if link_count != 1: raise Exception(\"!!!More than one component in this diagram - call the link version of ths function HFL!!!\")\n",
    "    raw_complex = gfk.build_cinf([sigx, sigo])\n",
    "    comp, defield = construct_cinf(raw_complex)\n",
    "    \n",
    "    grade_complex(comp, defield, sigo)\n",
    "    \n",
    "    graph_red_search(comp)\n",
    "    \n",
    "    gml_export_weighted(comp, filename)\n",
    "    \n",
    "    normalize(comp, defield)\n",
    "    graph_red_search(comp)\n",
    "    remove_zeros(comp)\n",
    "    \n",
    "    norm_filename = \"Normalized\" + filename\n",
    "    \n",
    "    gml_export_weighted(comp, norm_filename)\n",
    "    \n",
    "    minusinator = comp.copy()\n",
    "    \n",
    "    to_minus(minusinator, defield)\n",
    "    \n",
    "    graph_red_search(minusinator)\n",
    "    remove_zeros(minusinator)\n",
    "    minus_filename = \"Minus\" + filename\n",
    "    \n",
    "    gml_export_weighted(minusinator, minus_filename)\n",
    "    \n",
    "    return grid_complex(comp, defield)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Braid code - not necessary at present - will be nice later\n",
    "\n",
    "#converting braid notation to a grid --- this is not a unique choice in general so we're going to make some decisions\n",
    "\n",
    "class braid:\n",
    "    \n",
    "    def __init__(self, recipe, size = 0):\n",
    "        if size == 0:\n",
    "            candidate1 = max(recipe)\n",
    "            candidate2 = abs(min(recipe))\n",
    "            size = max([candidate1,candidate2])+1\n",
    "        self.strands = []\n",
    "        for i in range(1, size+1):\n",
    "            self.strands.append(i)\n",
    "        self.recipe = recipe\n",
    "        self.size = size    \n",
    "        \n",
    "def braid_to_cromwell(given):\n",
    "    n = given.size\n",
    "    closing_heights = []\n",
    "    for i in range(n):\n",
    "        closing_heights.append(i+1)\n",
    "    cromwell = [] #We're going to keep track of corners of the knot as a cromwell matrix (0's and 1's) and track the ones here by marking the two heights\n",
    "                  #for example [[3,1],[2,3],[1,2]] contains the information for a 3x3. The Cromwell matrix won't see the sub-ordering\n",
    "    strands = given.strands.copy()\n",
    "    for sig in given.recipe:\n",
    "        new_entry = crom_twist(sig, strands, cromwell, closing_heights)\n",
    "        cromwell.append(new_entry)\n",
    "    for i in range(len(strands)):\n",
    "        if strands[i] != closing_heights[i]:\n",
    "            cromwell.append([closing_heights[i],strands[i]])\n",
    "    return cromwell\n",
    "\n",
    "def crom_twist(bmove, strings, current_crom, closing_ht):\n",
    "    coord = []\n",
    "    n = len(strings)\n",
    "    if bmove > 0:\n",
    "        lower = strings[bmove-1]\n",
    "        upper = strings[bmove]\n",
    "        for i in range(len(current_crom)):     #move previous cromwell stuff up to make room as below\n",
    "            crom_twist_helper_pos(current_crom[i], lower, upper)\n",
    "        for i in range(bmove+1, n):            #move the strands up to make room for rectilinear braid move\n",
    "            strings[i] += 1\n",
    "        for i in range(len(closing_ht)):\n",
    "            if closing_ht[i] > upper:\n",
    "                closing_ht[i] += 1\n",
    "        cm1 = [strings[bmove-1],strings[bmove]+1] #\\/\\/\\/this is where the braid move actually \"happens\" \\/\\/\\/\n",
    "        strings[bmove-1] = strings[bmove]\n",
    "        strings[bmove] = strings[bmove] + 1\n",
    "    elif bmove < 0:\n",
    "        bmove = (-1)*bmove\n",
    "        lower = strings[bmove-1]\n",
    "        upper = strings[bmove]\n",
    "        for i in range(len(current_crom)):     #move previous cromwell stuff up to make room as below\n",
    "            crom_twist_helper_neg(current_crom[i], lower, upper)\n",
    "        for i in range(bmove-1, n):            #move the strands up to make room for rectilinear braid move\n",
    "            strings[i] += 1\n",
    "        for i in range(len(closing_ht)):\n",
    "            if closing_ht[i] >= lower:\n",
    "                closing_ht[i] += 1\n",
    "        cm1 = [strings[bmove],strings[bmove-1]-1] #\\/\\/\\/this is where the braid move actually \"happens\" \\/\\/\\/\n",
    "        strings[bmove] = strings[bmove - 1]\n",
    "        strings[bmove-1] = strings[bmove - 1] - 1\n",
    "    else:\n",
    "        print(\"invalid braid move\")\n",
    "    return cm1\n",
    "\n",
    "def crom_twist_helper_neg(crom_pair, lower, upper):\n",
    "    for i in range(2):\n",
    "        if crom_pair[i] >= lower:\n",
    "            crom_pair[i] += 1\n",
    "    return\n",
    "\n",
    "def crom_twist_helper_pos(crom_pair, lower, upper):\n",
    "    for i in range(2):\n",
    "        if crom_pair[i] > upper:\n",
    "            crom_pair[i] += 1\n",
    "    return\n",
    "\n",
    "def cromwell_to_grid(cromwell_pairs):\n",
    "    n = len(cromwell_pairs)\n",
    "    xhold = []\n",
    "    ohold = []\n",
    "    for i in range(n):\n",
    "        xhold.append(0)\n",
    "        ohold.append(0)\n",
    "#     print(cromwell_pairs)\n",
    "    xhold[0] = cromwell_pairs[0][0]\n",
    "    ohold[0] = cromwell_pairs[0][1]\n",
    "    count = 2\n",
    "    cromwell_pairs[0] = [-1,-1]\n",
    "    while count < 2*n:\n",
    "        for i in range(n):\n",
    "            for j in range(2):\n",
    "                if ((cromwell_pairs[i][j] in xhold)and (not(cromwell_pairs[i][j] in ohold))):\n",
    "                    ohold[i] = cromwell_pairs[i][j]\n",
    "                    xhold[i] = cromwell_pairs[i][j-1]\n",
    "                    cromwell_pairs[i] = [-1,-1]\n",
    "                    count += 2\n",
    "                elif ((cromwell_pairs[i][j] in ohold)and (not(cromwell_pairs[i][j] in xhold))):\n",
    "                    xhold[i] = cromwell_pairs[i][j]\n",
    "                    ohold[i] = cromwell_pairs[i][j-1]\n",
    "                    cromwell_pairs[i] = [-1,-1]\n",
    "                    count += 2\n",
    "    return (xhold,ohold)\n",
    "\n",
    "def grid_from_braid(bnotation):\n",
    "    \n",
    "    br = braid(bnotation)\n",
    "    crom = braid_to_cromwell(br)\n",
    "    xlist, olist = cromwell_to_grid(crom)\n",
    "    return xlist, olist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLD CODE\n",
    "\n",
    "# file = open(\"TrefoilComplex.csv\")\n",
    "# csvreader = csv.reader(file)\n",
    "# header = []\n",
    "# header = next(csvreader)\n",
    "\n",
    "# rows = []\n",
    "\n",
    "# for row in csvreader:\n",
    "#     rows.append(row)\n",
    "#     print(row)\n",
    "\n",
    "\n",
    "# file.close()\n",
    "\n",
    "# def comp_from_pickle(filename = 'DefaultPickleComp', grade = True):\n",
    "    \n",
    "# # GFK toolkit has the ability to export its raw complex as a pickle file, this imports those files, then constructs cinf. \n",
    "# # Largely unnecessary if calling from the imported GFK directly\n",
    "\n",
    "#     graph, size, knot = imp_from_pickle(filename)\n",
    "#     print(\"Grid complex imported with grid number = \" + str(size))\n",
    "#     nxg, defield = construct_cinf(graph, size)\n",
    "#     if grade:\n",
    "#         print('proceeding to grade complex.')\n",
    "#         nxg = grade_complex(nxg, defield)\n",
    "    \n",
    "#     return nxg, defield\n",
    "\n",
    "# def imp_from_pickle(filename = 'DefaultPickleComp'):\n",
    "    \n",
    "# # Imports pickle file and returns the object. Will import from DefaultPickleComp if no name is provided\n",
    "    \n",
    "#     if filename == 'DefaultPickleComp':\n",
    "#         print('No name provided for import - importing from DefaultPickleComp')\n",
    "    \n",
    "    \n",
    "#     try:\n",
    "#         file = open(filename,'rb')\n",
    "#         print(\"file opened\")\n",
    "#     except:\n",
    "#         print('Ran into an error: Make sure you\\'ve exported to the file you\\'re trying to import from')\n",
    "#     stuff = pickle.load(file)\n",
    "#     file.close()\n",
    "#     print('file closed')\n",
    "#     return stuff\n",
    "\n",
    "# def reduce_around(M, position): \n",
    "# #M isa matrix and position is a pair [a,b] where a 1 is located\n",
    "# #function does Gauss-Jordan-ish elimination on that column and in a symmetric way to the entry's row\n",
    "#     a,b = position\n",
    "#     #First step is to use the row to cancel the other entries, then we'll do a symmetric cancellation on\n",
    "#     #the columns as well\n",
    "#     column = M[:][b]\n",
    "#     for index, entry in enumerate(column):\n",
    "#         if ((index != 0) and (index != a) and (entry != 0)):\n",
    "#             M.add_multiple_of_row(index, entry, a)\n",
    "#     for index, entry in enumerate(column):\n",
    "#         if ((index != 0) and (index != a) and (entry != 0)):\n",
    "#             M.add_multiple_of_col(index, entry, b)\n",
    "#     #Now we'll repeat the process but with the row entries\n",
    "#     row = M[a][:]\n",
    "#     for index, entry in enumerate(row):\n",
    "#         if ((index != 0) and (index != b) and (entry != 0)):\n",
    "#             M.add_multiple_of_col(index, entry, b)\n",
    "#     for index, entry in enumerate(column):\n",
    "#         if ((index != 0) and (index != b) and (entry != 0)):\n",
    "#             M.add_multiple_of_row(index, entry, a)\n",
    "#     return\n",
    "\n",
    "# def hom_reduction(adj_mat):\n",
    "#     M = adj_mat\n",
    "#     row_position = 0\n",
    "#     for row in M:\n",
    "#         check, column_position = row_count(row)\n",
    "#         if row_count(check[0]) > 1:\n",
    "#             reduce_around(M, row_position, column_position)\n",
    "#         row_position = position + 1\n",
    "\n",
    "\n",
    "\n",
    "# def cinf_coeff(size):\n",
    "#     n = size\n",
    "#     varis = name_some_vars(['U','V'],n)\n",
    "#     F = LaurentPolynomialRing(GF(2), varis)\n",
    "#     F.inject_variables()\n",
    "# #     preF = LaurentPolynomialRing(GF(2), 'U', n) #F[Ui+-] which we'll then pair up with the Vi\n",
    "# #     preF.inject_variables()                     #Telling Sage we have Ui's as variables\n",
    "# #     Vars = preF.gens()                          #storing the variables in a list - not currently implemented anywhere\n",
    "# #     for vari in preF.gens():\n",
    "# #         preF.<vari> = preF\n",
    "# #     F = LaurentPolynomialRing(preF, 'V', n)     #Takes our preF (F[Ui+-]) and adjoins Vi\n",
    "# #     F.inject_variables()                        #F only thinks it has Vi as variables, we tell Sage about it\n",
    "# #     Vars = Vars + F.gens()\n",
    "# #     for vari in F.gens():\n",
    "# #        F.<vari> = F\n",
    "# #     for vari in Vars: \n",
    "# #         F.<vari> = F    \n",
    "#     return F,list(F.gens())\n",
    "\n",
    "# def find_one(targetlist): #Searches a list for first 1 - will be used for reduction\n",
    "# #     print(\"searching for 1 in\" + str(targetlist))\n",
    "#     if 1 in list(targetlist):\n",
    "        \n",
    "# #         print(\"found 1 in the list at\" + str(list(targetlist).index(1)))\n",
    "#         return list(targetlist).index(1)\n",
    "\n",
    "#     return -1\n",
    "\n",
    "# def find_col_with_one(matrix, startc=0):\n",
    "    \n",
    "#     endc = len(matrix[0])\n",
    "#     print(str(endc))\n",
    "#     for n in range(startc, endc):\n",
    "        \n",
    "#         search_result = find_one(matrix[:][n])\n",
    "#         if search_result != -1: return (search_result, n)\n",
    "        \n",
    "#     return (-1, -1)\n",
    "\n",
    "\n",
    "# def reduction_remap(matrix, row, col):\n",
    "#     n = len(matrix[0])\n",
    "#     range1 = range_skip_entry(n, row)\n",
    "# #     print(\"searching through \" + str(range1))\n",
    "#     for count, target_row in enumerate(range1):\n",
    "        \n",
    "#         entry = matrix[target_row][col]\n",
    "#         if entry != 0: my_row_add(matrix, row, target_row, entry)\n",
    "            \n",
    "#     return matrix\n",
    "\n",
    "# def row_col_del(matrix, loc):\n",
    "#     newrange = list(range(len(matrix[0])))\n",
    "#     del newrange[loc]\n",
    "#     return matrix[newrange,newrange]\n",
    "\n",
    "# def construct_sageG_cinf(g, size = -1): #Construct CFKinf complex from graph data - essentially just changing weights to polynomials\n",
    "#                                   #Only works for grid diagrams *not* Latin Squares\n",
    "#     #DEPRECATED None of the current pipelines are using sage graphs\n",
    "#     if size == -1:\n",
    "#         size = len(g.get_edge_data(list(g.edges())[0][0],list(g.edges())[0][1])['diffweight'])  #kind of a mess - just turning the edges\n",
    "#     n = size/2                                                                              #into a list and checking the length of\n",
    "#                                                                                             #the weight of the first edge\n",
    "#     F,Vars = cinf_coeff(n)\n",
    "#     resG = DiGraph()\n",
    "#     for edge in g.edges:\n",
    "        \n",
    "#         start = edge[0]\n",
    "#         end = edge[1]\n",
    "#         poly = F(1)\n",
    "#         i = 0\n",
    "#         for entry in g[edge[0]][edge[1]]['diffweight']:\n",
    "            \n",
    "#             poly = poly*(Vars[i])**entry\n",
    "#             i = i + 1\n",
    "            \n",
    "#         resG.add_edge(start, end, poly)\n",
    "        \n",
    "#     return resG\n",
    "\n",
    "# def convert_gml(fileName): #GridToolsTBD exports to a text file - this grabs it and converts the edges back to lists\n",
    "#                            #super inneficient - should convert to pickle file system or something\n",
    "#     g = nx.read_gml(fileName)\n",
    "#     for edge in g.edges:\n",
    "#         g[edge[0]][edge[1]]['diffweight'] = ast.literal_eval(g[edge[0]][edge[1]]['weight'])\n",
    "#         g[edge[0]][edge[1]]['diffweight'] = g[edge[0]][edge[1]]['diffweight'][0]+g[edge[0]][edge[1]]['diffweight'][1] #end result is edge weights as list of\n",
    "#                                                                                                           #multiplicities [U1,U2...,Un,V1,...,Vn]\n",
    "#     return g\n",
    "\n",
    "# def imp_and_construct_complex(filename):\n",
    "    \n",
    "#     #Input: Filename string for a file\n",
    "    \n",
    "#     print('importing complex...')\n",
    "#     g = convert_gml(filename)\n",
    "#     return construct_cinf(g)\n",
    "\n",
    "# def reduction(matrix):\n",
    "#     col, row = find_col_with_one(matrix)\n",
    "# #     print(\"reducing around entry \" +str(row) + \",\" +str(col))\n",
    "#     if col == -1:\n",
    "        \n",
    "#         print(\"completed reduction\")\n",
    "#         print(matrix)\n",
    "#         print (type(matrix))\n",
    "#         return matrix\n",
    "    \n",
    "#     print(\"reduction in progress\")\n",
    "#     remapped_matrix = reduction_remap(matrix, row, col)\n",
    "#     if row < col:\n",
    "        \n",
    "#         remapped_matrix = row_col_del(remapped_matrix, col)\n",
    "#         remapped_matrix = row_col_del(remapped_matrix, row)\n",
    "        \n",
    "#     else:\n",
    "        \n",
    "#         remapped_matrix = row_col_del(remapped_matrix, row)\n",
    "#         remapped_matrix = row_col_del(remapped_matrix, col)\n",
    "        \n",
    "#     return reduction(remapped_matrix)\n",
    "    \n",
    "# def my_row_add(matrix, row, targetrow, multiple):\n",
    "#     n = len(matrix[0])\n",
    "#     for i in range(n):\n",
    "#         current_src = matrix[row][i]\n",
    "#         if current_src != 0:\n",
    "# #             print(\"adding copies times \" + str(current_src))\n",
    "# #             print(\"multiple\" + str(multiple))\n",
    "# #             print(\"target entry \" + str(matrix[targetrow][i]))\n",
    "#             matrix[targetrow,i] = matrix[targetrow][i] + multiple*current_src\n",
    "# #         print(matrix)\n",
    "#     return matrix\n",
    "\n",
    "\n",
    "# def alex_power_change(poly, field):\n",
    "    \n",
    "#     gens = field.gens()\n",
    "#     size = len(gens)/2\n",
    "#     grade = 0\n",
    "#     powers = poly.exponents()\n",
    "#     if len(powers) > 1:\n",
    "        \n",
    "#         raise Exception(\"Ran into a non-homogoneous degree change - polynomial wasn't a monomial\")\n",
    "\n",
    "#     if len(powers) == 0:\n",
    "        \n",
    "#         return 0\n",
    "        \n",
    "#     powers = powers[0]\n",
    "#     for i in range(size):\n",
    "        \n",
    "#         grade = grade - powers[i] + powers[i+size]\n",
    "        \n",
    "#     return grade\n",
    "\n",
    "# def mod_out_uv(chain_comp, field):\n",
    "#     gens = field.gens()\n",
    "#     size = len(gens)/2    \n",
    "#     for edge in chain_comp.edges():\n",
    "    \n",
    "#         for i in range(size):\n",
    "            \n",
    "#             src = edge[0]\n",
    "#             tar = edge[1]\n",
    "# #             print(gens[0])\n",
    "# #             print(gens[size])\n",
    "# #             print(chain_comp[src][tar]['diffweight'])\n",
    "#             chain_comp[src][tar]['diffweight'] = chain_comp[src][tar]['diffweight'].subs({gens[i]:gens[0]})\n",
    "#             chain_comp[src][tar]['diffweight'] = chain_comp[src][tar]['diffweight'].subs({gens[size+i]:gens[size]})\n",
    "#         print(chain_comp[src][tar]['diffweight'])\n",
    "\n",
    "            \n",
    "#     return 1\n",
    "\n",
    "# def U_to_zero(chain_comp, field):\n",
    "# #Substitutes 0 for all the Ui\n",
    "    \n",
    "#     print(\"normalizing Vi's to i = 0 and Ui = 0\")\n",
    "#     gens = field.gens()\n",
    "#     size = len(gens)/2    \n",
    "#     for edge in chain_comp.edges():\n",
    "    \n",
    "#         for i in range(size):\n",
    "            \n",
    "#             src = edge[0]\n",
    "#             tar = edge[1]\n",
    "#             chain_comp[src][tar]['diffweight'] = chain_comp[src][tar]['diffweight'].subs({gens[i]:0})\n",
    "#             chain_comp[src][tar]['diffweight'] = chain_comp[src][tar]['diffweight'].subs({gens[i+size]:gens[size]})\n",
    "            \n",
    "#     remove_zeros(chain_comp)\n",
    "#     return 1\n",
    "\n",
    "# def remove_loops(givengraph, overwrite = True):\n",
    "    \n",
    "#     if overwrite:\n",
    "#         graph = givengraph\n",
    "#     else:\n",
    "#         graph = givengraph.copy()\n",
    "    \n",
    "#     for ed in list(graph.edges()):\n",
    "#         try:\n",
    "#             out = graph.edges()(ed[0],ed[1])\n",
    "#             back = graph.edges()[ed[1],ed[0]]\n",
    "#             graph.remove_edge(ed[0],ed[1])\n",
    "#             graph.remove_edge(ed[1],ed[0])\n",
    "#         except KeyError:\n",
    "#             continue\n",
    "            \n",
    "#     return graph\n",
    "\n",
    "# def remove_NU_loops(givengraph, overwrite = True):\n",
    "    \n",
    "#     if overwrite:\n",
    "#         graph = givengraph\n",
    "#     else:\n",
    "#         graph = givengraph.copy()\n",
    "    \n",
    "#     for ed in list(graph.edges()):\n",
    "#         try:\n",
    "#             out = graph.edges()(ed[0],ed[1])\n",
    "#             back = graph.edges()[ed[1],ed[0]]\n",
    "#             if graph[ed[0]][ed[1]]['diffweight'] == 1:\n",
    "#                 continue\n",
    "#             if graph[ed[1]][ed[0]]['diffweight'] == 1:\n",
    "#                 continue\n",
    "#             graph.remove_edge(ed[0],ed[1])\n",
    "#             graph.remove_edge(ed[1],ed[0])\n",
    "#         except KeyError:\n",
    "#             continue\n",
    "            \n",
    "#     return graph\n",
    "\n",
    "# def mod_out_nonVar0(chain_comp, field):\n",
    "\n",
    "# #     print(\"setting Ui's and Vi's = 0\")\n",
    "#     gens = field.gens()\n",
    "#     size = len(gens)/2    \n",
    "#     for edge in chain_comp.edges():\n",
    "    \n",
    "#         for i in range(1,size):\n",
    "            \n",
    "#             src = edge[0]\n",
    "#             tar = edge[1]\n",
    "#             chain_comp[src][tar]['diffweight'] = chain_comp[src][tar]['diffweight'].subs({gens[i]:0})\n",
    "\n",
    "#         for i in range(size+1,2*size):\n",
    "\n",
    "#             src = edge[0]\n",
    "#             tar = edge[1]\n",
    "#             chain_comp[src][tar]['diffweight'] = chain_comp[src][tar]['diffweight'].subs({gens[i]:0})\n",
    "\n",
    "#     return 1\n",
    "\n",
    "\n",
    "# iterate through dictionary keys(dict)\n",
    "#     tracker = -1\n",
    "#     for target in keydic\n",
    "#         if target weight == 1\n",
    "#             graph reduction alg\n",
    "#             tracker = 1\n",
    "#     if tracker == 1\n",
    "#         return rerun\n",
    "#     else\n",
    "#         return\n",
    "        \n",
    "# graph reduction(dict, key, target)\n",
    "#     for x in predecessors(target)\n",
    "#         if x == key: continue\n",
    "#         for y in successors(key)\n",
    "#             if y == target: continue\n",
    "#             x_weight = thegraph[x][targ]['weight']\n",
    "#             y_weight = thegraph[key][y]['weight']\n",
    "#             W = x_weight x y_weight\n",
    "#             add edge to graph from x to y weight = W\n",
    "#     delete key\n",
    "#     delete target\n",
    "#     return graph\n",
    "\n",
    "    \n",
    "    \n",
    "#     def surgery_helper(self, grading_levels, target_levels):\n",
    "# #REWRITE IN PROGRESS - CURRENTLY 90% OF ORIGINAL KNOT VERSION. UPDATING TO LINK AND SELF REFERENCE VERSION.\n",
    "#         #Input: grading_levels ex: [2,3,1,1] would be asking for the subcomplex of GFC with A0 <= 2, A1 <=3 etc.\n",
    "\n",
    "#         if len(grading_levels) != len(self.components)\n",
    "#             raise(\"!!Cannot compute surgered complex without grading cutoff information for each Alexander multigrading!!\")\n",
    "#         working_comp = self.comp.copy()\n",
    "\n",
    "#         surgery_collection = []\n",
    "\n",
    "#         if ((min_grading == None) or (max_grading == None)):\n",
    "\n",
    "#             min_grading, max_grading = grading_range(chain_comp)\n",
    "\n",
    "#         for grading in range(max_grading+1,min_grading-1, -1): #Theres room to improve here - likely don't need +-2 buffer\n",
    "\n",
    "#             surgery_collection.append([f\"surgery{grading}\",working_comp.copy()])\n",
    "#             comp_truncate(!!!!!)\n",
    "\n",
    "#         for name, comp in surgery_collection:\n",
    "\n",
    "#             to_minus(comp, !!!!!)\n",
    "#             remove_zeros(comp)\n",
    "#             graph_red_search(comp)\n",
    "\n",
    "#         return surgery_collection \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     comp.find_max_difference(\"AGrading\")\n",
    "    \n",
    "    \n",
    "#     for key in comp.max_grading_changes.keys():\n",
    "        \n",
    "#         comp.find_max_difference(key)\n",
    "    \n",
    "#     split_key = \"AGrading\"\n",
    "    \n",
    "#     for key in comp.max_grading_changes.keys():\n",
    "        \n",
    "#         if comp.max_grading_changes[key] < comp.max_grading_changes[split_key]:\n",
    "            \n",
    "#             split_key = key\n",
    "#     print(comp.max_grading_changes)\n",
    "#     print(\"splitting along \" + split_key + \" with max step = \" + str(comp.max_grading_changes[split_key]))\n",
    "# #     comp.graph_red_search()\n",
    "\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "SageMath 9.5",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
