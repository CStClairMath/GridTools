{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as itools\n",
    "import networkx as nx\n",
    "import csv\n",
    "# import ast\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "#from sage.graphs.graph_decompositions.graph_products import is_cartesian_product\n",
    "import CodeModules.GFKTools as gfk\n",
    "from CodeModules.GridPermutations import *\n",
    "import time\n",
    "import pickle\n",
    "import CodeModules.perm as pr\n",
    "from multiprocessing.managers import BaseManager\n",
    "import random as rd\n",
    "\n",
    "\n",
    "TIMERS = True\n",
    "PROCESSOR_COUNT = 12\n",
    "OUTPUTDIRECTORY = 'Outputs/'\n",
    "PRINT_PROGRESS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyManager(BaseManager):\n",
    "\n",
    "    # Necessary class definition for parallel processing\n",
    "\n",
    "    pass\n",
    "\n",
    "class grid_complex:\n",
    "    \n",
    "    # This is the data type that holds all the information and most of the functions and methods necessary\n",
    "    # to produce and manipulate the graded complex.\n",
    "    \n",
    "    def __init__(self, directed_graph, rng, sigx = None, sigo = None):\n",
    "    \n",
    "    # Initializing and setting default values. sigx and sigo should generally be provided - fail safes are included\n",
    "    # however if they're ever used then only the relative grading of the final object will be correct\n",
    "    \n",
    "        if type(directed_graph) != nx.DiGraph:\n",
    "            raise(\"!This data type only supports networkx digraphs!\")\n",
    "        \n",
    "        self.comp = directed_graph\n",
    "        self.ring = rng\n",
    "        self.min_gradings = {}\n",
    "        self.max_gradings = {}\n",
    "        self.max_grading_changes = {}\n",
    "        self.sigx = sigx\n",
    "        self.sigo = sigo\n",
    "        self.set_to_minus = False\n",
    "        self.set_to_tilde = False\n",
    "        \n",
    "        # From here the values necessary for the surgered manifold gradings are mapped out\n",
    "        \n",
    "        if (sigx != None) and (sigo != None):\n",
    "            self.size = len(sigx)\n",
    "            self.components = link_components(sigx, sigo)\n",
    "            for i in range(len(self.components)):\n",
    "\n",
    "                key = f'AGrading{i}'\n",
    "                self.min_gradings[key] = 0\n",
    "                self.max_gradings[key] = 0\n",
    "                self.max_grading_changes[key] = 0\n",
    "                key = f'UGrading{i}'\n",
    "                self.min_gradings[key] = 0\n",
    "                self.max_gradings[key] = 0\n",
    "                self.max_grading_changes[key] = 0\n",
    "                key = f'VGrading{i}'\n",
    "                self.min_gradings[key] = 0\n",
    "                self.max_gradings[key] = 0\n",
    "                self.max_grading_changes[key] = 0\n",
    "        else:\n",
    "            \n",
    "        # This is included in case the methods in the class are useful to another complex being loaded in\n",
    "        \n",
    "            self.components = None\n",
    "        \n",
    "        \n",
    "    def __repr__(self):\n",
    "\n",
    "        # If the object is called it will return the underlying digraph\n",
    "        return self.comp\n",
    "    \n",
    "    def subcomplex(self, subgraph):\n",
    "\n",
    "        # This is essentially just the subgraph - may not be an actual subcomplex if poor choice of vertices/edges are made\n",
    "        sub_copy = subgraph.copy()\n",
    "        result = grid_complex(sub_copy, self.ring)\n",
    "        \n",
    "    \n",
    "    def copy(self):\n",
    "\n",
    "        # Adds copy functionality like the copy module\n",
    "        if self.sigx == None:\n",
    "            new_copy = grid_complex(self.comp.copy(), self.ring)\n",
    "        else:\n",
    "            new_copy = grid_complex(self.comp.copy(), self.ring, self.sigx.copy(), self.sigo.copy())\n",
    "        return new_copy\n",
    "    \n",
    "    def grid(self):        \n",
    "        # Adding functionality to return the original grid that produced the complex\n",
    "        return [self.sigx, self.sigo]\n",
    "\n",
    "    \n",
    "    def graph(self):\n",
    "        return self.comp\n",
    "    \n",
    "    def ring(self):\n",
    "        return self.ring\n",
    "    \n",
    "    \n",
    "    \n",
    "    def to_hat(self):\n",
    "\n",
    "        # Substitutes 0 for all the U and V variables in the complex\n",
    "\n",
    "        print(\"setting Ui's and Vi's = 0\")\n",
    "        gens = self.ring.gens()\n",
    "        size = len(gens)/2    \n",
    "        for edge in self.comp.edges():\n",
    "\n",
    "            for i in range(2*size):\n",
    "\n",
    "                src = edge[0]\n",
    "                tar = edge[1]\n",
    "                self.comp[src][tar]['diffweight'] = self.comp[src][tar]['diffweight'].subs({gens[i]:0})\n",
    "\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def to_minus(self):\n",
    "\n",
    "        # Substitutes U0 for all the Ui and 1 for Vi\n",
    "\n",
    "        self.set_to_minus = True\n",
    "        print(\"normalizing Ui's and setting Vi = 1\")\n",
    "        gens = self.ring.gens()\n",
    "        size = len(gens)/2    \n",
    "        for edge in self.comp.edges():\n",
    "\n",
    "            for component in self.components:\n",
    "                for i in component:\n",
    "\n",
    "                    # if i == component[0]: continue\n",
    "                    setting_var = component[0] - 1\n",
    "                    src = edge[0]\n",
    "                    tar = edge[1]\n",
    "                    self.comp[src][tar]['diffweight'] = self.comp[src][tar]['diffweight'].subs({gens[i-1]:gens[setting_var]})\n",
    "                    self.comp[src][tar]['diffweight'] = self.comp[src][tar]['diffweight'].subs({gens[i+size-1]:1})\n",
    "\n",
    "        self.remove_zeros()\n",
    "        return\n",
    "\n",
    "\n",
    "    def to_tilde(self, overwrite = True):\n",
    "\n",
    "        # Converts the complex to the tilde flavor by setting all the U's and V's to 0\n",
    "        # overwrite option determines whether to apply it to the complex or to make a copy and apply\n",
    "        # the changes there.\n",
    "\n",
    "        if overwrite == False:\n",
    "\n",
    "            replacement = self.copy()\n",
    "            return replacement.to_tilde()\n",
    "\n",
    "        self.set_to_tilde = True\n",
    "        print(\"Setting all U's and V's to 0\")\n",
    "        gens = self.ring.gens()\n",
    "        size = len(gens)/2    \n",
    "\n",
    "        for edge in self.comp.edges():\n",
    "\n",
    "            for i in range(2*size):\n",
    "\n",
    "                src = edge[0]\n",
    "                tar = edge[1]\n",
    "                self.comp[src][tar]['diffweight'] = self.comp[src][tar]['diffweight'].subs({gens[i]:0})\n",
    "\n",
    "        self.remove_zeros()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def link_normalize(self):\n",
    "\n",
    "        # Substitutes Ucomp for all the Ui associated to that component\n",
    "\n",
    "        gens = self.ring.gens()\n",
    "        size = len(gens)/2    \n",
    "        for edge in self.comp.edges():\n",
    "\n",
    "            for component in self.components:\n",
    "                for i in component:\n",
    "\n",
    "                    if i == component[0]: continue\n",
    "                    setting_var = component[0] - 1\n",
    "                    src = edge[0]\n",
    "                    tar = edge[1]\n",
    "                    self.comp[src][tar]['diffweight'] = self.comp[src][tar]['diffweight'].subs({gens[i-1]:gens[setting_var]})\n",
    "                    self.comp[src][tar]['diffweight'] = self.comp[src][tar]['diffweight'].subs({gens[i+size-1]:gens[size+setting_var]})\n",
    "\n",
    "        self.remove_zeros()\n",
    "        return\n",
    "\n",
    "    \n",
    "#     def normalize(self):\n",
    "#     #Substitutes U0 for all the Ui and V0 for all Vi\n",
    "\n",
    "#         gens = self.field.gens()\n",
    "#         size = len(gens)/2    \n",
    "#         for edge in self.comp.edges():\n",
    "\n",
    "#             for i in range(size):\n",
    "\n",
    "#                 src = edge[0]\n",
    "#                 tar = edge[1]\n",
    "#                 self.comp[src][tar]['diffweight'] = self.comp[src][tar]['diffweight'].subs({gens[i]:gens[0]})\n",
    "#                 self.comp[src][tar]['diffweight'] = self.comp[src][tar]['diffweight'].subs({gens[i+size]:gens[size]})\n",
    "\n",
    "#         self.remove_zeros()\n",
    "#         return\n",
    "\n",
    "    def remove_zeros(self):\n",
    "\n",
    "    # Searches the complex for edges with weight 0 and removes the edge\n",
    "\n",
    "        elist = list(self.comp.edges())\n",
    "        for x,y in elist:\n",
    "\n",
    "            if self.comp[x][y]['diffweight'] == 0:\n",
    "\n",
    "                self.comp.remove_edge(x,y)\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "    def split_by_grading(self, partition_list, key):\n",
    "\n",
    "        # Unnecessary in current version - different approach to parallelization\n",
    "        # partition_list is expected to be of the form matching the partition function's output.\n",
    "\n",
    "        result = []\n",
    "        \n",
    "        for data in partition_list:\n",
    "            gens = [vert for vert in self.comp.nodes() if ((self.comp.nodes()[vert][key] >= data[0]) and (self.comp.nodes()[vert][key] <= data[4])) ]\n",
    "            subg = self.comp.subgraph(gens)\n",
    "            result.append(subg)\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    \n",
    "    def graph_red_search(self, started = False, timerstart = None): \n",
    "\n",
    "        # searches through a cfk inf complex for reducible edges and calling\n",
    "        # the reduction function to eliminate the pair according to the reduction algorithm\n",
    "        \n",
    "        if not started:\n",
    "            timerstart = time.time()    \n",
    "            print(\"Reducing complex...\")\n",
    "        \n",
    "        print(len([source for source, target, weight in self.comp.edges(data = 'diffweight') if weight == 1]))\n",
    "        while True:\n",
    "#             count = (count + 1)%\n",
    "            try:\n",
    "                red_target = next((source, target) for source, target, weight in self.comp.edges(data = 'diffweight') if weight == 1)\n",
    "#                 print(self.comp.edges[red_target])\n",
    "                self.graph_reduction(red_target[0], red_target[1])\n",
    "                continue\n",
    "            except:\n",
    "                (\"StopIteration\")\n",
    "            break\n",
    "\n",
    "        timerstop = time.time()\n",
    "        # print('Time to reduce complex: ' + str(timerstop - timerstart))\n",
    "\n",
    "        return\n",
    "\n",
    "    def graph_reduction(self, key, target):\n",
    "\n",
    "        # Deletes edge specified from graph_red_search and adds in edges according to the\n",
    "        # reduction algorithm\n",
    "\n",
    "        for x in self.comp.predecessors(target):\n",
    "\n",
    "            if x == key: continue\n",
    "            for y in self.comp.successors(key):\n",
    "\n",
    "                if y == target: continue\n",
    "                x_weight = self.comp[x][target]['diffweight']\n",
    "                y_weight = self.comp[key][y]['diffweight']\n",
    "                red_weight = x_weight * y_weight\n",
    "                if self.comp.has_edge(x,y):\n",
    "                    old_weight = self.comp[x][y]['diffweight']\n",
    "                    red_weight = red_weight + old_weight\n",
    "                self.comp.add_edge(x,y,diffweight=red_weight)\n",
    "\n",
    "        self.comp.remove_node(key)\n",
    "        self.comp.remove_node(target)\n",
    "        return\n",
    "\n",
    "\n",
    "    def minus_reduction(self, overwrite = True):\n",
    "    \n",
    "        # Reduces the complex but only reducing edges between vertices that are in the same Alexander gradings\n",
    "        # Note: This will not overwrite (regardless of argument) if the complex hasn't been converted to the minus flavor. Instead, it\n",
    "        # will make a copy, do the reduction there, and return the new complex\n",
    "\n",
    "        if self.set_to_minus == False:\n",
    "            replacement = self.copy()\n",
    "            replacement.to_minus()\n",
    "            replacement.minus_reduction(True)\n",
    "\n",
    "        if overwrite == False:\n",
    "            replacement = self.copy()\n",
    "            replacement.minus_reduction(True)\n",
    "\n",
    "        while True:\n",
    "\n",
    "            starting_edge_count = len([source for source, target, weight in self.comp.edges(data = 'diffweight') if (weight == 1 and alexander_grading_equivalent(self.comp, source, target, len(self.components)))])\n",
    "\n",
    "            try:\n",
    "\n",
    "                source, target = next((source, target) for source, target, weight in self.comp.edges(data = 'diffweight') if (weight == 1 and alexander_grading_equivalent(self.comp, source, target, len(self.components))))\n",
    "                print(\"my alexander function returned \" + str(alexander_grading_equivalent(self.comp, source, target, len(self.components))))\n",
    "                print(self.comp.nodes()[source][\"AGrading0\"])\n",
    "                print(self.comp.nodes()[target][\"AGrading0\"])\n",
    "                # print(self.comp.nodes()[source][\"AGrading1\"])\n",
    "                self.graph_reduction(source, target)\n",
    "            except StopIteration:\n",
    "                pass\n",
    "            except:\n",
    "                print(\"Unexpected Error\")\n",
    "\n",
    "            end_edge_count = len([source for source, target, weight in self.comp.edges(data = 'diffweight') if (weight == 1 and alexander_grading_equivalent(self.comp, source, target, len(self.components)))])\n",
    "\n",
    "            if starting_edge_count == end_edge_count:\n",
    "\n",
    "                break\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def grade_link_complex(self):\n",
    "\n",
    "        # Input: given_graph a networkx directed graph with 'diffweight' attribute on edges\n",
    "        #        given_field the laurent polynomial field associated to the grid graph\n",
    "        #        gridX a list representing the vertex to be graded 0 in U V and Alexander gradings\n",
    "        #\n",
    "        # Output: given_graph with new attributes on the vertices for U V and Alexander gradings\n",
    "        #         also an attribute HasBeenGraded as an artifact\n",
    "\n",
    "\n",
    "        # If the positions of the Xs aren't provided we'll initialize around whatever\n",
    "        # state happens to appear first in the digraph structure - This will mean the complex's absolute grading will be off\n",
    "        if self.sigx == None:\n",
    "\n",
    "            gridX = list(self.comp.nodes())[0]\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            gridX = self.sigx\n",
    "\n",
    "        if self.sigo == None:\n",
    "\n",
    "            gridO = list(self.comp.nodes())[0]\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            gridO = self.sigo\n",
    "            \n",
    "        gens = self.ring.gens()\n",
    "        size = len(gens)/2 \n",
    "\n",
    "        print(\"grading complex...\")\n",
    "\n",
    "        comp_set = len(self.components)\n",
    "\n",
    "        # Adding an attribute to all nodes to keep track of if they've been assigned gradings\n",
    "        for i in range(comp_set):\n",
    "            nx.set_node_attributes(self.comp, False, f\"HasBeenGraded{i}\")\n",
    "\n",
    "        # The gradings are relative so we're declaring one to be in U, V, and Alexander grading 0\n",
    "        # this block initializes those balues\n",
    "        for i in range(comp_set):\n",
    "#             self.comp.nodes()[str(gridX)][f'HasBeenGraded{i}'] = True\n",
    "            self.comp.nodes()[str(gridX)][f'AGrading{i}'] = 0\n",
    "#             self.comp.nodes()[str(gridX)][f'UGrading{i}'] = 0\n",
    "#             self.comp.nodes()[str(gridX)][f'VGrading{i}'] = 0\n",
    "\n",
    "        if TIMERS: timerstart = time.time()\n",
    "\n",
    "        # Built in function to find a spanning tree\n",
    "        #span = nx.algorithms.tree.branchings.greedy_branching(given_graph)\n",
    "\n",
    "        tree = nx.algorithms.minimum_spanning_tree( self.comp.to_undirected()  )\n",
    "        eds = set(tree.edges())  # optimization\n",
    "        spanset = []\n",
    "\n",
    "        for edge in eds:\n",
    "\n",
    "            if edge in self.comp.edges():\n",
    "                spanset.append(edge)\n",
    "\n",
    "            else:\n",
    "                spanset.append((edge[1],edge[0]))\n",
    "\n",
    "        span = self.comp.edge_subgraph(spanset)\n",
    "\n",
    "        if TIMERS:\n",
    "\n",
    "            timerstop = time.time()\n",
    "            print(\"Time to find arborescence:\" + str(timerstop - timerstart))\n",
    "\n",
    "        # Bit of baseball terminology for the following nested loops, the active data is essentially at bat, the list we're working\n",
    "        # through is called on_deck, and then we're building up the follow up as in_the_hole which will turn into\n",
    "        # on deck on the following loop\n",
    "        #\n",
    "        # On deck holds the edges to be iterated through\n",
    "        on_deck = [str(gridX)]\n",
    "\n",
    "        # In the hole holds the ones to be iterated through once on_deck is cleared\n",
    "        in_the_hole = []\n",
    "\n",
    "        if TIMERS: timerstart = time.time()\n",
    "\n",
    "            \n",
    "        comp_count = len(self.components)\n",
    "            \n",
    "        # Grading Loops Start:\n",
    "        ####################\n",
    "        \n",
    "        self.componentwise_relative_grading_loop(\"UGrading\", gridX, self.virtual_U_gradings_succ, self.virtual_U_gradings_pred, span, comp_count)\n",
    "        self.componentwise_relative_grading_loop(\"VGrading\", gridX, self.virtual_V_gradings_succ, self.virtual_V_gradings_pred, span, comp_count)\n",
    "        self.relative_grading_loop(\"UGrading\", gridX, self.maslov_U_succ, self.maslov_U_pred, span, comp_count)\n",
    "        self.relative_grading_loop(\"VGrading\", gridX, self.maslov_V_succ, self.maslov_V_pred, span, comp_count)\n",
    "        \n",
    "        ####################\n",
    "        # Grading Loops End\n",
    "\n",
    "        for vert in self.comp.nodes():\n",
    "            self.comp.nodes()[vert]['AGrading'] = 0          \n",
    "            for i in range(len(self.components)):\n",
    "                stab_count = len(self.components[i])\n",
    "                self.comp.nodes()[vert][f'AGrading{i}'] = (1/2)*(self.comp.nodes()[vert][f'VGrading{i}']-self.comp.nodes()[vert][f'UGrading{i}'])-(1/2)*(stab_count - 1)\n",
    "                self.comp.nodes()[vert]['AGrading'] += self.comp.nodes()[vert][f'AGrading{i}']\n",
    "        if TIMERS:\n",
    "\n",
    "            timerstop = time.time()\n",
    "            print('Time to grade complex (given arborescence): ' + str(timerstop - timerstart))\n",
    "\n",
    "        return\n",
    "\n",
    "    def gml_export(self, filename = 'PleaseNameMe.gml'):\n",
    "\n",
    "        # Exports the graph as a gml file which can be opened in a program like Gephi\n",
    "\n",
    "#         if component_length == -1:\n",
    "#             return(\"!!! Unknown number of components for export !!!\")\n",
    "\n",
    "        component_length = len(self.components)\n",
    "        \n",
    "        if component_length == 0:\n",
    "            raise(\"Error finding number of components\")\n",
    "        \n",
    "        nxG = self.comp.copy()\n",
    "\n",
    "        if filename == 'PleaseNameMe.gml':\n",
    "            print(\"You didn't name your output! It's been named PleaseNameMe.gml\")\n",
    "\n",
    "        if filename[-4:] != \".gml\":\n",
    "            filename += \".gml\"\n",
    "\n",
    "        for x,y in nxG.edges():\n",
    "\n",
    "            nxG[x][y]['diffweight'] = str(nxG[x][y]['diffweight'])\n",
    "\n",
    "        for node in nxG.nodes():\n",
    "\n",
    "            #print(str((nxG.nodes()[node]['UGrading'],nxG.nodes()[node]['VGrading'],nxG.nodes()[node]['AGrading'])))\n",
    "            try:\n",
    "                nxG.nodes[node]['UGrading'] = int(nxG.nodes[node]['UGrading'])\n",
    "                nxG.nodes[node]['VGrading'] = int(nxG.nodes[node]['VGrading'])\n",
    "                nxG.nodes[node]['AGrading'] = int(nxG.nodes[node]['AGrading'])\n",
    "            except:\n",
    "                nxG.nodes[node]['UGrading'] = int(-99)\n",
    "                nxG.nodes[node]['VGrading'] = int(-99)\n",
    "                nxG.nodes[node]['AGrading'] = int(-99)\n",
    "            for i in range(component_length):\n",
    "                try:\n",
    "                    nxG.nodes[node][f'AGrading{i}'] = int(nxG.nodes[node][f'AGrading{i}']) \n",
    "                    nxG.nodes[node][f'UGrading{i}'] = int(nxG.nodes[node][f'UGrading{i}'])\n",
    "                    nxG.nodes[node][f'VGrading{i}'] = int(nxG.nodes[node][f'VGrading{i}'])\n",
    "                except:\n",
    "                    nxG.nodes[node][f'AGrading{i}'] = int(-99)\n",
    "                    nxG.nodes[node][f'UGrading{i}'] = int(-99)\n",
    "                    nxG.nodes[node][f'VGrading{i}'] = int(-99)\n",
    "\n",
    "        print(\"writing to \" + OUTPUTDIRECTORY + str(filename))\n",
    "        nx.write_gml(nxG, OUTPUTDIRECTORY + filename)\n",
    "\n",
    "        return\n",
    "\n",
    "  \n",
    "    def find_grading_ranges(self, key = \"AGrading\"):\n",
    "\n",
    "        # Finds the minimum and maximum gradings among the vertices associated with a grading key\n",
    "\n",
    "        self.min_gradings[key] = 0\n",
    "        self.max_gradings[key] = 0\n",
    "        \n",
    "        for vert in self.comp.nodes():\n",
    "\n",
    "            if self.comp.nodes[vert][key] < self.min_gradings[key]:\n",
    "\n",
    "                self.min_gradings[key] = self.comp.nodes[vert][key]\n",
    "\n",
    "            if self.comp.nodes[vert][key] > self.max_gradings[key]:\n",
    "\n",
    "                self.max_gradings[key] = self.comp.nodes[vert][key]\n",
    "\n",
    "        return\n",
    "\n",
    "    \n",
    "    def comp_truncate(self, grading_cutoff):\n",
    "\n",
    "        # Grading cutoff should be a tuple of values, this function will\n",
    "        # I've only considered this for calling after converting to minus complex\n",
    "\n",
    "        generators = self.ring.gens()\n",
    "        for i in range(len(self.components)):\n",
    "            for vert in self.comp:\n",
    "\n",
    "                if self.comp.nodes()[vert][f\"AGrading{i}\"] >= grading_cutoff[i]:\n",
    "                    self.comp.nodes()[vert][f\"AGrading{i}\"] += 1\n",
    "                    self.comp.nodes()[vert][f\"UGrading{i}\"] += -2\n",
    "\n",
    "                    for targ in self.comp.successors(vert):\n",
    "\n",
    "                        self.comp[vert][targ]['diffweight'] = self.comp[vert][targ]['diffweight']*generators[i]\n",
    "\n",
    "                    for pred in self.comp.predecessors(vert):\n",
    "\n",
    "                        self.comp[pred][vert]['diffweight'] = self.comp[pred][vert]['diffweight']*(generators[i]^(-1))\n",
    "\n",
    "        return\n",
    "    \n",
    "    def surgery(self, grading_list = None, target_grading = None):\n",
    "\n",
    "        # Creates a copy of the graph and truncates it below every combination of Alexander gradings\n",
    "        # and reduces the resulting complexes then writes them out\n",
    "\n",
    "        if grading_list == None:\n",
    "            \n",
    "            grading_list = []\n",
    "            \n",
    "            for i in range(len(self.components)):\n",
    "                self.find_grading_ranges(f\"AGrading{i}\")\n",
    "\n",
    "            for i in range(len(self.components)):\n",
    "                grading_list.append(self.max_gradings[f\"AGrading{i}\"])\n",
    "                        \n",
    "        if target_grading == None:\n",
    "            \n",
    "            target_grading = []\n",
    "            for i in range(len(self.components)):\n",
    "                target_grading.append(self.min_gradings[f\"AGrading{i}\"])\n",
    "        \n",
    "        print(\"target gradings = \" + str(target_grading))\n",
    "        print(\"max gradings = \" + str(grading_list))\n",
    "        if self.set_to_minus == False:\n",
    "            \n",
    "            print(\"This complex hasn't been converted to minus. Making a copy of the complex and converting it to the minus complex\")\n",
    "            minus_copy = self.copy()\n",
    "            minus_copy.to_minus()\n",
    "            minus_copy.surgery(grading_list, target_grading)\n",
    "            print(\"uhh didn't expect to be here...\")\n",
    "    \n",
    "        grading_ranges = []\n",
    "        \n",
    "        for i in range(len(target_grading)):\n",
    "            \n",
    "            grading_ranges.append(list(range(target_grading[i], grading_list[i]+1)))\n",
    "        \n",
    "        sub_gradings = itools.product(*grading_ranges)\n",
    "        \n",
    "        for grading in sub_gradings:\n",
    "            \n",
    "            specimen = self.copy()\n",
    "            specimen.comp_truncate(grading)\n",
    "            specimen.graph_red_search()\n",
    "            specimen.remove_zeros()\n",
    "            specimen.gml_export(str(self.sigx) + str(self.sigo) + \"surgery\" + str(grading))\n",
    "        \n",
    "        return\n",
    "\n",
    "    \n",
    "    def relative_grading_loop(self, grading_key, base_vertex, fn1, fn2, span = None, grading_multiplicity = 1):\n",
    "\n",
    "        # Loop structure around a vertex's neighbors to set gradings based on the functions fn1 and fn2.\n",
    "\n",
    "        if span == None:\n",
    "            \n",
    "            span = self.comp\n",
    "        \n",
    "\n",
    "        nx.set_node_attributes(self.comp, False, \"HasBeenGraded\")\n",
    "        self.comp.nodes()[str(base_vertex)][f'HasBeenGraded'] = True\n",
    "        self.comp.nodes()[str(base_vertex)][f'{grading_key}'] = 0\n",
    "\n",
    "        on_deck = [str(base_vertex)]\n",
    "        \n",
    "        in_the_hole = []\n",
    "\n",
    "        while len(on_deck) > 0: \n",
    "\n",
    "            for vert in on_deck:\n",
    "\n",
    "                # Every vertex in on_deck should be graded. The loops iterate through the neighbors of each of these\n",
    "                # vertices, grading them and then adding them to in_the_hole, ignoring vertices that have already been graded.\n",
    "                #\n",
    "                # The loop is broken into two halves since we have two flavors of neighbor in a directed graph, successors and\n",
    "                # predecessors, named accordingly. These flavors differ in relative grading change by a sign.\n",
    "                for i, component_columns in enumerate(self.components):\n",
    "                    for succ in span.successors(vert): \n",
    "\n",
    "                        #skip the vertex if its already been graded\n",
    "                        if self.comp.nodes()[succ]['HasBeenGraded']: continue\n",
    "                        \n",
    "                        in_the_hole.append(succ)\n",
    "                        \n",
    "                        fn1(succ, vert)\n",
    "\n",
    "                        self.comp.nodes()[succ]['HasBeenGraded'] = True\n",
    "\n",
    "                    for pred in span.predecessors(vert):\n",
    "\n",
    "                        if self.comp.nodes()[pred]['HasBeenGraded']: continue\n",
    "                        \n",
    "                        in_the_hole.append(pred)\n",
    "                        \n",
    "                        fn2(pred, vert)\n",
    "\n",
    "                        self.comp.nodes()[pred][f'HasBeenGraded'] = True\n",
    "                        \n",
    "            on_deck = in_the_hole\n",
    "            in_the_hole = []\n",
    "                                                \n",
    "        return\n",
    "\n",
    "    \n",
    "    def componentwise_relative_grading_loop(self, grading_key, base_vertex, fn1, fn2, span = None, grading_multiplicity = 1):\n",
    "\n",
    "        # Loop structure around a vertex's neighbors to set gradings based on the functions fn1 and fn2, passing\n",
    "        # the functions are passed component information as well\n",
    "\n",
    "        if span == None:\n",
    "            \n",
    "            span = self.comp\n",
    "        \n",
    "        for i in range(grading_multiplicity):\n",
    "\n",
    "            nx.set_node_attributes(self.comp, False, f\"HasBeenGraded{i}\")\n",
    "            self.comp.nodes()[str(base_vertex)][f'HasBeenGraded{i}'] = True\n",
    "            self.comp.nodes()[str(base_vertex)][f'{grading_key}{i}'] = 0\n",
    "\n",
    "        on_deck = [str(base_vertex)]\n",
    "        \n",
    "        in_the_hole =[]\n",
    "\n",
    "        while len(on_deck) > 0: \n",
    "\n",
    "            for vert in on_deck:\n",
    "\n",
    "                # Every vertex in on_deck should be graded. The loops iterate through the neighbors of each of these\n",
    "                # vertices, grading them and then adding them to in_the_hole, ignoring vertices that have already been graded.\n",
    "                #\n",
    "                # The loop is broken into two halves since we have two flavors of neighbor in a directed graph, successors and\n",
    "                # predecessors, named accordingly. These flavors differ in relative grading change by a sign.\n",
    "                for i, component_columns in enumerate(self.components):\n",
    "                    for succ in span.successors(vert): \n",
    "\n",
    "                        #skip the vertex if its already been graded\n",
    "                        if self.comp.nodes()[succ][f'HasBeenGraded{i}']: continue\n",
    "                        \n",
    "                        in_the_hole.append(succ)\n",
    "                        \n",
    "                        fn1(i, succ, vert, component_columns)\n",
    "\n",
    "                        self.comp.nodes()[succ][f'HasBeenGraded{i}'] = True\n",
    "\n",
    "                    for pred in span.predecessors(vert):\n",
    "\n",
    "                        if self.comp.nodes()[pred][f'HasBeenGraded{i}']: continue\n",
    "                        \n",
    "                        in_the_hole.append(pred)\n",
    "                        \n",
    "                        fn2(i, pred, vert, component_columns)\n",
    "\n",
    "                        self.comp.nodes()[pred][f'HasBeenGraded{i}'] = True\n",
    "                        \n",
    "            on_deck = in_the_hole\n",
    "            in_the_hole = []\n",
    "                        \n",
    "        return\n",
    "# The following block of function definitions are the supporting functions for the grading loops\n",
    "# These are passed as fn1 and fn2 to the grading loops in the grading function\n",
    "#########################################\n",
    "\n",
    "    def virtual_U_gradings_pred(self, i, pred, vert, component_columns):\n",
    "\n",
    "        ed_weight = self.comp[pred][vert]['diffweight']\n",
    "\n",
    "        Upows = link_U_deg(ed_weight, self.ring, component_columns)\n",
    "        self.comp.nodes()[pred][f'UGrading{i}'] = self.comp.nodes()[vert][f'UGrading{i}'] + 1 - 2*Upows\n",
    "        \n",
    "        return\n",
    "\n",
    "    def virtual_U_gradings_succ(self, i, succ, vert, component_columns):        \n",
    "        \n",
    "        ed_weight = self.comp[vert][succ]['diffweight']\n",
    "\n",
    "        Upows = link_U_deg(ed_weight, self.ring, component_columns)\n",
    "        self.comp.nodes()[succ][f'UGrading{i}'] = self.comp.nodes()[vert][f'UGrading{i}'] - 1 + 2*Upows\n",
    "    \n",
    "        return\n",
    "\n",
    "    def virtual_V_gradings_pred(self, i, pred, vert, component_columns):\n",
    "\n",
    "        ed_weight = self.comp[pred][vert]['diffweight']\n",
    "\n",
    "        Vpows = link_V_deg(ed_weight, self.ring, component_columns)\n",
    "        self.comp.nodes()[pred][f'VGrading{i}'] = self.comp.nodes()[vert][f'VGrading{i}'] + 1 - 2*Vpows\n",
    "        \n",
    "        return\n",
    "\n",
    "    def virtual_V_gradings_succ(self, i, succ, vert, component_columns):        \n",
    "        \n",
    "        ed_weight = self.comp[vert][succ]['diffweight']\n",
    "\n",
    "        Vpows = link_V_deg(ed_weight, self.ring, component_columns)\n",
    "        self.comp.nodes()[succ][f'VGrading{i}'] = self.comp.nodes()[vert][f'VGrading{i}'] - 1 + 2*Vpows\n",
    "              \n",
    "        return\n",
    "            \n",
    "    def maslov_U_pred(self, pred, vert):\n",
    "\n",
    "        ed_weight = self.comp[pred][vert]['diffweight']\n",
    "        \n",
    "        component_columns = self.sigx\n",
    "        \n",
    "        Upows = link_U_deg(ed_weight, self.ring, component_columns)\n",
    "        self.comp.nodes()[pred]['UGrading'] = self.comp.nodes()[vert]['UGrading'] + 1 - 2*Upows        \n",
    "        \n",
    "        return\n",
    "        \n",
    "    def maslov_U_succ(self, succ, vert):\n",
    "        \n",
    "        ed_weight = self.comp[vert][succ]['diffweight']\n",
    "\n",
    "        component_columns = self.sigx\n",
    "        \n",
    "        Upows = link_U_deg(ed_weight, self.ring, component_columns)\n",
    "        self.comp.nodes()[succ]['UGrading'] = self.comp.nodes()[vert]['UGrading'] - 1 + 2*Upows\n",
    "\n",
    "        return\n",
    "        \n",
    "    def maslov_V_pred(self, pred, vert):\n",
    "\n",
    "        ed_weight = self.comp[pred][vert]['diffweight']\n",
    "\n",
    "        component_columns = self.sigo\n",
    "        \n",
    "        Vpows = link_U_deg(ed_weight, self.ring, component_columns)\n",
    "        self.comp.nodes()[pred]['VGrading'] = self.comp.nodes()[vert]['VGrading'] + 1 - 2*Vpows        \n",
    "        \n",
    "        return\n",
    "        \n",
    "    def maslov_V_succ(self, succ, vert):\n",
    "        \n",
    "        ed_weight = self.comp[vert][succ]['diffweight']\n",
    "\n",
    "        component_columns = self.sigo\n",
    "        \n",
    "        Vpows = link_U_deg(ed_weight, self.ring, component_columns)\n",
    "        self.comp.nodes()[succ]['VGrading'] = self.comp.nodes()[vert]['VGrading'] - 1 + 2*Vpows\n",
    "\n",
    "        return\n",
    "    \n",
    "    #########################################\n",
    "    # End of relative grading support functions\n",
    "\n",
    "\n",
    "    def find_max_difference(self, key_set):\n",
    "\n",
    "        # For a given set of keys this function iterates through the graph and finds the largest difference. This could be improvable\n",
    "        # speed-wise by considering edges instead but as it stands the grading would have to be recomputed since that data is\n",
    "        # recorded in  the vertices instead. So in its current state that would be more expensive in processing and this is cheaper\n",
    "        # memory wise regardless.\n",
    "    \n",
    "        if type(key_set) == str:\n",
    "            key_set = [key_set]\n",
    "        \n",
    "        for key in key_set:\n",
    "            self.max_grading_changes[key] = 0\n",
    "        \n",
    "        result = 0\n",
    "        for vert in self.comp.nodes():\n",
    "            for nb in self.comp.neighbors(vert):\n",
    "                for key in key_set:\n",
    "                    if (abs(self.comp.nodes()[vert][key] - self.comp.nodes()[nb][key])) > self.max_grading_changes[key]:\n",
    "                        print(\"setting value\")\n",
    "                        self.max_grading_changes[key] = abs(self.comp.nodes()[vert][key] - self.comp.nodes()[nb][key])\n",
    "    \n",
    "        return\n",
    "    \n",
    "    def parallel_graph_single_split(self, key, split_count, split_blocks = None):\n",
    "        \n",
    "        # Deprecated by ego split \n",
    "\n",
    "        # WARNING: !!!split count should be passed at most one lower than the actual number of cores available, this is because of \n",
    "        # ceilings being a part of the function - it means it can return a set with more blocks than the given split count!!! \n",
    "  \n",
    "        self.find_max_difference(key)\n",
    "        \n",
    "        max_step = self.max_grading_changes[key]\n",
    "\n",
    "        self.find_grading_ranges(key)\n",
    "        \n",
    "        if split_blocks == None:\n",
    "            \n",
    "            split_blocks = degree_partition(max_step, math.ceil(self.min_gradings[key]), math.ceil(self.max_gradings[key]), split_count)\n",
    "    \n",
    "        if split_blocks == None:\n",
    "            \n",
    "            return None\n",
    "        \n",
    "        result = []\n",
    "        \n",
    "        for split in split_blocks:\n",
    "            \n",
    "            current_subgraph = []\n",
    "            vertex_set = []\n",
    "            vertex_set = [vert for vert in self.comp.nodes() if ((self.comp.nodes()[vert][key] >= split[0]) and (self.comp.nodes()[vert][key] <= split[-1]))]\n",
    "            current_subgraph = self.comp.subgraph(vertex_set).copy()\n",
    "            result.append([current_subgraph, split])\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def parallel_reduction_helper(self, subgraph_set, overwrite = True):\n",
    "        \n",
    "        print(\"running parallel_reduction_helper\")\n",
    "        process_dict = {}\n",
    "        for count, subgraph in enumerate(subgraph_set):\n",
    "            \n",
    "            process_dict[count] = mp.Process(target = subgraph[0].range_graph_red_search(), args = subgraph[1] )\n",
    "            process_dict[count].start()\n",
    "        \n",
    "        for proc in process_dict:\n",
    "            \n",
    "            proc.join()\n",
    "        \n",
    "        result = subgraph_set[0][0]\n",
    "        \n",
    "        for subgraph in subgraph_set:\n",
    "            \n",
    "            result = nx.compose(result, subgraph)\n",
    "        \n",
    "        if overwrite:\n",
    "            \n",
    "            self.comp = result\n",
    "            return\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            return result\n",
    "    \n",
    "    \n",
    "    def grading_parallel_graph_red_search(self, proc_count = 2, splitting_key = \"AGrading\"):\n",
    "        \n",
    "        # Deprecated by ego_parallel_red_search\n",
    "        \n",
    "        # graph_red_search with parallel processing by splitting into pieces based on splitting_key\n",
    "\n",
    "\n",
    "        key = splitting_key\n",
    "        \n",
    "        subgraph_set = self.parallel_graph_single_split(splitting_key, proc_count - 1)\n",
    "        \n",
    "        if subgraph_set == None:\n",
    "            \n",
    "            self.graph_red_search()\n",
    "            return\n",
    "        \n",
    "        step = parallel_active_range(self.max_grading_changes[key], math.ceil(self.min_gradings[key]), math.ceil(self.max_gradings[key]), proc_count)\n",
    "        \n",
    "        target_loop = math.ceil((1+self.max_gradings[key]-self.min_gradings[key])/step)\n",
    "        print(str(target_loop) + str(\" target number of loops\"))\n",
    "        \n",
    "        partition = subgraph_set[:][1]\n",
    "        \n",
    "        for i in range(target_loop):\n",
    "            \n",
    "            self.parallel_reduction_helper(subgraph_set)\n",
    "            \n",
    "            partition_block_iterator(partition, step)\n",
    "            \n",
    "            subgraph_set = self.parallel_graph_single_split(splitting_key, proc_count - 1, split_blocks = partition)\n",
    "#             iterate the split\n",
    "            \n",
    "        return\n",
    "\n",
    "    \n",
    "\n",
    "    def ego_parallel_red_search(self, cutoff = 100, proc_count = 2):\n",
    "\n",
    "        # graph_red_search with parallel processing support by using networkx ego graph function\n",
    "        # to split the graph\n",
    "        \n",
    "        if len([source for source, target, weight in self.comp.edges(data = 'diffweight') if weight == 1]) > cutoff:\n",
    "            print(\"entering parallel reduction\")\n",
    "        while len([source for source, target, weight in self.comp.edges(data = 'diffweight') if weight == 1]) > cutoff:\n",
    "               print(str(len([source for source, target, weight in self.comp.edges(data = 'diffweight') if weight == 1])) + \"reducible edges remaining\")\n",
    "               reducible_edge = rd.sample([source for source, target, weight in self.comp.edges(data = 'diffweight') if weight == 1], 1)\n",
    "               \n",
    "               self.ego_parallel_sweep(reducible_edge[0], proc_count)\n",
    "        print(\"parallel reduction complete\")\n",
    "        self.graph_red_search()\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def ego_parallel_sweep(self, start_vert = None, proc_count = 2):\n",
    "\n",
    "        if start_vert == None:\n",
    "            \n",
    "            start_vert = self.comp.nodes()[0]\n",
    "        \n",
    "        size = len(list(self.comp.nodes)[0])\n",
    "#         (self.comp.nodes[0])\n",
    "        ego_bands, safety = ego_split(self.comp, start_vert, size)\n",
    "        \n",
    "        partition_data = ego_region_partition(size)\n",
    "        \n",
    "        parallel_subgraph_packer(self.comp, ego_bands, partition_data, self.ring)\n",
    "        \n",
    "        region_count = len(partition_data)\n",
    "        count = 0 \n",
    "        MyManager.register('list', list)\n",
    "        with MyManager() as manager:\n",
    "            processed_subgraphs = manager.list()\n",
    "            while count < region_count:\n",
    "\n",
    "                process_dict = {}\n",
    "\n",
    "                for i in range(proc_count):\n",
    "\n",
    "                    if count < region_count:\n",
    "\n",
    "#                         processed_subgraphs = []\n",
    "                        process_dict[count] = mp.Process(target = subgraph_red_search, args = (partition_data[f\"block{count}\"]['total_region'],partition_data[f\"block{count}\"]['search_region'], processed_subgraphs))\n",
    "                        process_dict[count].start()\n",
    "                        count += 1\n",
    "\n",
    "                # print(\"Assigned parallel jobs, waiting for them to finish\")\n",
    "                for proc in process_dict:\n",
    "                    # print(proc)\n",
    "                    process_dict[proc].join()\n",
    "\n",
    "                # print(\"count = \" + str(count) + \"region_count = \" + str(region_count))     \n",
    "            processed_subgraphs = processed_subgraphs._getvalue()    \n",
    "            # print(\"replacing parent graph...\")\n",
    "            result = processed_subgraphs[0].comp\n",
    "        \n",
    "        for element in processed_subgraphs:\n",
    "            \n",
    "            result = nx.compose(result, element.comp)\n",
    "\n",
    "        result = nx.compose(result, safety)\n",
    "            \n",
    "        # print('reduced total graph from ' +  str(len(self.comp.nodes())), end = \"\")\n",
    "        \n",
    "        self.comp = result\n",
    "\n",
    "        self.remove_zeros()\n",
    "        # print(' to ' +  str(len(self.comp.nodes())))\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "def subgraph_red_search(subg, search_reg, result_list):\n",
    "\n",
    "    # graph_red_search limited to the subgraph search_reg, results are appended to result_list\n",
    "    # which in practice is a proxy list object handled by a multiprocessing manager\n",
    "\n",
    "    subgraph = subg.copy()\n",
    "    search_region = search_reg.copy()\n",
    "    og_size = len(subgraph.comp.nodes())\n",
    "    for ed in [edge for edge in search_region.comp.edges() if search_region.comp.edges[edge]['diffweight'] == 1]:\n",
    "#         print(\"identified edge \" + str(ed) + \" for reduction\")\n",
    "#         print(\"nodes of subg\" + str(subgraph.comp.nodes()))\n",
    "#         print(\"nodes of search region\" + str(search_region.comp.nodes()))\n",
    "        \n",
    "        if ed in subgraph.comp.edges():\n",
    "#             print(\"reducing an edge\")\n",
    "            subgraph.graph_reduction(ed[0], ed[1])\n",
    "        \n",
    "    f_size = len(subgraph.comp.nodes())\n",
    "    # print(\"reduced subgraph from size \" + str(og_size) + \" to \" + str(f_size))\n",
    "    result_list.append(subgraph)\n",
    "#     print(\"running change result length = \" + str(len(result_list)))\n",
    "            \n",
    "    return\n",
    "    \n",
    "\n",
    "def ego_split(graph, vertex, n):\n",
    "\n",
    "    # Returns a list of collections of vertices whose index is also their distance from the provided vertex\n",
    "    # Safety is provided to catch any separate components.\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        result.append(nx.ego_graph(graph, vertex, i))\n",
    "        \n",
    "    safety = graph.copy()\n",
    "    \n",
    "    safety.remove_nodes_from(result[n - 1].nodes())\n",
    "        \n",
    "    for i in range(n-1, 0, -1):\n",
    "        \n",
    "        result[i].remove_nodes_from(result[i-1].nodes())\n",
    "        \n",
    "    return result, safety\n",
    "\n",
    "def ego_region_partition(n):\n",
    "    \n",
    "    # Returns a dictionary of dictionaries which indicate the regions that are going to be reduced and\n",
    "    # preserved during the parallel reduction\n",
    "\n",
    "    result = {}\n",
    "    \n",
    "    split_count = math.ceil(n/4)\n",
    "    \n",
    "    result[\"block0\"] = {\"search_region\": [0,1] , \"reserved_region\": [2]}\n",
    "    \n",
    "    for i in range(1,split_count):\n",
    "        \n",
    "        result[f\"block{i}\"] = {\"search_region\" : [3*i, 3*i+1], \"reserved_region\" : [3*i-1,3*i+2]}\n",
    "        \n",
    "    return result\n",
    "\n",
    "def parallel_subgraph_packer(graph, subgraphs, region_data, ring):\n",
    "\n",
    "    # Takes the collections of vertices (intended for those from ego_split) as subgraphs from a parent\n",
    "    # graph and joins them up as subgraphs based on region_data. ring is provided to construct grid_complex objects\n",
    "    # from the resulting graphs.\n",
    "\n",
    "    # region_data should be a dict of dicts with inner dict data labeled \"search_region\" and \"reserved_region\"\n",
    "    # the outer data should be labeled f\"block{i}\". See ego_region_partition for an example function that works\n",
    "    # with this\n",
    "    \n",
    "    # subgraphs should be a list of subgraphs corresponding to the region data specified above\n",
    "    \n",
    "    for data in region_data:\n",
    "#         print(region_data[data])\n",
    "        \n",
    "        region_nodes = []\n",
    "        \n",
    "        # unpacking the indices of the subgraphs we were passed - so we need to unpack 3\n",
    "        # layers deep in total\n",
    "        \n",
    "        for region in region_data[data]:    \n",
    "            for i in region_data[data][region]:\n",
    "#                 print(type(subgraphs[i]))\n",
    "\n",
    "                region_nodes += (list(subgraphs[i].nodes()))\n",
    "        \n",
    "        packed_subgraph = graph.subgraph(region_nodes)\n",
    "        \n",
    "        region_data[data]['total_region'] = grid_complex(packed_subgraph, ring)\n",
    "    \n",
    "    \n",
    "    for data in region_data:\n",
    "        \n",
    "        region_nodes = []\n",
    "        \n",
    "        for i in region_data[data]['search_region']:\n",
    "        \n",
    "            region_nodes += list(subgraphs[i].nodes())\n",
    "            \n",
    "        packed_subgraph = graph.subgraph(region_nodes)\n",
    "        \n",
    "        region_data[data]['search_region'] = grid_complex(packed_subgraph, ring)\n",
    "    \n",
    "    return region_data\n",
    "    \n",
    "\n",
    "def subgraph_neighborhood(graph, subgraph):\n",
    "\n",
    "    # Output: subgraph induced by the given subgraph and any neighbors it has in graph\n",
    "\n",
    "    result_nodes = set(subgraph.nodes())\n",
    "    for node in subgraph.nodes():\n",
    "        \n",
    "        for neighbor in graph.neighbors(node):\n",
    "            \n",
    "            result_nodes.add(neighbor)\n",
    "    \n",
    "    result = graph.subgraph(result_nodes)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def partition_block_iterator(blocks, step_size):\n",
    "    \n",
    "    for count, block in enumerate(blocks):\n",
    "        \n",
    "        if count == 0:\n",
    "            \n",
    "            for i in range(1, len(block)):\n",
    "                \n",
    "                blocks[i] += step_size\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            for i in range(len(block)):\n",
    "                \n",
    "                blocks[i] += step_size\n",
    "    \n",
    "    return\n",
    "    \n",
    "def name_some_vars(letters, num):\n",
    "    \n",
    "# Accepts a collection of strings, and an integer. Passing \"U\" and 3 for example returns \"U0, U1, U2\"\n",
    "    \n",
    "    result = []\n",
    "    num = int(num)\n",
    "    for letter in letters:\n",
    "        \n",
    "        for i in range(num):\n",
    "            new_var = f\"{letter}{i}\"\n",
    "            #print(new_var)\n",
    "            result.append(new_var)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def construct_cinf(g, sigx, sigo, size = -1): \n",
    "    \n",
    "    # Construct CFKinf complex from graph data - essentially just changing weights to polynomials\n",
    "    # Only works for grid diagrams *not* Latin Squares\n",
    "\n",
    "    print('constructing cinf...')\n",
    "    if size == -1:\n",
    "        size = len(g.get_edge_data(list(g.edges())[0][0],list(g.edges())[0][1])['diffweight'][0])  #kind of a mess - just turning the edges\n",
    "        print(\"Grid size is \" + str(size/2))\n",
    "        n = size/2                                                                              #into a list and checking the length of#the weight of the first edge\n",
    "    else:\n",
    "        n = size\n",
    "    timerstart = time.time()\n",
    "    F,Vars = cinf_coeff(n)\n",
    "    resG = nx.DiGraph()\n",
    "    for edge in g.edges:\n",
    "        \n",
    "        start = edge[0]\n",
    "        end = edge[1]\n",
    "        poly = F(0)\n",
    "        \n",
    "        \n",
    "        for subweight in g[edge[0]][edge[1]]['diffweight']:\n",
    "            \n",
    "            i = 0\n",
    "            polychange = F(1)\n",
    "#             print(str(subweight) + str(edge))\n",
    "            for entry in subweight:\n",
    "                \n",
    "                polychange = polychange*(Vars[i])**entry\n",
    "                i = i + 1\n",
    "                \n",
    "            poly += polychange\n",
    "#             print(str(edge) + str(poly))\n",
    "        resG.add_edge(start,end,diffweight = poly)\n",
    "    \n",
    "    timerend = time.time()\n",
    "    elap = timerend - timerstart\n",
    "    print('Time to construct cinf '+ str(elap))\n",
    "    return grid_complex(resG, F, sigx, sigo)\n",
    "        \n",
    "    \n",
    "def cinf_coeff(size):\n",
    "    \n",
    "    # Takes size as an argument and returns the Laurent polynomial ring over Z2 with coefficients U0,...Usize-1,V0,...Vsize-1\n",
    "    \n",
    "    n = size\n",
    "    varis = name_some_vars(['U','V'],n)\n",
    "    F = LaurentPolynomialRing(GF(2), varis)\n",
    "    F.inject_variables()\n",
    "  \n",
    "    return F,list(F.gens())\n",
    "\n",
    "\n",
    "def range_skip_entry(n, skip):\n",
    "    \n",
    "    # Acts similarly to standard range(n) but omits the \"skip\"th entry\n",
    "\n",
    "    u = []\n",
    "    for i in range(0, skip): u.append(i)\n",
    "    for j in range(skip+1, n): u.append(j)       \n",
    "    return u\n",
    "\n",
    "\n",
    "def link_GFC(sigx, sigo, filename = None):\n",
    "\n",
    "    # Group of usual commands/functions used to produce, simplify and output a grid_complex and\n",
    "    # its simplification in one function - uses the parallel processing functions\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if filename == None:\n",
    "        filename = \"X\"\n",
    "        for pos in sigx:\n",
    "            filename = filename + str(pos)\n",
    "        filename = filename + \"O\"\n",
    "        for pos in sigo:\n",
    "            filename = filename + str(pos)\n",
    "        filename = filename + \".gml\"\n",
    "    \n",
    "    comp = setup_complex(sigx, sigo)\n",
    "\n",
    "    print(\"passing to parallel reducer\")\n",
    "    comp.ego_parallel_red_search(proc_count = PROCESSOR_COUNT)\n",
    "#     comp.parallel_graph_red_search(PROCESSOR_COUNT, split_key)\n",
    "    print(\"completed parallel reducer function\")\n",
    "    comp.gml_export(filename)\n",
    "\n",
    "    comp.link_normalize()\n",
    "    \n",
    "#     comp.parallel_graph_red_search(PROCESSOR_COUNT)\n",
    "    \n",
    "    filename = \"Normalized\" + filename\n",
    "    comp.gml_export(filename)\n",
    "    \n",
    "    for i in range(len(comp.components)):\n",
    "        comp.find_grading_ranges(f'AGrading{i}')\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(\"Time to process complex = \" + str(end_time - start_time) + \" seconds\")\n",
    "    \n",
    "    return comp\n",
    "\n",
    "\n",
    "\n",
    "def setup_complex(sigx, sigo):\n",
    "\n",
    "    # Takes two lists sigx and sigo, constructs and grades the associated complex then returns the result\n",
    "\n",
    "    raw_complex = gfk.build_cinf([sigx, sigo])\n",
    "\n",
    "    comp = construct_cinf(raw_complex, sigx, sigo)\n",
    "    \n",
    "    comp.grade_link_complex()\n",
    "\n",
    "    return comp\n",
    "\n",
    "\n",
    "\n",
    "def link_components(sigx, sigo):\n",
    "\n",
    "    # Returns the number of components in the link defined by sigx and sigo\n",
    "\n",
    "    xperm = pr.perm(sigx)\n",
    "    operm = pr.perm(sigo)\n",
    "    comps = xperm*operm**(-1)\n",
    "    result = comps.cycles()\n",
    "    \n",
    "    return result\n",
    "\n",
    "def link_U_deg(poly, ring, component_columns):\n",
    "\n",
    "    # Input: poly a laurent polynomial in field a laurent polynomial ring\n",
    "    #\n",
    "    # Output: The total sum of powers of Ui in poly\n",
    "    \n",
    "    gens = ring.gens()\n",
    "    size = len(gens)/2\n",
    "    degree = 0\n",
    "    \n",
    "    if type(poly) == sage.rings.finite_rings.integer_mod.IntegerMod_int: return 0\n",
    "    \n",
    "    powers = poly.exponents()   \n",
    "    \n",
    "    # len(powers) tells you how many terms the polynomial has\n",
    "#     if len(powers) > 1:\n",
    "        \n",
    "#         print(poly)\n",
    "        \n",
    "#         raise Exception(\"Ran into a non-homogoneous degree change - polynomial wasn't a monomial\")\n",
    "\n",
    "    if len(powers) == 0:\n",
    "        \n",
    "        return 0    \n",
    "    \n",
    "    # powers is a list of lists since its intended for more than just monomials, since we are only care about the leading\n",
    "    # term we pull that one out\n",
    "    powers = powers[0]\n",
    "    \n",
    "    for i in component_columns:\n",
    "        \n",
    "        degree = degree + powers[i-1]\n",
    "    \n",
    "    return degree\n",
    "\n",
    "\n",
    "def link_V_deg(poly, ring, component_columns):\n",
    "\n",
    "    #Input: poly a laurent polynomial in \"ring\" a laurent polynomial ring\n",
    "    #\n",
    "    #Output: The total sum of powers of Ui in poly    \n",
    "    \n",
    "    gens = ring.gens()\n",
    "    size = len(gens)/2\n",
    "    degree = 0\n",
    "    \n",
    "    if type(poly) == sage.rings.finite_rings.integer_mod.IntegerMod_int: return 0\n",
    "    \n",
    "    powers = poly.exponents()   \n",
    "    \n",
    "    if len(powers) == 0:\n",
    "        \n",
    "        return 0    \n",
    "    \n",
    "    # powers is a list of lists since its intended for more than just monomials, since we are only care about the leading\n",
    "    # term we pull that one out\n",
    "\n",
    "    powers = powers[0]\n",
    "\n",
    "    for i in component_columns:\n",
    "        \n",
    "        degree = degree + powers[size + i-1]\n",
    "    \n",
    "    return degree\n",
    "\n",
    "def parallel_active_range(max_grading_step, lower_range, upper_range, split_count):\n",
    "    \n",
    "    # deprecated by ego parallelization\n",
    "\n",
    "    # Finds and returns the range of gradings that can be reduced without affecting the gluing region\n",
    "    # or bleeding outside of the reserved regions\n",
    "\n",
    "    block_size = math.floor((upper_range - lower_range)/split_count)\n",
    "    \n",
    "    result = block_size - 2*max_grading_step\n",
    "\n",
    "    return result\n",
    "    \n",
    "    \n",
    "def degree_partition(max_grading_step, lower_range, upper_range, split_count):\n",
    "\n",
    "    # deprecated by ego parallelization\n",
    "\n",
    "    # Returns lists marking degrees for gluing, reducing and preserving when splitting the graph\n",
    "    # by grading for parallelization\n",
    "\n",
    "    #output = list of lists\n",
    "       \n",
    "    if split_count == 0:\n",
    "        raise Exception(\"Cannot split the graph into 0 pieces - check function arguments\")\n",
    "    \n",
    "    first_round = []\n",
    "    \n",
    "    block_size = math.floor((upper_range - lower_range)/split_count)\n",
    "    \n",
    "    active_range = block_size - 2*max_grading_step\n",
    "    print(\"active range \" + str(active_range))\n",
    "    \n",
    "    if ((active_range <= 0) and (split_count > 1)) :\n",
    "        \n",
    "        print(str((max_grading_step, lower_range, upper_range, split_count - 1)))\n",
    "        print(\"Cannot partition the graph into this many pieces! Parititioning into a smaller number of pieces\")\n",
    "        return degree_partition(max_grading_step, lower_range, upper_range, split_count - 1)\n",
    "    \n",
    "    if split_count == 1:\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    block = []\n",
    "    \n",
    "    max_grading_step += -1\n",
    "    \n",
    "    trailing_edge = lower_range - 1 - max_grading_step\n",
    "    leading_edge = trailing_edge \n",
    "\n",
    "    while trailing_edge < upper_range:\n",
    "        \n",
    "        block = []\n",
    "        block.append(leading_edge)\n",
    "        leading_edge += 1\n",
    "        block.append(leading_edge)\n",
    "        leading_edge += max_grading_step\n",
    "        block.append(leading_edge)\n",
    "        leading_edge += active_range\n",
    "        block.append(leading_edge)\n",
    "        leading_edge += max_grading_step\n",
    "        block.append(leading_edge)\n",
    "        leading_edge += 1\n",
    "        block.append(leading_edge)\n",
    "        first_round.append(block)\n",
    "        trailing_edge = leading_edge\n",
    "        \n",
    "    print(first_round)\n",
    "    return first_round\n",
    "\n",
    "def alexander_grading_equivalent(comp, source, target, component_count):\n",
    "\n",
    "    #Returns bool for if two vertices have the same Alexander multigradings\n",
    "\n",
    "    result = True\n",
    "\n",
    "    for i in range(component_count):\n",
    "        if comp.nodes()[source][f'AGrading{i}'] != comp.nodes()[target][f'AGrading{i}']:\n",
    "            result = False\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "#End of main code block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructing cinf...\n",
      "Grid size is 6\n",
      "Defining U0, U1, U2, U3, U4, U5, V0, V1, V2, V3, V4, V5\n",
      "Time to construct cinf 0.448178768157959\n",
      "grading complex...\n",
      "Time to find arborescence:0.2987854480743408\n",
      "Time to grade complex (given arborescence): 0.288036584854126\n",
      "Setting all U's and V's to 0\n",
      "Reducing complex...\n",
      "1548\n",
      "writing to Outputs/TildeTest.gml\n"
     ]
    }
   ],
   "source": [
    "comp = setup_complex(*link_dict['L4a1_0'])\n",
    "comp.to_tilde()\n",
    "comp.graph_red_search()\n",
    "comp.remove_zeros()\n",
    "comp.gml_export(\"TildeTest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructing cinf...\n",
      "Grid size is 4\n",
      "Defining U0, U1, U2, U3, V0, V1, V2, V3\n",
      "Time to construct cinf 0.004470109939575195\n",
      "grading complex...\n",
      "Time to find arborescence:0.0029401779174804688\n",
      "Time to grade complex (given arborescence): 0.005205392837524414\n",
      "passing to parallel reducer\n",
      "parallel reduction complete\n",
      "Reducing complex...\n",
      "16\n",
      "completed parallel reducer function\n",
      "writing to Outputs/X4321O2143.gml\n",
      "writing to Outputs/NormalizedX4321O2143.gml\n",
      "Time to process complex = 0.12974214553833008 seconds\n",
      "normalizing Ui's and setting Vi = 1\n",
      "writing to Outputs/AAAtrefoilminux.gml\n",
      "writing to Outputs/AAAhopefullyreducedthing.gml\n"
     ]
    }
   ],
   "source": [
    "comp = link_GFC(*link_dict['L2a1_0'])\n",
    "comp.to_minus()\n",
    "comp.gml_export(\"AAAtrefoilminus\")\n",
    "comp.minus_reduction()\n",
    "comp.gml_export(\"AAAhopefullyreducedthing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp.comp.nodes()['[1, 3, 4, 5, 2]'][\"AGrading0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m((x \u001b[39mfor\u001b[39;49;00m x \u001b[39min\u001b[39;49;00m []))\n\u001b[1;32m      2\u001b[0m x\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x = next((x for x in []))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(comp.comp.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructing cinf...\n",
      "Grid size is 5\n",
      "Defining U0, U1, U2, U3, U4, V0, V1, V2, V3, V4\n",
      "Time to construct cinf 0.03600025177001953\n",
      "grading complex...\n",
      "Time to find arborescence:0.017015457153320312\n",
      "Time to grade complex (given arborescence): 0.010982036590576172\n",
      "passing to parallel reducer\n",
      "entering parallel reduction\n",
      "150reducible edges remaining\n",
      "parallel reduction complete\n",
      "Reducing complex...\n",
      "67\n",
      "completed parallel reducer function\n",
      "writing to Outputs/k3_1.gml\n",
      "writing to Outputs/Normalizedk3_1.gml\n",
      "Time to process complex = 1.1260972023010254 seconds\n",
      "constructing cinf...\n",
      "Grid size is 5\n",
      "Defining U0, U1, U2, U3, U4, V0, V1, V2, V3, V4\n",
      "Time to construct cinf 0.03342318534851074\n",
      "grading complex...\n",
      "Time to find arborescence:0.0164034366607666\n",
      "Time to grade complex (given arborescence): 0.009777545928955078\n",
      "passing to parallel reducer\n",
      "entering parallel reduction\n",
      "150reducible edges remaining\n",
      "parallel reduction complete\n",
      "Reducing complex...\n",
      "48\n",
      "completed parallel reducer function\n",
      "writing to Outputs/mk3_1.gml\n",
      "writing to Outputs/Normalizedmk3_1.gml\n",
      "Time to process complex = 1.2055387496948242 seconds\n",
      "constructing cinf...\n",
      "Grid size is 6\n",
      "Defining U0, U1, U2, U3, U4, U5, V0, V1, V2, V3, V4, V5\n",
      "Time to construct cinf 0.2822248935699463\n",
      "grading complex...\n",
      "Time to find arborescence:0.14372801780700684\n",
      "Time to grade complex (given arborescence): 0.07957029342651367\n",
      "passing to parallel reducer\n",
      "entering parallel reduction\n",
      "1380reducible edges remaining\n",
      "599reducible edges remaining\n",
      "261reducible edges remaining\n",
      "parallel reduction complete\n",
      "Reducing complex...\n",
      "97\n",
      "completed parallel reducer function\n",
      "writing to Outputs/k4_1.gml\n",
      "writing to Outputs/Normalizedk4_1.gml\n",
      "Time to process complex = 12.543559074401855 seconds\n",
      "constructing cinf...\n",
      "Grid size is 7\n",
      "Defining U0, U1, U2, U3, U4, U5, U6, V0, V1, V2, V3, V4, V5, V6\n",
      "Time to construct cinf 2.7728567123413086\n",
      "grading complex...\n",
      "Time to find arborescence:2.59385347366333\n",
      "Time to grade complex (given arborescence): 0.6396362781524658\n",
      "passing to parallel reducer\n",
      "entering parallel reduction\n",
      "13176reducible edges remaining\n",
      "8146reducible edges remaining\n",
      "2520reducible edges remaining\n",
      "815reducible edges remaining\n",
      "307reducible edges remaining\n",
      "164reducible edges remaining\n",
      "117reducible edges remaining\n",
      "parallel reduction complete\n",
      "Reducing complex...\n",
      "60\n",
      "completed parallel reducer function\n",
      "writing to Outputs/k5_1.gml\n",
      "writing to Outputs/Normalizedk5_1.gml\n",
      "Time to process complex = 232.27715587615967 seconds\n",
      "constructing cinf...\n",
      "Grid size is 7\n",
      "Defining U0, U1, U2, U3, U4, U5, U6, V0, V1, V2, V3, V4, V5, V6\n",
      "Time to construct cinf 2.703157663345337\n",
      "grading complex...\n",
      "Time to find arborescence:1.2849385738372803\n",
      "Time to grade complex (given arborescence): 0.6188812255859375\n",
      "passing to parallel reducer\n",
      "entering parallel reduction\n",
      "16632reducible edges remaining\n",
      "9659reducible edges remaining\n",
      "3591reducible edges remaining\n",
      "1675reducible edges remaining\n",
      "528reducible edges remaining\n",
      "457reducible edges remaining\n",
      "390reducible edges remaining\n",
      "376reducible edges remaining\n",
      "190reducible edges remaining\n",
      "101reducible edges remaining\n",
      "parallel reduction complete\n",
      "Reducing complex...\n",
      "99\n",
      "completed parallel reducer function\n",
      "writing to Outputs/mk5_1.gml\n",
      "writing to Outputs/Normalizedmk5_1.gml\n",
      "Time to process complex = 767.8061299324036 seconds\n",
      "constructing cinf...\n",
      "Grid size is 7\n",
      "Defining U0, U1, U2, U3, U4, U5, U6, V0, V1, V2, V3, V4, V5, V6\n",
      "Time to construct cinf 3.0472214221954346\n",
      "grading complex...\n",
      "Time to find arborescence:2.6993038654327393\n",
      "Time to grade complex (given arborescence): 0.7871334552764893\n",
      "passing to parallel reducer\n",
      "entering parallel reduction\n",
      "14712reducible edges remaining\n",
      "8534reducible edges remaining\n",
      "5152reducible edges remaining\n",
      "1646reducible edges remaining\n",
      "1553reducible edges remaining\n",
      "1552reducible edges remaining\n",
      "1406reducible edges remaining\n",
      "1248reducible edges remaining\n",
      "1079reducible edges remaining\n",
      "432reducible edges remaining\n",
      "424reducible edges remaining\n",
      "402reducible edges remaining\n",
      "364reducible edges remaining\n",
      "354reducible edges remaining\n",
      "346reducible edges remaining\n",
      "334reducible edges remaining\n",
      "330reducible edges remaining\n",
      "273reducible edges remaining\n",
      "242reducible edges remaining\n",
      "235reducible edges remaining\n",
      "231reducible edges remaining\n",
      "182reducible edges remaining\n",
      "141reducible edges remaining\n",
      "132reducible edges remaining\n",
      "132reducible edges remaining\n",
      "118reducible edges remaining\n",
      "parallel reduction complete\n",
      "Reducing complex...\n",
      "100\n",
      "completed parallel reducer function\n",
      "writing to Outputs/k5_2.gml\n",
      "writing to Outputs/Normalizedk5_2.gml\n",
      "Time to process complex = 997.8977370262146 seconds\n",
      "constructing cinf...\n",
      "Grid size is 7\n",
      "Defining U0, U1, U2, U3, U4, U5, U6, V0, V1, V2, V3, V4, V5, V6\n",
      "Time to construct cinf 4.5555713176727295\n",
      "grading complex...\n",
      "Time to find arborescence:1.511420488357544\n",
      "Time to grade complex (given arborescence): 0.7594771385192871\n",
      "passing to parallel reducer\n",
      "entering parallel reduction\n",
      "14712reducible edges remaining\n",
      "8774reducible edges remaining\n",
      "2227reducible edges remaining\n",
      "886reducible edges remaining\n",
      "850reducible edges remaining\n",
      "670reducible edges remaining\n",
      "394reducible edges remaining\n",
      "373reducible edges remaining\n",
      "161reducible edges remaining\n",
      "112reducible edges remaining\n",
      "parallel reduction complete\n",
      "Reducing complex...\n",
      "69\n",
      "completed parallel reducer function\n",
      "writing to Outputs/mk5_2.gml\n",
      "writing to Outputs/Normalizedmk5_2.gml\n",
      "Time to process complex = 596.2187142372131 seconds\n",
      "constructing cinf...\n",
      "Grid size is 8\n",
      "Defining U0, U1, U2, U3, U4, U5, U6, U7, V0, V1, V2, V3, V4, V5, V6, V7\n",
      "Time to construct cinf 34.17942523956299\n",
      "grading complex...\n",
      "Time to find arborescence:18.578322410583496\n",
      "Time to grade complex (given arborescence): 9.789670467376709\n",
      "passing to parallel reducer\n",
      "entering parallel reduction\n",
      "168672reducible edges remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-640:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cdstclair/anaconda3/envs/sage/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/cdstclair/anaconda3/envs/sage/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_1382/180305607.py\", line 869, in subgraph_red_search\n",
      "    subgraph.graph_reduction(ed[Integer(0)], ed[Integer(1)])\n",
      "  File \"/tmp/ipykernel_1382/180305607.py\", line 231, in graph_reduction\n",
      "    self.comp.add_edge(x,y,diffweight=red_weight)\n",
      "  File \"/home/cdstclair/anaconda3/envs/sage/lib/python3.11/site-packages/networkx/classes/digraph.py\", line 648, in add_edge\n",
      "    def add_edge(self, u_of_edge, v_of_edge, **attr):\n",
      "    \n",
      "  File \"src/cysignals/signals.pyx\", line 310, in cysignals.signals.python_check_interrupt\n",
      "KeyboardInterrupt\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for link in knot_dict:\n",
    "    comp = link_GFC(*knot_dict[link], link)\n",
    "#     gfk.pickle_it(comp, (link + \"gfk.p\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp.gml_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_partition(2, -3, 12, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp.find_max_difference(\"AGrading1\")\n",
    "comp.max_grading_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for knot in knot_dict:\n",
    "#     comp = link_GFC(*knot_dict[knot], knot)\n",
    "#     gfk.pickle_it(comp, (knot + \"gfk.p\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = link_GFC(*knot_dict['k4_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = comp.parallel_single_split('AGrading', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp.find_max_difference('AGrading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp.max_grading_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp.find_grading_ranges('AGrading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp.max_gradings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp.min_gradings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict = {}\n",
    "mydict[\"test\"] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge in comp.comp.nodes():\n",
    "    print(comp.comp.nodes()[edge])\n",
    "    input(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "comp.comp.nodes()['[8, 2, 3, 7, 1, 5, 4, 6]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testcomp = comp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testcomp.grade_link_complex()\n",
    "input(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next((source, target, weight) for source, target, weight in comp.comp.edges(data = 'agrading0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfk.pickle_it(comp, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comp.surgery()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = link_GFC([7,2,3,4,5,6,1],[2,3,4,5,6,7,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comp.surgery()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comp.to_minus()\n",
    "comp.graph_red_search()\n",
    "comp.remove_zeros()\n",
    "comp.gml_export(\"HopefullyS3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(trefoil_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for knot specific variations - should be unnecessary\n",
    "\n",
    "def gml_export_weighted(self, filename = 'PleaseNameMe.gml'):\n",
    "\n",
    "    nxG = self.comp.copy()\n",
    "\n",
    "    if filename == 'PleaseNameMe.gml':\n",
    "        print(\"You didn't name your output! It's been named PleaseNameMe.gml\")\n",
    "\n",
    "    if filename[-4:] != \".gml\":\n",
    "        filename += \".gml\"\n",
    "\n",
    "    for x,y in nxG.edges():\n",
    "\n",
    "        nxG[x][y]['diffweight'] = str(nxG[x][y]['diffweight'])\n",
    "\n",
    "    for node in nxG.nodes():\n",
    "\n",
    "        #print(str((nxG.nodes()[node]['UGrading'],nxG.nodes()[node]['VGrading'],nxG.nodes()[node]['AGrading'])))\n",
    "\n",
    "        try:\n",
    "            nxG.nodes[node]['AGrading'] = int(nxG.nodes[node]['AGrading']) \n",
    "            nxG.nodes[node]['UGrading'] = int(nxG.nodes[node]['UGrading'])\n",
    "            nxG.nodes[node]['VGrading'] = int(nxG.nodes[node]['VGrading'])\n",
    "        except:\n",
    "            nxG.nodes[node]['AGrading'] = int(-99)\n",
    "            nxG.nodes[node]['UGrading'] = int(-99)\n",
    "            nxG.nodes[node]['VGrading'] = int(-99)\n",
    "\n",
    "    nx.write_gml(nxG, filename)\n",
    "\n",
    "    return\n",
    "\n",
    "def grade_complex(given_graph, given_field, gridX = -1):\n",
    "    \n",
    "    #Input: given_graph a networkx directed graph with 'diffweight' attribute on edges\n",
    "    #       given_field the laurent polynomial field associated to the grid graph\n",
    "    #       gridX a list representing the vertex to be graded 0 in U V and Alexander gradings\n",
    "    #\n",
    "    #Output: given_graph with new attributes on the vertices for U V and Alexander gradings\n",
    "    #        also an attribute HasBeenGraded as an artifact\n",
    "    \n",
    "    \n",
    "    #If the positions of the Xs aren't provided we'll initialize around whatever\n",
    "    #state happens to appear first in the digraph structure\n",
    "    if gridX == -1:\n",
    "        \n",
    "        gridX = list(given_graph.nodes())[0]\n",
    "    \n",
    "    gens = given_field.gens()\n",
    "    size = len(gens)/2 \n",
    "\n",
    "    print(\"grading complex...\")\n",
    "    \n",
    "    #Adding an attribute to all nodes to keep track of if they've been assigned gradings\n",
    "    nx.set_node_attributes(given_graph, False, \"HasBeenGraded\")\n",
    "    \n",
    "    #The gradings are relative so we're declaring one to be in U, V, and Alexander grading 0\n",
    "    #this block initializes those balues\n",
    "    given_graph.nodes()[str(gridX)]['HasBeenGraded'] = True\n",
    "    given_graph.nodes()[str(gridX)]['AGrading'] = 0\n",
    "    given_graph.nodes()[str(gridX)]['UGrading'] = 0\n",
    "    given_graph.nodes()[str(gridX)]['VGrading'] = 0\n",
    "    \n",
    "    if TIMERS: timerstart = time.time()\n",
    "\n",
    "    #Built in function to find a spanning tree\n",
    "    #span = nx.algorithms.tree.branchings.greedy_branching(given_graph)\n",
    "    \n",
    "    tree = nx.algorithms.minimum_spanning_tree( given_graph.to_undirected()  )\n",
    "    eds = set(tree.edges())  # Issues with functions finding directed spanning set - insteada we find an undirected one then direct it\n",
    "    spanset = []\n",
    "    \n",
    "    for edge in eds:\n",
    "        \n",
    "        if edge in given_graph.edges():\n",
    "            spanset.append(edge)\n",
    "            \n",
    "        else:\n",
    "            spanset.append((edge[1],edge[0]))\n",
    "        \n",
    "    span = given_graph.edge_subgraph(spanset)\n",
    "        \n",
    "    if TIMERS:\n",
    "        \n",
    "        timerstop = time.time()\n",
    "        print(\"Time to find arborescence:\" + str(timerstop - timerstart))\n",
    "    \n",
    "    #Bit of baseball terminology for the following nested loops, the active data is essentially at bat, the list we're working\n",
    "    #through is called on_deck, and then we're building up the follow up as in_the_hole which will turn into\n",
    "    #on deck on the following loop\n",
    "    #\n",
    "    #On deck holds the edges to be iterated through\n",
    "    on_deck = [str(gridX)]\n",
    "    \n",
    "    #In the hole holds the ones to be iterated through once on_deck is cleared\n",
    "    in_the_hole = []\n",
    "    \n",
    "    if TIMERS: timerstart = time.time()\n",
    "    \n",
    "    while len(on_deck) > 0: \n",
    "               \n",
    "        for vert in on_deck:\n",
    "\n",
    "            #Every vertex in on_deck should be graded. The loops iterate through the neighbors of each of these\n",
    "            #vertices, grading them and then adding them to in_the_hole, ignoring vertices that have already been graded.\n",
    "            #\n",
    "            #The loop is broken into two halves since we have two flavors of neighbor in a directed graph, successors and\n",
    "            #predecessors, named accordingly. These flavors differ in relative grading change by a sign.\n",
    "            for succ in span.successors(vert): \n",
    "                \n",
    "                #skip the vertex if its already been graded\n",
    "                if given_graph.nodes()[succ]['HasBeenGraded']: continue\n",
    "                    \n",
    "                in_the_hole.append(succ)\n",
    "                \n",
    "                ed_weight = given_graph[vert][succ]['diffweight']\n",
    "                \n",
    "                #set the maslov (homological) gradings\n",
    "                Upows = U_deg(ed_weight, given_field)\n",
    "                given_graph.nodes()[succ]['UGrading'] = given_graph.nodes()[vert]['UGrading'] - 1 + 2*Upows\n",
    "\n",
    "                Vpows = V_deg(ed_weight, given_field)\n",
    "                given_graph.nodes()[succ]['VGrading'] = given_graph.nodes()[vert]['VGrading'] - 1 + 2*Vpows\n",
    "\n",
    "                #Alexander grading is a function of the U and V grading, set here\n",
    "                given_graph.nodes()[succ]['AGrading'] = (1/2)*(given_graph.nodes()[succ]['UGrading']-given_graph.nodes()[succ]['VGrading'])\n",
    "\n",
    "                given_graph.nodes()[succ]['HasBeenGraded'] = True\n",
    "\n",
    "            for pred in span.predecessors(vert):\n",
    "                \n",
    "                if given_graph.nodes()[pred]['HasBeenGraded']: continue\n",
    "                in_the_hole.append(pred)\n",
    "                ed_weight = given_graph[pred][vert]['diffweight']\n",
    "                \n",
    "                #set the maslov (homological) gradings, note the negative grading change since we're following an arrow backwards.\n",
    "                Upows = U_deg(ed_weight, given_field)\n",
    "                given_graph.nodes()[pred]['UGrading'] = given_graph.nodes()[vert]['UGrading'] + 1 - 2*Upows       \n",
    "\n",
    "                Vpows = V_deg(ed_weight, given_field)\n",
    "                given_graph.nodes()[pred]['VGrading'] = given_graph.nodes()[vert]['VGrading'] + 1 - 2*Vpows\n",
    "\n",
    "                given_graph.nodes()[pred]['AGrading'] = (1/2)*(given_graph.nodes()[pred]['UGrading']-given_graph.nodes()[pred]['VGrading'])\n",
    "                given_graph.nodes()[pred]['HasBeenGraded'] = True\n",
    "                \n",
    "        on_deck = in_the_hole\n",
    "        in_the_hole =[]\n",
    "        \n",
    "    if TIMERS:\n",
    "        \n",
    "        timerstop = time.time()\n",
    "        print('Time to grade complex (given arborescence): ' + str(timerstop - timerstart))\n",
    "    \n",
    "    return given_graph\n",
    "            \n",
    "\n",
    "    \n",
    "def U_deg(poly, field):\n",
    "    \n",
    "    #Input: poly a laurent polynomial (must be  a monomial) in field a laurent polynomial ring\n",
    "    #\n",
    "    #Output: The total sum of powers of Ui in poly\n",
    "    \n",
    "    gens = field.gens()\n",
    "    size = len(gens)/2\n",
    "    degree = 0\n",
    "    \n",
    "    if type(poly) == sage.rings.finite_rings.integer_mod.IntegerMod_int: return 0\n",
    "    \n",
    "    powers = poly.exponents()   \n",
    "    \n",
    "    #len(powers) tells you how many terms the polynomial has\n",
    "#     if len(powers) > 1:\n",
    "        \n",
    "#         print(poly)\n",
    "        \n",
    "#         raise Exception(\"Ran into a non-homogoneous degree change - polynomial wasn't a monomial\")\n",
    "\n",
    "    if len(powers) == 0:\n",
    "        \n",
    "        return 0    \n",
    "    \n",
    "    #powers is a list of lists since its intended for more than just monomials, since we are guaranteeing\n",
    "    #a monomial at this point we'll just lift that inner list out\n",
    "    powers = powers[0]\n",
    "    \n",
    "    for i in range(size):\n",
    "        \n",
    "        degree = degree + powers[i]\n",
    "    \n",
    "    return degree\n",
    "\n",
    "    \n",
    "def V_deg(poly, field):\n",
    "    \n",
    "    #Input: poly a laurent polynomial (must be  a monomial) in field a laurent polynomial ring\n",
    "    #\n",
    "    #Output: The total sum of powers of Ui in poly    \n",
    "    \n",
    "    gens = field.gens()\n",
    "    size = len(gens)/2\n",
    "    degree = 0\n",
    "    \n",
    "    if type(poly) == sage.rings.finite_rings.integer_mod.IntegerMod_int: return 0\n",
    "    \n",
    "    powers = poly.exponents()   \n",
    "    \n",
    "    #len(powers) tells you how many terms the polynomial has    \n",
    "#     if len(powers) > 1:\n",
    "        \n",
    "#         print(poly)\n",
    "#         raise Exception(\"Ran into a non-homogoneous degree change - polynomial wasn't a monomial\")\n",
    "\n",
    "    if len(powers) == 0:\n",
    "        \n",
    "        return 0    \n",
    "    \n",
    "    #powers is a list of lists since its intended for more than just monomials, since we are guaranteeing\n",
    "    #a monomial at this point we'll just lift that inner list out    \n",
    "    powers = powers[0]\n",
    "    for i in range(size):\n",
    "        \n",
    "        degree = degree + powers[size + i]\n",
    "    \n",
    "    return degree    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GFC(sigx, sigo, filename = None):\n",
    "    \n",
    "    if filename == None:\n",
    "        filename = \"X\"\n",
    "        for pos in sigx:\n",
    "            filename = filename + str(pos)\n",
    "        filename = filename + \"O\"\n",
    "        for pos in sigo:\n",
    "            filename = filename + str(pos)\n",
    "        filename = filename + \".gml\"\n",
    "    \n",
    "    components = link_components(sigx, sigo)\n",
    "    link_count = len(components)\n",
    "    if link_count != 1: raise Exception(\"!!!More than one component in this diagram - call the link version of ths function HFL!!!\")\n",
    "    raw_complex = gfk.build_cinf([sigx, sigo])\n",
    "    comp, defield = construct_cinf(raw_complex)\n",
    "    \n",
    "    grade_complex(comp, defield, sigo)\n",
    "    \n",
    "    graph_red_search(comp)\n",
    "    \n",
    "    gml_export_weighted(comp, filename)\n",
    "    \n",
    "    normalize(comp, defield)\n",
    "    graph_red_search(comp)\n",
    "    remove_zeros(comp)\n",
    "    \n",
    "    norm_filename = \"Normalized\" + filename\n",
    "    \n",
    "    gml_export_weighted(comp, norm_filename)\n",
    "    \n",
    "    minusinator = comp.copy()\n",
    "    \n",
    "    to_minus(minusinator, defield)\n",
    "    \n",
    "    graph_red_search(minusinator)\n",
    "    remove_zeros(minusinator)\n",
    "    minus_filename = \"Minus\" + filename\n",
    "    \n",
    "    gml_export_weighted(minusinator, minus_filename)\n",
    "    \n",
    "    return grid_complex(comp, defield)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Braid code - not necessary at present - will be nice later\n",
    "\n",
    "#converting braid notation to a grid --- this is not a unique choice in general so we're going to make some decisions\n",
    "\n",
    "class braid:\n",
    "    \n",
    "    def __init__(self, recipe, size = 0):\n",
    "        if size == 0:\n",
    "            candidate1 = max(recipe)\n",
    "            candidate2 = abs(min(recipe))\n",
    "            size = max([candidate1,candidate2])+1\n",
    "        self.strands = []\n",
    "        for i in range(1, size+1):\n",
    "            self.strands.append(i)\n",
    "        self.recipe = recipe\n",
    "        self.size = size    \n",
    "        \n",
    "def braid_to_cromwell(given):\n",
    "    n = given.size\n",
    "    closing_heights = []\n",
    "    for i in range(n):\n",
    "        closing_heights.append(i+1)\n",
    "    cromwell = [] #We're going to keep track of corners of the knot as a cromwell matrix (0's and 1's) and track the ones here by marking the two heights\n",
    "                  #for example [[3,1],[2,3],[1,2]] contains the information for a 3x3. The Cromwell matrix won't see the sub-ordering\n",
    "    strands = given.strands.copy()\n",
    "    for sig in given.recipe:\n",
    "        new_entry = crom_twist(sig, strands, cromwell, closing_heights)\n",
    "        cromwell.append(new_entry)\n",
    "    for i in range(len(strands)):\n",
    "        if strands[i] != closing_heights[i]:\n",
    "            cromwell.append([closing_heights[i],strands[i]])\n",
    "    return cromwell\n",
    "\n",
    "def crom_twist(bmove, strings, current_crom, closing_ht):\n",
    "    coord = []\n",
    "    n = len(strings)\n",
    "    if bmove > 0:\n",
    "        lower = strings[bmove-1]\n",
    "        upper = strings[bmove]\n",
    "        for i in range(len(current_crom)):     #move previous cromwell stuff up to make room as below\n",
    "            crom_twist_helper_pos(current_crom[i], lower, upper)\n",
    "        for i in range(bmove+1, n):            #move the strands up to make room for rectilinear braid move\n",
    "            strings[i] += 1\n",
    "        for i in range(len(closing_ht)):\n",
    "            if closing_ht[i] > upper:\n",
    "                closing_ht[i] += 1\n",
    "        cm1 = [strings[bmove-1],strings[bmove]+1] #\\/\\/\\/this is where the braid move actually \"happens\" \\/\\/\\/\n",
    "        strings[bmove-1] = strings[bmove]\n",
    "        strings[bmove] = strings[bmove] + 1\n",
    "    elif bmove < 0:\n",
    "        bmove = (-1)*bmove\n",
    "        lower = strings[bmove-1]\n",
    "        upper = strings[bmove]\n",
    "        for i in range(len(current_crom)):     #move previous cromwell stuff up to make room as below\n",
    "            crom_twist_helper_neg(current_crom[i], lower, upper)\n",
    "        for i in range(bmove-1, n):            #move the strands up to make room for rectilinear braid move\n",
    "            strings[i] += 1\n",
    "        for i in range(len(closing_ht)):\n",
    "            if closing_ht[i] >= lower:\n",
    "                closing_ht[i] += 1\n",
    "        cm1 = [strings[bmove],strings[bmove-1]-1] #\\/\\/\\/this is where the braid move actually \"happens\" \\/\\/\\/\n",
    "        strings[bmove] = strings[bmove - 1]\n",
    "        strings[bmove-1] = strings[bmove - 1] - 1\n",
    "    else:\n",
    "        print(\"invalid braid move\")\n",
    "    return cm1\n",
    "\n",
    "def crom_twist_helper_neg(crom_pair, lower, upper):\n",
    "    for i in range(2):\n",
    "        if crom_pair[i] >= lower:\n",
    "            crom_pair[i] += 1\n",
    "    return\n",
    "\n",
    "def crom_twist_helper_pos(crom_pair, lower, upper):\n",
    "    for i in range(2):\n",
    "        if crom_pair[i] > upper:\n",
    "            crom_pair[i] += 1\n",
    "    return\n",
    "\n",
    "def cromwell_to_grid(cromwell_pairs):\n",
    "    n = len(cromwell_pairs)\n",
    "    xhold = []\n",
    "    ohold = []\n",
    "    for i in range(n):\n",
    "        xhold.append(0)\n",
    "        ohold.append(0)\n",
    "#     print(cromwell_pairs)\n",
    "    xhold[0] = cromwell_pairs[0][0]\n",
    "    ohold[0] = cromwell_pairs[0][1]\n",
    "    count = 2\n",
    "    cromwell_pairs[0] = [-1,-1]\n",
    "    while count < 2*n:\n",
    "        for i in range(n):\n",
    "            for j in range(2):\n",
    "                if ((cromwell_pairs[i][j] in xhold)and (not(cromwell_pairs[i][j] in ohold))):\n",
    "                    ohold[i] = cromwell_pairs[i][j]\n",
    "                    xhold[i] = cromwell_pairs[i][j-1]\n",
    "                    cromwell_pairs[i] = [-1,-1]\n",
    "                    count += 2\n",
    "                elif ((cromwell_pairs[i][j] in ohold)and (not(cromwell_pairs[i][j] in xhold))):\n",
    "                    xhold[i] = cromwell_pairs[i][j]\n",
    "                    ohold[i] = cromwell_pairs[i][j-1]\n",
    "                    cromwell_pairs[i] = [-1,-1]\n",
    "                    count += 2\n",
    "    return (xhold,ohold)\n",
    "\n",
    "def grid_from_braid(bnotation):\n",
    "    \n",
    "    br = braid(bnotation)\n",
    "    crom = braid_to_cromwell(br)\n",
    "    xlist, olist = cromwell_to_grid(crom)\n",
    "    return xlist, olist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLD CODE\n",
    "\n",
    "# file = open(\"TrefoilComplex.csv\")\n",
    "# csvreader = csv.reader(file)\n",
    "# header = []\n",
    "# header = next(csvreader)\n",
    "\n",
    "# rows = []\n",
    "\n",
    "# for row in csvreader:\n",
    "#     rows.append(row)\n",
    "#     print(row)\n",
    "\n",
    "\n",
    "# file.close()\n",
    "\n",
    "# def comp_from_pickle(filename = 'DefaultPickleComp', grade = True):\n",
    "    \n",
    "# # GFK toolkit has the ability to export its raw complex as a pickle file, this imports those files, then constructs cinf. \n",
    "# # Largely unnecessary if calling from the imported GFK directly\n",
    "\n",
    "#     graph, size, knot = imp_from_pickle(filename)\n",
    "#     print(\"Grid complex imported with grid number = \" + str(size))\n",
    "#     nxg, defield = construct_cinf(graph, size)\n",
    "#     if grade:\n",
    "#         print('proceeding to grade complex.')\n",
    "#         nxg = grade_complex(nxg, defield)\n",
    "    \n",
    "#     return nxg, defield\n",
    "\n",
    "# def imp_from_pickle(filename = 'DefaultPickle'):\n",
    "    \n",
    "# # Imports pickle file and returns the object. Will import from DefaultPickleComp if no name is provided\n",
    "    \n",
    "#     if filename == 'DefaultPickleComp':\n",
    "#         print('No name provided for import - importing from DefaultPickleComp')\n",
    "    \n",
    "    \n",
    "#     try:\n",
    "#         file = open(filename,'rb')\n",
    "#         print(\"file opened\")\n",
    "#     except:\n",
    "#         print('Ran into an error: Make sure you\\'ve exported to the file you\\'re trying to import from')\n",
    "#     stuff = pickle.load(file)\n",
    "#     file.close()\n",
    "#     print('file closed')\n",
    "#     return stuff\n",
    "\n",
    "# def reduce_around(M, position): \n",
    "# #M isa matrix and position is a pair [a,b] where a 1 is located\n",
    "# #function does Gauss-Jordan-ish elimination on that column and in a symmetric way to the entry's row\n",
    "#     a,b = position\n",
    "#     #First step is to use the row to cancel the other entries, then we'll do a symmetric cancellation on\n",
    "#     #the columns as well\n",
    "#     column = M[:][b]\n",
    "#     for index, entry in enumerate(column):\n",
    "#         if ((index != 0) and (index != a) and (entry != 0)):\n",
    "#             M.add_multiple_of_row(index, entry, a)\n",
    "#     for index, entry in enumerate(column):\n",
    "#         if ((index != 0) and (index != a) and (entry != 0)):\n",
    "#             M.add_multiple_of_col(index, entry, b)\n",
    "#     #Now we'll repeat the process but with the row entries\n",
    "#     row = M[a][:]\n",
    "#     for index, entry in enumerate(row):\n",
    "#         if ((index != 0) and (index != b) and (entry != 0)):\n",
    "#             M.add_multiple_of_col(index, entry, b)\n",
    "#     for index, entry in enumerate(column):\n",
    "#         if ((index != 0) and (index != b) and (entry != 0)):\n",
    "#             M.add_multiple_of_row(index, entry, a)\n",
    "#     return\n",
    "\n",
    "# def hom_reduction(adj_mat):\n",
    "#     M = adj_mat\n",
    "#     row_position = 0\n",
    "#     for row in M:\n",
    "#         check, column_position = row_count(row)\n",
    "#         if row_count(check[0]) > 1:\n",
    "#             reduce_around(M, row_position, column_position)\n",
    "#         row_position = position + 1\n",
    "\n",
    "\n",
    "\n",
    "# def cinf_coeff(size):\n",
    "#     n = size\n",
    "#     varis = name_some_vars(['U','V'],n)\n",
    "#     F = LaurentPolynomialRing(GF(2), varis)\n",
    "#     F.inject_variables()\n",
    "# #     preF = LaurentPolynomialRing(GF(2), 'U', n) #F[Ui+-] which we'll then pair up with the Vi\n",
    "# #     preF.inject_variables()                     #Telling Sage we have Ui's as variables\n",
    "# #     Vars = preF.gens()                          #storing the variables in a list - not currently implemented anywhere\n",
    "# #     for vari in preF.gens():\n",
    "# #         preF.<vari> = preF\n",
    "# #     F = LaurentPolynomialRing(preF, 'V', n)     #Takes our preF (F[Ui+-]) and adjoins Vi\n",
    "# #     F.inject_variables()                        #F only thinks it has Vi as variables, we tell Sage about it\n",
    "# #     Vars = Vars + F.gens()\n",
    "# #     for vari in F.gens():\n",
    "# #        F.<vari> = F\n",
    "# #     for vari in Vars: \n",
    "# #         F.<vari> = F    \n",
    "#     return F,list(F.gens())\n",
    "\n",
    "# def find_one(targetlist): #Searches a list for first 1 - will be used for reduction\n",
    "# #     print(\"searching for 1 in\" + str(targetlist))\n",
    "#     if 1 in list(targetlist):\n",
    "        \n",
    "# #         print(\"found 1 in the list at\" + str(list(targetlist).index(1)))\n",
    "#         return list(targetlist).index(1)\n",
    "\n",
    "#     return -1\n",
    "\n",
    "# def find_col_with_one(matrix, startc=0):\n",
    "    \n",
    "#     endc = len(matrix[0])\n",
    "#     print(str(endc))\n",
    "#     for n in range(startc, endc):\n",
    "        \n",
    "#         search_result = find_one(matrix[:][n])\n",
    "#         if search_result != -1: return (search_result, n)\n",
    "        \n",
    "#     return (-1, -1)\n",
    "\n",
    "\n",
    "# def reduction_remap(matrix, row, col):\n",
    "#     n = len(matrix[0])\n",
    "#     range1 = range_skip_entry(n, row)\n",
    "# #     print(\"searching through \" + str(range1))\n",
    "#     for count, target_row in enumerate(range1):\n",
    "        \n",
    "#         entry = matrix[target_row][col]\n",
    "#         if entry != 0: my_row_add(matrix, row, target_row, entry)\n",
    "            \n",
    "#     return matrix\n",
    "\n",
    "# def row_col_del(matrix, loc):\n",
    "#     newrange = list(range(len(matrix[0])))\n",
    "#     del newrange[loc]\n",
    "#     return matrix[newrange,newrange]\n",
    "\n",
    "# def construct_sageG_cinf(g, size = -1): #Construct CFKinf complex from graph data - essentially just changing weights to polynomials\n",
    "#                                   #Only works for grid diagrams *not* Latin Squares\n",
    "#     #DEPRECATED None of the current pipelines are using sage graphs\n",
    "#     if size == -1:\n",
    "#         size = len(g.get_edge_data(list(g.edges())[0][0],list(g.edges())[0][1])['diffweight'])  #kind of a mess - just turning the edges\n",
    "#     n = size/2                                                                              #into a list and checking the length of\n",
    "#                                                                                             #the weight of the first edge\n",
    "#     F,Vars = cinf_coeff(n)\n",
    "#     resG = DiGraph()\n",
    "#     for edge in g.edges:\n",
    "        \n",
    "#         start = edge[0]\n",
    "#         end = edge[1]\n",
    "#         poly = F(1)\n",
    "#         i = 0\n",
    "#         for entry in g[edge[0]][edge[1]]['diffweight']:\n",
    "            \n",
    "#             poly = poly*(Vars[i])**entry\n",
    "#             i = i + 1\n",
    "            \n",
    "#         resG.add_edge(start, end, poly)\n",
    "        \n",
    "#     return resG\n",
    "\n",
    "# def convert_gml(fileName): #GridToolsTBD exports to a text file - this grabs it and converts the edges back to lists\n",
    "#                            #super inneficient - should convert to pickle file system or something\n",
    "#     g = nx.read_gml(fileName)\n",
    "#     for edge in g.edges:\n",
    "#         g[edge[0]][edge[1]]['diffweight'] = ast.literal_eval(g[edge[0]][edge[1]]['weight'])\n",
    "#         g[edge[0]][edge[1]]['diffweight'] = g[edge[0]][edge[1]]['diffweight'][0]+g[edge[0]][edge[1]]['diffweight'][1] #end result is edge weights as list of\n",
    "#                                                                                                           #multiplicities [U1,U2...,Un,V1,...,Vn]\n",
    "#     return g\n",
    "\n",
    "# def imp_and_construct_complex(filename):\n",
    "    \n",
    "#     #Input: Filename string for a file\n",
    "    \n",
    "#     print('importing complex...')\n",
    "#     g = convert_gml(filename)\n",
    "#     return construct_cinf(g)\n",
    "\n",
    "# def reduction(matrix):\n",
    "#     col, row = find_col_with_one(matrix)\n",
    "# #     print(\"reducing around entry \" +str(row) + \",\" +str(col))\n",
    "#     if col == -1:\n",
    "        \n",
    "#         print(\"completed reduction\")\n",
    "#         print(matrix)\n",
    "#         print (type(matrix))\n",
    "#         return matrix\n",
    "    \n",
    "#     print(\"reduction in progress\")\n",
    "#     remapped_matrix = reduction_remap(matrix, row, col)\n",
    "#     if row < col:\n",
    "        \n",
    "#         remapped_matrix = row_col_del(remapped_matrix, col)\n",
    "#         remapped_matrix = row_col_del(remapped_matrix, row)\n",
    "        \n",
    "#     else:\n",
    "        \n",
    "#         remapped_matrix = row_col_del(remapped_matrix, row)\n",
    "#         remapped_matrix = row_col_del(remapped_matrix, col)\n",
    "        \n",
    "#     return reduction(remapped_matrix)\n",
    "    \n",
    "# def my_row_add(matrix, row, targetrow, multiple):\n",
    "#     n = len(matrix[0])\n",
    "#     for i in range(n):\n",
    "#         current_src = matrix[row][i]\n",
    "#         if current_src != 0:\n",
    "# #             print(\"adding copies times \" + str(current_src))\n",
    "# #             print(\"multiple\" + str(multiple))\n",
    "# #             print(\"target entry \" + str(matrix[targetrow][i]))\n",
    "#             matrix[targetrow,i] = matrix[targetrow][i] + multiple*current_src\n",
    "# #         print(matrix)\n",
    "#     return matrix\n",
    "\n",
    "\n",
    "# def alex_power_change(poly, field):\n",
    "    \n",
    "#     gens = field.gens()\n",
    "#     size = len(gens)/2\n",
    "#     grade = 0\n",
    "#     powers = poly.exponents()\n",
    "#     if len(powers) > 1:\n",
    "        \n",
    "#         raise Exception(\"Ran into a non-homogoneous degree change - polynomial wasn't a monomial\")\n",
    "\n",
    "#     if len(powers) == 0:\n",
    "        \n",
    "#         return 0\n",
    "        \n",
    "#     powers = powers[0]\n",
    "#     for i in range(size):\n",
    "        \n",
    "#         grade = grade - powers[i] + powers[i+size]\n",
    "        \n",
    "#     return grade\n",
    "\n",
    "# def mod_out_uv(chain_comp, field):\n",
    "#     gens = field.gens()\n",
    "#     size = len(gens)/2    \n",
    "#     for edge in chain_comp.edges():\n",
    "    \n",
    "#         for i in range(size):\n",
    "            \n",
    "#             src = edge[0]\n",
    "#             tar = edge[1]\n",
    "# #             print(gens[0])\n",
    "# #             print(gens[size])\n",
    "# #             print(chain_comp[src][tar]['diffweight'])\n",
    "#             chain_comp[src][tar]['diffweight'] = chain_comp[src][tar]['diffweight'].subs({gens[i]:gens[0]})\n",
    "#             chain_comp[src][tar]['diffweight'] = chain_comp[src][tar]['diffweight'].subs({gens[size+i]:gens[size]})\n",
    "#         print(chain_comp[src][tar]['diffweight'])\n",
    "\n",
    "            \n",
    "#     return 1\n",
    "\n",
    "# def U_to_zero(chain_comp, field):\n",
    "# #Substitutes 0 for all the Ui\n",
    "    \n",
    "#     print(\"normalizing Vi's to i = 0 and Ui = 0\")\n",
    "#     gens = field.gens()\n",
    "#     size = len(gens)/2    \n",
    "#     for edge in chain_comp.edges():\n",
    "    \n",
    "#         for i in range(size):\n",
    "            \n",
    "#             src = edge[0]\n",
    "#             tar = edge[1]\n",
    "#             chain_comp[src][tar]['diffweight'] = chain_comp[src][tar]['diffweight'].subs({gens[i]:0})\n",
    "#             chain_comp[src][tar]['diffweight'] = chain_comp[src][tar]['diffweight'].subs({gens[i+size]:gens[size]})\n",
    "            \n",
    "#     remove_zeros(chain_comp)\n",
    "#     return 1\n",
    "\n",
    "# def remove_loops(givengraph, overwrite = True):\n",
    "    \n",
    "#     if overwrite:\n",
    "#         graph = givengraph\n",
    "#     else:\n",
    "#         graph = givengraph.copy()\n",
    "    \n",
    "#     for ed in list(graph.edges()):\n",
    "#         try:\n",
    "#             out = graph.edges()(ed[0],ed[1])\n",
    "#             back = graph.edges()[ed[1],ed[0]]\n",
    "#             graph.remove_edge(ed[0],ed[1])\n",
    "#             graph.remove_edge(ed[1],ed[0])\n",
    "#         except KeyError:\n",
    "#             continue\n",
    "            \n",
    "#     return graph\n",
    "\n",
    "# def remove_NU_loops(givengraph, overwrite = True):\n",
    "    \n",
    "#     if overwrite:\n",
    "#         graph = givengraph\n",
    "#     else:\n",
    "#         graph = givengraph.copy()\n",
    "    \n",
    "#     for ed in list(graph.edges()):\n",
    "#         try:\n",
    "#             out = graph.edges()(ed[0],ed[1])\n",
    "#             back = graph.edges()[ed[1],ed[0]]\n",
    "#             if graph[ed[0]][ed[1]]['diffweight'] == 1:\n",
    "#                 continue\n",
    "#             if graph[ed[1]][ed[0]]['diffweight'] == 1:\n",
    "#                 continue\n",
    "#             graph.remove_edge(ed[0],ed[1])\n",
    "#             graph.remove_edge(ed[1],ed[0])\n",
    "#         except KeyError:\n",
    "#             continue\n",
    "            \n",
    "#     return graph\n",
    "\n",
    "# def mod_out_nonVar0(chain_comp, field):\n",
    "\n",
    "# #     print(\"setting Ui's and Vi's = 0\")\n",
    "#     gens = field.gens()\n",
    "#     size = len(gens)/2    \n",
    "#     for edge in chain_comp.edges():\n",
    "    \n",
    "#         for i in range(1,size):\n",
    "            \n",
    "#             src = edge[0]\n",
    "#             tar = edge[1]\n",
    "#             chain_comp[src][tar]['diffweight'] = chain_comp[src][tar]['diffweight'].subs({gens[i]:0})\n",
    "\n",
    "#         for i in range(size+1,2*size):\n",
    "\n",
    "#             src = edge[0]\n",
    "#             tar = edge[1]\n",
    "#             chain_comp[src][tar]['diffweight'] = chain_comp[src][tar]['diffweight'].subs({gens[i]:0})\n",
    "\n",
    "#     return 1\n",
    "\n",
    "\n",
    "# iterate through dictionary keys(dict)\n",
    "#     tracker = -1\n",
    "#     for target in keydic\n",
    "#         if target weight == 1\n",
    "#             graph reduction alg\n",
    "#             tracker = 1\n",
    "#     if tracker == 1\n",
    "#         return rerun\n",
    "#     else\n",
    "#         return\n",
    "        \n",
    "# graph reduction(dict, key, target)\n",
    "#     for x in predecessors(target)\n",
    "#         if x == key: continue\n",
    "#         for y in successors(key)\n",
    "#             if y == target: continue\n",
    "#             x_weight = thegraph[x][targ]['weight']\n",
    "#             y_weight = thegraph[key][y]['weight']\n",
    "#             W = x_weight x y_weight\n",
    "#             add edge to graph from x to y weight = W\n",
    "#     delete key\n",
    "#     delete target\n",
    "#     return graph\n",
    "\n",
    "    \n",
    "    \n",
    "#     def surgery_helper(self, grading_levels, target_levels):\n",
    "# #REWRITE IN PROGRESS - CURRENTLY 90% OF ORIGINAL KNOT VERSION. UPDATING TO LINK AND SELF REFERENCE VERSION.\n",
    "#         #Input: grading_levels ex: [2,3,1,1] would be asking for the subcomplex of GFC with A0 <= 2, A1 <=3 etc.\n",
    "\n",
    "#         if len(grading_levels) != len(self.components)\n",
    "#             raise(\"!!Cannot compute surgered complex without grading cutoff information for each Alexander multigrading!!\")\n",
    "#         working_comp = self.comp.copy()\n",
    "\n",
    "#         surgery_collection = []\n",
    "\n",
    "#         if ((min_grading == None) or (max_grading == None)):\n",
    "\n",
    "#             min_grading, max_grading = grading_range(chain_comp)\n",
    "\n",
    "#         for grading in range(max_grading+1,min_grading-1, -1): #Theres room to improve here - likely don't need +-2 buffer\n",
    "\n",
    "#             surgery_collection.append([f\"surgery{grading}\",working_comp.copy()])\n",
    "#             comp_truncate(!!!!!)\n",
    "\n",
    "#         for name, comp in surgery_collection:\n",
    "\n",
    "#             to_minus(comp, !!!!!)\n",
    "#             remove_zeros(comp)\n",
    "#             graph_red_search(comp)\n",
    "\n",
    "#         return surgery_collection \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     comp.find_max_difference(\"AGrading\")\n",
    "    \n",
    "    \n",
    "#     for key in comp.max_grading_changes.keys():\n",
    "        \n",
    "#         comp.find_max_difference(key)\n",
    "    \n",
    "#     split_key = \"AGrading\"\n",
    "    \n",
    "#     for key in comp.max_grading_changes.keys():\n",
    "        \n",
    "#         if comp.max_grading_changes[key] < comp.max_grading_changes[split_key]:\n",
    "            \n",
    "#             split_key = key\n",
    "#     print(comp.max_grading_changes)\n",
    "#     print(\"splitting along \" + split_key + \" with max step = \" + str(comp.max_grading_changes[split_key]))\n",
    "# #     comp.graph_red_search()\n",
    "\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "SageMath 10.2",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
