{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools as itools\n",
    "import networkx as nx\n",
    "import csv\n",
    "# import ast\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "#from sage.graphs.graph_decompositions.graph_products import is_cartesian_product\n",
    "import CodeModules.GFKTools as gfk\n",
    "from CodeModules.GridPermutations import *\n",
    "import time\n",
    "import pickle\n",
    "import CodeModules.perm as pr\n",
    "from multiprocessing.managers import BaseManager\n",
    "import random as rd\n",
    "\n",
    "\n",
    "TIMERS = True\n",
    "PROCESSOR_COUNT = 12\n",
    "OUTPUTDIRECTORY = 'Outputs/'\n",
    "PRINT_PROGRESS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:53:32) [GCC 12.3.0]'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyManager(BaseManager):\n",
    "    \n",
    "    pass\n",
    "\n",
    "class grid_complex:\n",
    "    \n",
    "    #This is the data type that holds all the information and most of the functions and methods necessary\n",
    "    #to produce and manipulate the graded complex.\n",
    "    \n",
    "    def __init__(self, directed_graph, rng, sigx = None, sigo = None):\n",
    "    \n",
    "    #Initializing and setting default values. sigx and sigo should generally be provided - fail safes are included\n",
    "    #however if they're ever used then only the relative grading of the final object will be correct\n",
    "    \n",
    "        if type(directed_graph) != nx.DiGraph:\n",
    "            raise(\"!This data type only supports networkx digraphs!\")\n",
    "        \n",
    "        self.comp = directed_graph\n",
    "        self.ring = rng\n",
    "        self.min_gradings = {}\n",
    "        self.max_gradings = {}\n",
    "        self.max_grading_changes = {}\n",
    "        self.sigx = sigx\n",
    "        self.sigo = sigo\n",
    "        self.set_to_minus = False\n",
    "        \n",
    "        #From here the values necessary for the surgered manifold gradings are mapped out\n",
    "        \n",
    "        if (sigx != None) and (sigo != None):\n",
    "            self.size = len(sigx)\n",
    "            self.components = link_components(sigx, sigo)\n",
    "            for i in range(len(self.components)):\n",
    "\n",
    "                key = f'AGrading{i}'\n",
    "                self.min_gradings[key] = 0\n",
    "                self.max_gradings[key] = 0\n",
    "                self.max_grading_changes[key] = 0\n",
    "                key = f'UGrading{i}'\n",
    "                self.min_gradings[key] = 0\n",
    "                self.max_gradings[key] = 0\n",
    "                self.max_grading_changes[key] = 0\n",
    "                key = f'VGrading{i}'\n",
    "                self.min_gradings[key] = 0\n",
    "                self.max_gradings[key] = 0\n",
    "                self.max_grading_changes[key] = 0\n",
    "        else:\n",
    "            \n",
    "        #This is included in case the methods in the class are useful to another complex being loaded in\n",
    "        \n",
    "            self.components = None\n",
    "        \n",
    "        \n",
    "    def __repr__(self):\n",
    "        #If the object is called it will return the underlying digraph\n",
    "        return self.comp\n",
    "    \n",
    "    def subcomplex(self, subgraph):\n",
    "        #This is essentially just the subgraph - may not be an actual subcomplex if poor choice of vertices/edges are made\n",
    "        sub_copy = subgraph.copy()\n",
    "        result = grid_complex(sub_copy, self.ring)\n",
    "        \n",
    "    \n",
    "    def copy(self):\n",
    "        if self.sigx == None:\n",
    "            new_copy = grid_complex(self.comp.copy(), self.ring)\n",
    "        else:\n",
    "            new_copy = grid_complex(self.comp.copy(), self.ring, self.sigx.copy(), self.sigo.copy())\n",
    "        return new_copy\n",
    "    \n",
    "    def grid(self):        \n",
    "        #Adding functionality to return the original grid that produced the complex\n",
    "        return [self.sigx, self.sigo]\n",
    "\n",
    "    \n",
    "    def graph(self):\n",
    "        return self.comp\n",
    "    \n",
    "    def ring(self):\n",
    "        return self.ring\n",
    "    \n",
    "    \n",
    "    \n",
    "    def to_hat(self):\n",
    "\n",
    "        print(\"setting Ui's and Vi's = 0\")\n",
    "        gens = self.ring.gens()\n",
    "        size = len(gens)/2    \n",
    "        for edge in self.comp.edges():\n",
    "\n",
    "            for i in range(2*size):\n",
    "\n",
    "                src = edge[0]\n",
    "                tar = edge[1]\n",
    "                self.comp[src][tar]['diffweight'] = self.comp[src][tar]['diffweight'].subs({gens[i]:0})\n",
    "\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def to_minus(self):\n",
    "    #Substitutes U0 for all the Ui and 1 for Vi\n",
    "        self.set_to_minus = True\n",
    "        print(\"normalizing Ui's and setting Vi = 1\")\n",
    "        gens = self.ring.gens()\n",
    "        size = len(gens)/2    \n",
    "        for edge in self.comp.edges():\n",
    "\n",
    "            for component in self.components:\n",
    "                for i in component:\n",
    "\n",
    "#                     if i == component[0]: continue\n",
    "                    setting_var = component[0] - 1\n",
    "                    src = edge[0]\n",
    "                    tar = edge[1]\n",
    "                    self.comp[src][tar]['diffweight'] = self.comp[src][tar]['diffweight'].subs({gens[i-1]:gens[setting_var]})\n",
    "                    self.comp[src][tar]['diffweight'] = self.comp[src][tar]['diffweight'].subs({gens[i+size-1]:1})\n",
    "\n",
    "        self.remove_zeros()\n",
    "        return\n",
    "\n",
    "    def link_normalize(self):\n",
    "    #Substitutes Ucomp for all the Ui associated to that component\n",
    "\n",
    "        gens = self.ring.gens()\n",
    "        size = len(gens)/2    \n",
    "        for edge in self.comp.edges():\n",
    "\n",
    "            for component in self.components:\n",
    "                for i in component:\n",
    "\n",
    "                    if i == component[0]: continue\n",
    "                    setting_var = component[0] - 1\n",
    "                    src = edge[0]\n",
    "                    tar = edge[1]\n",
    "                    self.comp[src][tar]['diffweight'] = self.comp[src][tar]['diffweight'].subs({gens[i-1]:gens[setting_var]})\n",
    "                    self.comp[src][tar]['diffweight'] = self.comp[src][tar]['diffweight'].subs({gens[i+size-1]:gens[size+setting_var]})\n",
    "\n",
    "        self.remove_zeros()\n",
    "        return\n",
    "\n",
    "    \n",
    "#     def normalize(self):\n",
    "#     #Substitutes U0 for all the Ui and V0 for all Vi\n",
    "\n",
    "#         gens = self.field.gens()\n",
    "#         size = len(gens)/2    \n",
    "#         for edge in self.comp.edges():\n",
    "\n",
    "#             for i in range(size):\n",
    "\n",
    "#                 src = edge[0]\n",
    "#                 tar = edge[1]\n",
    "#                 self.comp[src][tar]['diffweight'] = self.comp[src][tar]['diffweight'].subs({gens[i]:gens[0]})\n",
    "#                 self.comp[src][tar]['diffweight'] = self.comp[src][tar]['diffweight'].subs({gens[i+size]:gens[size]})\n",
    "\n",
    "#         self.remove_zeros()\n",
    "#         return\n",
    "\n",
    "    def remove_zeros(self):\n",
    "\n",
    "        elist = list(self.comp.edges())\n",
    "        for x,y in elist:\n",
    "\n",
    "            if self.comp[x][y]['diffweight'] == 0:\n",
    "\n",
    "                self.comp.remove_edge(x,y)\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "    def split_by_grading(self, partition_list, key):\n",
    "    #partition list is supposed to be of the form matching the partition function's output\n",
    "        result = []\n",
    "        \n",
    "        for data in partition_list:\n",
    "            gens = [vert for vert in self.comp.nodes() if ((self.comp.nodes()[vert][key] >= data[0]) and (self.comp.nodes()[vert][key] <= data[4])) ]\n",
    "            subg = self.comp.subgraph(gens)\n",
    "            result.append(subg)\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    \n",
    "    def graph_red_search(self, started = False, timerstart = None): \n",
    "    #searches through a cfk inf complex for reducible edges and calling\n",
    "    #the reduction function to eliminate the pair according to the reduction algorithm\n",
    "    #     dict_graph = nx.to_dict_of_dicts(given_graph)\n",
    "        \n",
    "        if not started:\n",
    "            timerstart = time.time()    \n",
    "            print(\"Reducing complex...\")\n",
    "        \n",
    "        print(len([source for source, target, weight in self.comp.edges(data = 'diffweight') if weight == 1]))\n",
    "        while True:\n",
    "#             count = (count + 1)%\n",
    "            try:\n",
    "                red_target = next((source, target) for source, target, weight in self.comp.edges(data = 'diffweight') if weight == 1)\n",
    "#                 print(self.comp.edges[red_target])\n",
    "                self.graph_reduction(red_target[0], red_target[1])\n",
    "                continue\n",
    "            except:\n",
    "                (\"StopIteration\")\n",
    "            break\n",
    "                \n",
    "#         for key in self.comp:\n",
    "\n",
    "#             for target in self.comp[key]:\n",
    "\n",
    "#                 if self.comp[key][target]['diffweight'] == 1:\n",
    "#                     self.graph_reduction(key, target)\n",
    "#                     return self.graph_red_search(True, timerstart)\n",
    "\n",
    "        timerstop = time.time()\n",
    "        print('Time to reduce complex: ' + str(timerstop - timerstart))\n",
    "\n",
    "        return\n",
    "\n",
    "    def graph_reduction(self, key, target):\n",
    "    #Deletes edge specified from graph_red_search and adds in edges according to the\n",
    "    #reduction algorithm\n",
    "        for x in self.comp.predecessors(target):\n",
    "\n",
    "            if x == key: continue\n",
    "            for y in self.comp.successors(key):\n",
    "\n",
    "                if y == target: continue\n",
    "                x_weight = self.comp[x][target]['diffweight']\n",
    "                y_weight = self.comp[key][y]['diffweight']\n",
    "                red_weight = x_weight * y_weight\n",
    "                if self.comp.has_edge(x,y):\n",
    "                    old_weight = self.comp[x][y]['diffweight']\n",
    "                    red_weight = red_weight + old_weight\n",
    "                self.comp.add_edge(x,y,diffweight=red_weight)\n",
    "\n",
    "        self.comp.remove_node(key)\n",
    "        self.comp.remove_node(target)\n",
    "        return\n",
    "\n",
    "    def grade_link_complex(self):\n",
    "\n",
    "        #Input: given_graph a networkx directed graph with 'diffweight' attribute on edges\n",
    "        #       given_field the laurent polynomial field associated to the grid graph\n",
    "        #       gridX a list representing the vertex to be graded 0 in U V and Alexander gradings\n",
    "        #\n",
    "        #Output: given_graph with new attributes on the vertices for U V and Alexander gradings\n",
    "        #        also an attribute HasBeenGraded as an artifact\n",
    "\n",
    "\n",
    "        #If the positions of the Xs aren't provided we'll initialize around whatever\n",
    "        #state happens to appear first in the digraph structure - This will mean the complex's absolute grading will be off\n",
    "        if self.sigx == None:\n",
    "\n",
    "            gridX = list(self.comp.nodes())[0]\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            gridX = self.sigx\n",
    "\n",
    "        if self.sigo == None:\n",
    "\n",
    "            gridO = list(self.comp.nodes())[0]\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            gridO = self.sigo\n",
    "            \n",
    "        gens = self.ring.gens()\n",
    "        size = len(gens)/2 \n",
    "\n",
    "        print(\"grading complex...\")\n",
    "\n",
    "        comp_set = len(self.components)\n",
    "\n",
    "        #Adding an attribute to all nodes to keep track of if they've been assigned gradings\n",
    "        for i in range(comp_set):\n",
    "            nx.set_node_attributes(self.comp, False, f\"HasBeenGraded{i}\")\n",
    "\n",
    "        #The gradings are relative so we're declaring one to be in U, V, and Alexander grading 0\n",
    "        #this block initializes those balues\n",
    "        for i in range(comp_set):\n",
    "#             self.comp.nodes()[str(gridX)][f'HasBeenGraded{i}'] = True\n",
    "            self.comp.nodes()[str(gridX)][f'AGrading{i}'] = 0\n",
    "#             self.comp.nodes()[str(gridX)][f'UGrading{i}'] = 0\n",
    "#             self.comp.nodes()[str(gridX)][f'VGrading{i}'] = 0\n",
    "\n",
    "        if TIMERS: timerstart = time.time()\n",
    "\n",
    "        #Built in function to find a spanning tree\n",
    "        #span = nx.algorithms.tree.branchings.greedy_branching(given_graph)\n",
    "\n",
    "        tree = nx.algorithms.minimum_spanning_tree( self.comp.to_undirected()  )\n",
    "        eds = set(tree.edges())  # optimization\n",
    "        spanset = []\n",
    "\n",
    "        for edge in eds:\n",
    "\n",
    "            if edge in self.comp.edges():\n",
    "                spanset.append(edge)\n",
    "\n",
    "            else:\n",
    "                spanset.append((edge[1],edge[0]))\n",
    "\n",
    "        span = self.comp.edge_subgraph(spanset)\n",
    "\n",
    "        if TIMERS:\n",
    "\n",
    "            timerstop = time.time()\n",
    "            print(\"Time to find arborescence:\" + str(timerstop - timerstart))\n",
    "\n",
    "        #Bit of baseball terminology for the following nested loops, the active data is essentially at bat, the list we're working\n",
    "        #through is called on_deck, and then we're building up the follow up as in_the_hole which will turn into\n",
    "        #on deck on the following loop\n",
    "        #\n",
    "        #On deck holds the edges to be iterated through\n",
    "        on_deck = [str(gridX)]\n",
    "\n",
    "        #In the hole holds the ones to be iterated through once on_deck is cleared\n",
    "        in_the_hole = []\n",
    "\n",
    "        if TIMERS: timerstart = time.time()\n",
    "\n",
    "            \n",
    "        comp_count = len(self.components)\n",
    "            \n",
    "        #Grading Loops Start:\n",
    "        ####################\n",
    "        \n",
    "        self.componentwise_relative_grading_loop(\"UGrading\", gridX, self.virtual_U_gradings_succ, self.virtual_U_gradings_pred, span, comp_count)\n",
    "        self.componentwise_relative_grading_loop(\"VGrading\", gridX, self.virtual_V_gradings_succ, self.virtual_V_gradings_pred, span, comp_count)\n",
    "        self.relative_grading_loop(\"UGrading\", gridX, self.maslov_U_succ, self.maslov_U_pred, span, comp_count)\n",
    "        self.relative_grading_loop(\"VGrading\", gridX, self.maslov_V_succ, self.maslov_V_pred, span, comp_count)\n",
    "        \n",
    "        ####################\n",
    "        #Grading Loops End\n",
    "\n",
    "        for vert in self.comp.nodes():\n",
    "            self.comp.nodes()[vert]['AGrading'] = 0          \n",
    "            for i in range(len(self.components)):\n",
    "                stab_count = len(self.components[i])\n",
    "                self.comp.nodes()[vert][f'AGrading{i}'] = (1/2)*(self.comp.nodes()[vert][f'VGrading{i}']-self.comp.nodes()[vert][f'UGrading{i}'])-(1/2)*(stab_count - 1)\n",
    "                self.comp.nodes()[vert]['AGrading'] += self.comp.nodes()[vert][f'AGrading{i}']\n",
    "        if TIMERS:\n",
    "\n",
    "            timerstop = time.time()\n",
    "            print('Time to grade complex (given arborescence): ' + str(timerstop - timerstart))\n",
    "\n",
    "        return\n",
    "\n",
    "    def gml_export(self, filename = 'PleaseNameMe.gml'):\n",
    "\n",
    "#         if component_length == -1:\n",
    "#             return(\"!!! Unknown number of components for export !!!\")\n",
    "\n",
    "        component_length = len(self.components)\n",
    "        \n",
    "        if component_length == 0:\n",
    "            raise(\"Error finding number of components\")\n",
    "        \n",
    "        nxG = self.comp.copy()\n",
    "\n",
    "        if filename == 'PleaseNameMe.gml':\n",
    "            print(\"You didn't name your output! It's been named PleaseNameMe.gml\")\n",
    "\n",
    "        if filename[-4:] != \".gml\":\n",
    "            filename += \".gml\"\n",
    "\n",
    "        for x,y in nxG.edges():\n",
    "\n",
    "            nxG[x][y]['diffweight'] = str(nxG[x][y]['diffweight'])\n",
    "\n",
    "        for node in nxG.nodes():\n",
    "\n",
    "            #print(str((nxG.nodes()[node]['UGrading'],nxG.nodes()[node]['VGrading'],nxG.nodes()[node]['AGrading'])))\n",
    "            try:\n",
    "                nxG.nodes[node]['UGrading'] = int(nxG.nodes[node]['UGrading'])\n",
    "                nxG.nodes[node]['VGrading'] = int(nxG.nodes[node]['VGrading'])\n",
    "                nxG.nodes[node]['AGrading'] = int(nxG.nodes[node]['AGrading'])\n",
    "            except:\n",
    "                nxG.nodes[node]['UGrading'] = int(-99)\n",
    "                nxG.nodes[node]['VGrading'] = int(-99)\n",
    "                nxG.nodes[node]['AGrading'] = int(-99)\n",
    "            for i in range(component_length):\n",
    "                try:\n",
    "                    nxG.nodes[node][f'AGrading{i}'] = int(nxG.nodes[node][f'AGrading{i}']) \n",
    "                    nxG.nodes[node][f'UGrading{i}'] = int(nxG.nodes[node][f'UGrading{i}'])\n",
    "                    nxG.nodes[node][f'VGrading{i}'] = int(nxG.nodes[node][f'VGrading{i}'])\n",
    "                except:\n",
    "                    nxG.nodes[node][f'AGrading{i}'] = int(-99)\n",
    "                    nxG.nodes[node][f'UGrading{i}'] = int(-99)\n",
    "                    nxG.nodes[node][f'VGrading{i}'] = int(-99)\n",
    "\n",
    "        print(\"writing to \" + OUTPUTDIRECTORY + str(filename))\n",
    "        nx.write_gml(nxG, OUTPUTDIRECTORY + filename)\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "    \n",
    "    def find_grading_ranges(self, key = \"AGrading\"):\n",
    "\n",
    "        self.min_gradings[key] = 0\n",
    "        self.max_gradings[key] = 0\n",
    "        \n",
    "        for vert in self.comp.nodes():\n",
    "\n",
    "            if self.comp.nodes[vert][key] < self.min_gradings[key]:\n",
    "\n",
    "                self.min_gradings[key] = self.comp.nodes[vert][key]\n",
    "\n",
    "            if self.comp.nodes[vert][key] > self.max_gradings[key]:\n",
    "\n",
    "                self.max_gradings[key] = self.comp.nodes[vert][key]\n",
    "\n",
    "        return\n",
    "\n",
    "    \n",
    "    def comp_truncate(self, grading_cutoff):\n",
    "    #Grading cutoff should be a tuple of values, this function will\n",
    "    #I've only considered this for calling after converting to minus complex\n",
    "        generators = self.ring.gens()\n",
    "        for i in range(len(self.components)):\n",
    "            for vert in self.comp:\n",
    "\n",
    "                if self.comp.nodes()[vert][f\"AGrading{i}\"] >= grading_cutoff[i]:\n",
    "                    self.comp.nodes()[vert][f\"AGrading{i}\"] += 1\n",
    "                    self.comp.nodes()[vert][f\"UGrading{i}\"] += -2\n",
    "\n",
    "                    for targ in self.comp.successors(vert):\n",
    "\n",
    "                        self.comp[vert][targ]['diffweight'] = self.comp[vert][targ]['diffweight']*generators[i]\n",
    "\n",
    "                    for pred in self.comp.predecessors(vert):\n",
    "\n",
    "                        self.comp[pred][vert]['diffweight'] = self.comp[pred][vert]['diffweight']*(generators[i]^(-1))\n",
    "\n",
    "        return\n",
    "    \n",
    "    def surgery(self, grading_list = None, target_grading = None):\n",
    "\n",
    "        if grading_list == None:\n",
    "            \n",
    "            grading_list = []\n",
    "            \n",
    "            for i in range(len(self.components)):\n",
    "                self.find_grading_ranges(f\"AGrading{i}\")\n",
    "\n",
    "            for i in range(len(self.components)):\n",
    "                grading_list.append(self.max_gradings[f\"AGrading{i}\"])\n",
    "                        \n",
    "        if target_grading == None:\n",
    "            \n",
    "            target_grading = []\n",
    "            for i in range(len(self.components)):\n",
    "                target_grading.append(self.min_gradings[f\"AGrading{i}\"])\n",
    "        \n",
    "        print(\"target gradings = \" + str(target_grading))\n",
    "        print(\"max gradings = \" + str(grading_list))\n",
    "        if self.set_to_minus == False:\n",
    "            \n",
    "            print(\"This complex hasn't been converted to minus. Making a copy of the complex and converting it to the minus complex\")\n",
    "            minus_copy = self.copy()\n",
    "            minus_copy.to_minus()\n",
    "            minus_copy.surgery(grading_list, target_grading)\n",
    "            print(\"uhh didn't expect to be here...\")\n",
    "    \n",
    "        grading_ranges = []\n",
    "        \n",
    "        for i in range(len(target_grading)):\n",
    "            \n",
    "            grading_ranges.append(list(range(target_grading[i], grading_list[i]+1)))\n",
    "        \n",
    "        sub_gradings = itools.product(*grading_ranges)\n",
    "        \n",
    "        for grading in sub_gradings:\n",
    "            \n",
    "            specimen = self.copy()\n",
    "            specimen.comp_truncate(grading)\n",
    "            specimen.graph_red_search()\n",
    "            specimen.remove_zeros()\n",
    "            specimen.gml_export(str(self.sigx) + str(self.sigo) + \"surgery\" + str(grading))\n",
    "        \n",
    "        return\n",
    "\n",
    "    \n",
    "    def relative_grading_loop(self, grading_key, base_vertex, fn1, fn2, span = None, grading_multiplicity = 1):\n",
    "\n",
    "        if span == None:\n",
    "            \n",
    "            span = self.comp\n",
    "        \n",
    "\n",
    "        nx.set_node_attributes(self.comp, False, \"HasBeenGraded\")\n",
    "        self.comp.nodes()[str(base_vertex)][f'HasBeenGraded'] = True\n",
    "        self.comp.nodes()[str(base_vertex)][f'{grading_key}'] = 0\n",
    "\n",
    "        on_deck = [str(base_vertex)]\n",
    "        \n",
    "        in_the_hole = []\n",
    "\n",
    "        while len(on_deck) > 0: \n",
    "\n",
    "            for vert in on_deck:\n",
    "\n",
    "                #Every vertex in on_deck should be graded. The loops iterate through the neighbors of each of these\n",
    "                #vertices, grading them and then adding them to in_the_hole, ignoring vertices that have already been graded.\n",
    "                #\n",
    "                #The loop is broken into two halves since we have two flavors of neighbor in a directed graph, successors and\n",
    "                #predecessors, named accordingly. These flavors differ in relative grading change by a sign.\n",
    "                for i, component_columns in enumerate(self.components):\n",
    "                    for succ in span.successors(vert): \n",
    "\n",
    "                        #skip the vertex if its already been graded\n",
    "                        if self.comp.nodes()[succ]['HasBeenGraded']: continue\n",
    "                        \n",
    "                        in_the_hole.append(succ)\n",
    "                        \n",
    "                        fn1(succ, vert)\n",
    "\n",
    "                        self.comp.nodes()[succ]['HasBeenGraded'] = True\n",
    "\n",
    "                    for pred in span.predecessors(vert):\n",
    "\n",
    "                        if self.comp.nodes()[pred]['HasBeenGraded']: continue\n",
    "                        \n",
    "                        in_the_hole.append(pred)\n",
    "                        \n",
    "                        fn2(pred, vert)\n",
    "\n",
    "                        self.comp.nodes()[pred][f'HasBeenGraded'] = True\n",
    "                        \n",
    "            on_deck = in_the_hole\n",
    "            in_the_hole = []\n",
    "                                                \n",
    "        return\n",
    "\n",
    "    \n",
    "    def componentwise_relative_grading_loop(self, grading_key, base_vertex, fn1, fn2, span = None, grading_multiplicity = 1):\n",
    "\n",
    "        if span == None:\n",
    "            \n",
    "            span = self.comp\n",
    "        \n",
    "        for i in range(grading_multiplicity):\n",
    "\n",
    "            nx.set_node_attributes(self.comp, False, f\"HasBeenGraded{i}\")\n",
    "            self.comp.nodes()[str(base_vertex)][f'HasBeenGraded{i}'] = True\n",
    "            self.comp.nodes()[str(base_vertex)][f'{grading_key}{i}'] = 0\n",
    "\n",
    "        on_deck = [str(base_vertex)]\n",
    "        \n",
    "        in_the_hole =[]\n",
    "\n",
    "        while len(on_deck) > 0: \n",
    "\n",
    "            for vert in on_deck:\n",
    "\n",
    "                #Every vertex in on_deck should be graded. The loops iterate through the neighbors of each of these\n",
    "                #vertices, grading them and then adding them to in_the_hole, ignoring vertices that have already been graded.\n",
    "                #\n",
    "                #The loop is broken into two halves since we have two flavors of neighbor in a directed graph, successors and\n",
    "                #predecessors, named accordingly. These flavors differ in relative grading change by a sign.\n",
    "                for i, component_columns in enumerate(self.components):\n",
    "                    for succ in span.successors(vert): \n",
    "\n",
    "                        #skip the vertex if its already been graded\n",
    "                        if self.comp.nodes()[succ][f'HasBeenGraded{i}']: continue\n",
    "                        \n",
    "                        in_the_hole.append(succ)\n",
    "                        \n",
    "                        fn1(i, succ, vert, component_columns)\n",
    "\n",
    "                        self.comp.nodes()[succ][f'HasBeenGraded{i}'] = True\n",
    "\n",
    "                    for pred in span.predecessors(vert):\n",
    "\n",
    "                        if self.comp.nodes()[pred][f'HasBeenGraded{i}']: continue\n",
    "                        \n",
    "                        in_the_hole.append(pred)\n",
    "                        \n",
    "                        fn2(i, pred, vert, component_columns)\n",
    "\n",
    "                        self.comp.nodes()[pred][f'HasBeenGraded{i}'] = True\n",
    "                        \n",
    "            on_deck = in_the_hole\n",
    "            in_the_hole = []\n",
    "                        \n",
    "        return\n",
    "\n",
    "    def virtual_U_gradings_pred(self, i, pred, vert, component_columns):\n",
    "\n",
    "        ed_weight = self.comp[pred][vert]['diffweight']\n",
    "\n",
    "        Upows = link_U_deg(ed_weight, self.ring, component_columns)\n",
    "        self.comp.nodes()[pred][f'UGrading{i}'] = self.comp.nodes()[vert][f'UGrading{i}'] + 1 - 2*Upows\n",
    "        \n",
    "        return\n",
    "\n",
    "    def virtual_U_gradings_succ(self, i, succ, vert, component_columns):        \n",
    "        \n",
    "        ed_weight = self.comp[vert][succ]['diffweight']\n",
    "\n",
    "        Upows = link_U_deg(ed_weight, self.ring, component_columns)\n",
    "        self.comp.nodes()[succ][f'UGrading{i}'] = self.comp.nodes()[vert][f'UGrading{i}'] - 1 + 2*Upows\n",
    "    \n",
    "        return\n",
    "\n",
    "    def virtual_V_gradings_pred(self, i, pred, vert, component_columns):\n",
    "\n",
    "        ed_weight = self.comp[pred][vert]['diffweight']\n",
    "\n",
    "        Vpows = link_V_deg(ed_weight, self.ring, component_columns)\n",
    "        self.comp.nodes()[pred][f'VGrading{i}'] = self.comp.nodes()[vert][f'VGrading{i}'] + 1 - 2*Vpows\n",
    "        \n",
    "        return\n",
    "\n",
    "    def virtual_V_gradings_succ(self, i, succ, vert, component_columns):        \n",
    "        \n",
    "        ed_weight = self.comp[vert][succ]['diffweight']\n",
    "\n",
    "        Vpows = link_V_deg(ed_weight, self.ring, component_columns)\n",
    "        self.comp.nodes()[succ][f'VGrading{i}'] = self.comp.nodes()[vert][f'VGrading{i}'] - 1 + 2*Vpows\n",
    "              \n",
    "        return\n",
    "            \n",
    "    def maslov_U_pred(self, pred, vert):\n",
    "\n",
    "        ed_weight = self.comp[pred][vert]['diffweight']\n",
    "        \n",
    "        component_columns = self.sigx\n",
    "        \n",
    "        Upows = link_U_deg(ed_weight, self.ring, component_columns)\n",
    "        self.comp.nodes()[pred]['UGrading'] = self.comp.nodes()[vert]['UGrading'] + 1 - 2*Upows        \n",
    "        \n",
    "        return\n",
    "        \n",
    "    def maslov_U_succ(self, succ, vert):\n",
    "        \n",
    "        ed_weight = self.comp[vert][succ]['diffweight']\n",
    "\n",
    "        component_columns = self.sigx\n",
    "        \n",
    "        Upows = link_U_deg(ed_weight, self.ring, component_columns)\n",
    "        self.comp.nodes()[succ]['UGrading'] = self.comp.nodes()[vert]['UGrading'] - 1 + 2*Upows\n",
    "\n",
    "        return\n",
    "        \n",
    "    def maslov_V_pred(self, pred, vert):\n",
    "\n",
    "        ed_weight = self.comp[pred][vert]['diffweight']\n",
    "\n",
    "        component_columns = self.sigo\n",
    "        \n",
    "        Vpows = link_U_deg(ed_weight, self.ring, component_columns)\n",
    "        self.comp.nodes()[pred]['VGrading'] = self.comp.nodes()[vert]['VGrading'] + 1 - 2*Vpows        \n",
    "        \n",
    "        return\n",
    "        \n",
    "    def maslov_V_succ(self, succ, vert):\n",
    "        \n",
    "        ed_weight = self.comp[vert][succ]['diffweight']\n",
    "\n",
    "        component_columns = self.sigo\n",
    "        \n",
    "        Vpows = link_U_deg(ed_weight, self.ring, component_columns)\n",
    "        self.comp.nodes()[succ]['VGrading'] = self.comp.nodes()[vert]['VGrading'] - 1 + 2*Vpows\n",
    "\n",
    "        return\n",
    "    \n",
    "    def find_max_difference(self, key_set):\n",
    "    #For a given set of keys this function iterates through the graph and finds the largest difference. This could be improvable\n",
    "    #speed-wise by considering edges instead but as it stands the grading would have to be recomputed since that data is\n",
    "    #recorded in  the vertices instead. So in its current state that would be more expensive in processing and this is cheaper\n",
    "    #memory wise regardless.\n",
    "    \n",
    "        if type(key_set) == str:\n",
    "            key_set = [key_set]\n",
    "        \n",
    "        for key in key_set:\n",
    "            self.max_grading_changes[key] = 0\n",
    "        \n",
    "        result = 0\n",
    "        for vert in self.comp.nodes():\n",
    "            for nb in self.comp.neighbors(vert):\n",
    "                for key in key_set:\n",
    "                    if (abs(self.comp.nodes()[vert][key] - self.comp.nodes()[nb][key])) > self.max_grading_changes[key]:\n",
    "                        print(\"setting value\")\n",
    "                        self.max_grading_changes[key] = abs(self.comp.nodes()[vert][key] - self.comp.nodes()[nb][key])\n",
    "    \n",
    "        return\n",
    "    \n",
    "    def parallel_graph_single_split(self, key, split_count, split_blocks = None):\n",
    "        \n",
    "    #WARNING: !!!split count should be passed at most one lower than the actual number of cores available, this is because of \n",
    "    #ceilings being a part of the function - it means it can return a set with more blocks than the given split count!!! \n",
    "  \n",
    "        self.find_max_difference(key)\n",
    "        \n",
    "        max_step = self.max_grading_changes[key]\n",
    "\n",
    "        self.find_grading_ranges(key)\n",
    "        \n",
    "        if split_blocks == None:\n",
    "            \n",
    "            split_blocks = degree_partition(max_step, math.ceil(self.min_gradings[key]), math.ceil(self.max_gradings[key]), split_count)\n",
    "    \n",
    "        if split_blocks == None:\n",
    "            \n",
    "            return None\n",
    "        \n",
    "        result = []\n",
    "        \n",
    "        for split in split_blocks:\n",
    "            \n",
    "            current_subgraph = []\n",
    "            vertex_set = []\n",
    "            vertex_set = [vert for vert in self.comp.nodes() if ((self.comp.nodes()[vert][key] >= split[0]) and (self.comp.nodes()[vert][key] <= split[-1]))]\n",
    "            current_subgraph = self.comp.subgraph(vertex_set).copy()\n",
    "            result.append([current_subgraph, split])\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def parallel_reduction_helper(self, subgraph_set, overwrite = True):\n",
    "        \n",
    "        print(\"running parallel_reduction_helper\")\n",
    "        process_dict = {}\n",
    "        for count, subgraph in enumerate(subgraph_set):\n",
    "            \n",
    "            process_dict[count] = mp.Process(target = subgraph[0].range_graph_red_search(), args = subgraph[1] )\n",
    "            process_dict[count].start()\n",
    "        \n",
    "        for proc in process_dict:\n",
    "            \n",
    "            proc.join()\n",
    "        \n",
    "        result = subgraph_set[0][0]\n",
    "        \n",
    "        for subgraph in subgraph_set:\n",
    "            \n",
    "            result = nx.compose(result, subgraph)\n",
    "        \n",
    "        if overwrite:\n",
    "            \n",
    "            self.comp = result\n",
    "            return\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            return result\n",
    "    \n",
    "    \n",
    "    def grading_parallel_graph_red_search(self, proc_count = 2, splitting_key = \"AGrading\"):\n",
    "        \n",
    "        key = splitting_key\n",
    "        \n",
    "        subgraph_set = self.parallel_graph_single_split(splitting_key, proc_count - 1)\n",
    "        \n",
    "        if subgraph_set == None:\n",
    "            \n",
    "            self.graph_red_search()\n",
    "            return\n",
    "        \n",
    "        step = parallel_active_range(self.max_grading_changes[key], math.ceil(self.min_gradings[key]), math.ceil(self.max_gradings[key]), proc_count)\n",
    "        \n",
    "        target_loop = math.ceil((1+self.max_gradings[key]-self.min_gradings[key])/step)\n",
    "        print(str(target_loop) + str(\" target number of loops\"))\n",
    "        \n",
    "        partition = subgraph_set[:][1]\n",
    "        \n",
    "        for i in range(target_loop):\n",
    "            \n",
    "            self.parallel_reduction_helper(subgraph_set)\n",
    "            \n",
    "            partition_block_iterator(partition, step)\n",
    "            \n",
    "            subgraph_set = self.parallel_graph_single_split(splitting_key, proc_count - 1, split_blocks = partition)\n",
    "#             iterate the split\n",
    "            \n",
    "        return\n",
    "\n",
    "    \n",
    "\n",
    "    def ego_parallel_red_search(self, cutoff = 5, proc_count = 2):\n",
    "        \n",
    "        if len([source for source, target, weight in self.comp.edges(data = 'diffweight') if weight == 1]) > cutoff:\n",
    "            print(\"entering parallel reduction\")\n",
    "        while len([source for source, target, weight in self.comp.edges(data = 'diffweight') if weight == 1]) > cutoff:\n",
    "               print(str(len([source for source, target, weight in self.comp.edges(data = 'diffweight') if weight == 1])) + \"reducible edges remaining\")\n",
    "               reducible_edge = rd.sample([source for source, target, weight in self.comp.edges(data = 'diffweight') if weight == 1], 1)\n",
    "               \n",
    "               self.ego_parallel_sweep(reducible_edge[0], proc_count)\n",
    "        print(\"parallel reduction complete\")\n",
    "        self.graph_red_search()\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def ego_parallel_sweep(self, start_vert = None, proc_count = 2):\n",
    "\n",
    "        if start_vert == None:\n",
    "            \n",
    "            start_vert = self.comp.nodes()[0]\n",
    "        \n",
    "        size = len(list(self.comp.nodes)[0])\n",
    "#         (self.comp.nodes[0])\n",
    "        ego_bands, safety = ego_split(self.comp, start_vert, size)\n",
    "        \n",
    "        partition_data = ego_region_partition(size)\n",
    "        \n",
    "        parallel_subgraph_packer(self.comp, ego_bands, partition_data, self.ring)\n",
    "        \n",
    "        region_count = len(partition_data)\n",
    "        count = 0 \n",
    "        MyManager.register('list', list)\n",
    "        with MyManager() as manager:\n",
    "            processed_subgraphs = manager.list()\n",
    "            while count < region_count:\n",
    "\n",
    "                process_dict = {}\n",
    "\n",
    "                for i in range(proc_count):\n",
    "\n",
    "                    if count < region_count:\n",
    "\n",
    "#                         processed_subgraphs = []\n",
    "                        process_dict[count] = mp.Process(target = subgraph_red_search, args = (partition_data[f\"block{count}\"]['total_region'],partition_data[f\"block{count}\"]['search_region'], processed_subgraphs))\n",
    "                        process_dict[count].start()\n",
    "                        count += 1\n",
    "\n",
    "                # print(\"Assigned parallel jobs, waiting for them to finish\")\n",
    "                for proc in process_dict:\n",
    "                    # print(proc)\n",
    "                    process_dict[proc].join()\n",
    "\n",
    "                # print(\"count = \" + str(count) + \"region_count = \" + str(region_count))     \n",
    "            processed_subgraphs = processed_subgraphs._getvalue()    \n",
    "            # print(\"replacing parent graph...\")\n",
    "            result = processed_subgraphs[0].comp\n",
    "        \n",
    "        for element in processed_subgraphs:\n",
    "            \n",
    "            result = nx.compose(result, element.comp)\n",
    "\n",
    "        result = nx.compose(result, safety)\n",
    "            \n",
    "        # print('reduced total graph from ' +  str(len(self.comp.nodes())), end = \"\")\n",
    "        \n",
    "        self.comp = result\n",
    "\n",
    "        self.remove_zeros()\n",
    "        # print(' to ' +  str(len(self.comp.nodes())))\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "def subgraph_red_search(subg, search_reg, result_list):\n",
    "#     print(search_region)\n",
    "    # print(type(search_reg))\n",
    "    subgraph = subg.copy()\n",
    "    search_region = search_reg.copy()\n",
    "    og_size = len(subgraph.comp.nodes())\n",
    "    for ed in [edge for edge in search_region.comp.edges() if search_region.comp.edges[edge]['diffweight'] == 1]:\n",
    "#         print(\"identified edge \" + str(ed) + \" for reduction\")\n",
    "#         print(\"nodes of subg\" + str(subgraph.comp.nodes()))\n",
    "#         print(\"nodes of search region\" + str(search_region.comp.nodes()))\n",
    "        \n",
    "        if ed in subgraph.comp.edges():\n",
    "#             print(\"reducing an edge\")\n",
    "            subgraph.graph_reduction(ed[0], ed[1])\n",
    "        \n",
    "    f_size = len(subgraph.comp.nodes())\n",
    "    # print(\"reduced subgraph from size \" + str(og_size) + \" to \" + str(f_size))\n",
    "    result_list.append(subgraph)\n",
    "#     print(\"running change result length = \" + str(len(result_list)))\n",
    "            \n",
    "    return\n",
    "    \n",
    "    \n",
    "# def scatter(permutation):\n",
    "    \n",
    "#     p = pr.perm(permutation)\n",
    "#     size = len(p)\n",
    "#     result = []\n",
    "#     cycle = pr.full_cycle(size)\n",
    "#     for i in range(size):\n",
    "#         result.append(p)\n",
    "#         p = cycle*p\n",
    "        \n",
    "#     return result\n",
    "\n",
    "# def scatter_graph(permutation, graph):\n",
    "    \n",
    "\n",
    "def ego_split(graph, vertex, n):\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        result.append(nx.ego_graph(graph, vertex, i))\n",
    "        \n",
    "    safety = graph.copy()\n",
    "    \n",
    "    safety.remove_nodes_from(result[n - 1].nodes())\n",
    "        \n",
    "    for i in range(n-1, 0, -1):\n",
    "        \n",
    "        result[i].remove_nodes_from(result[i-1].nodes())\n",
    "        \n",
    "    return result, safety\n",
    "\n",
    "def ego_region_partition(n):\n",
    "    \n",
    "    result = {}\n",
    "    \n",
    "    split_count = math.ceil(n/4)\n",
    "    \n",
    "    result[\"block0\"] = {\"search_region\": [0,1] , \"reserved_region\": [2]}\n",
    "    \n",
    "    for i in range(1,split_count):\n",
    "        \n",
    "        result[f\"block{i}\"] = {\"search_region\" : [3*i, 3*i+1], \"reserved_region\" : [3*i-1,3*i+2]}\n",
    "        \n",
    "    return result\n",
    "\n",
    "def parallel_subgraph_packer(graph, subgraphs, region_data, ring):\n",
    "    #region_data should be a dict of dicts with inner dict data labeled \"search_region\" and \"reserved_region\"\n",
    "    #the outer data should be labeled f\"block{i}\". See ego_region_partition for an example function that works\n",
    "    #with this\n",
    "    \n",
    "    #subgraphs should be a list of subgraphs corresponding to the region data specified above\n",
    "    \n",
    "    for data in region_data:\n",
    "#         print(region_data[data])\n",
    "        \n",
    "        region_nodes = []\n",
    "        \n",
    "        #unpacking the indices of the subgraphs we were passed - so we need to unpack 3\n",
    "        #layers deep in total\n",
    "        \n",
    "        for region in region_data[data]:    \n",
    "            for i in region_data[data][region]:\n",
    "#                 print(type(subgraphs[i]))\n",
    "\n",
    "                region_nodes += (list(subgraphs[i].nodes()))\n",
    "        \n",
    "        packed_subgraph = graph.subgraph(region_nodes)\n",
    "        \n",
    "        region_data[data]['total_region'] = grid_complex(packed_subgraph, ring)\n",
    "    \n",
    "    \n",
    "    for data in region_data:\n",
    "        \n",
    "        region_nodes = []\n",
    "        \n",
    "        for i in region_data[data]['search_region']:\n",
    "        \n",
    "            region_nodes += list(subgraphs[i].nodes())\n",
    "            \n",
    "        packed_subgraph = graph.subgraph(region_nodes)\n",
    "        \n",
    "        region_data[data]['search_region'] = grid_complex(packed_subgraph, ring)\n",
    "    \n",
    "    return region_data\n",
    "    \n",
    "\n",
    "def subgraph_neighborhood(graph, subgraph):\n",
    "    #Output: subgraph induced by the given subgraph and any neighbors it has in graph\n",
    "    result_nodes = set(subgraph.nodes())\n",
    "    for node in subgraph.nodes():\n",
    "        \n",
    "        for neighbor in graph.neighbors(node):\n",
    "            \n",
    "            result_nodes.add(neighbor)\n",
    "    \n",
    "    result = graph.subgraph(result_nodes)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def partition_block_iterator(blocks, step_size):\n",
    "    \n",
    "    for count, block in enumerate(blocks):\n",
    "        \n",
    "        if count == 0:\n",
    "            \n",
    "            for i in range(1, len(block)):\n",
    "                \n",
    "                blocks[i] += step_size\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            for i in range(len(block)):\n",
    "                \n",
    "                blocks[i] += step_size\n",
    "    \n",
    "    return\n",
    "    \n",
    "def name_some_vars(letters, num):\n",
    "    \n",
    "# Accepts a collection of strings, and an integer. Passing \"U\" and 3 for example returns \"U0, U1, U2\"\n",
    "    \n",
    "    result = []\n",
    "    num = int(num)\n",
    "    for letter in letters:\n",
    "        \n",
    "        for i in range(num):\n",
    "            new_var = f\"{letter}{i}\"\n",
    "            #print(new_var)\n",
    "            result.append(new_var)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def construct_cinf(g, sigx, sigo, size = -1): #Construct CFKinf complex from graph data - essentially just changing weights to polynomials\n",
    "                                  #Only works for grid diagrams *not* Latin Squares\n",
    "    print('constructing cinf...')\n",
    "    if size == -1:\n",
    "        size = len(g.get_edge_data(list(g.edges())[0][0],list(g.edges())[0][1])['diffweight'][0])  #kind of a mess - just turning the edges\n",
    "        print(\"Grid size is \" + str(size/2))\n",
    "        n = size/2                                                                              #into a list and checking the length of#the weight of the first edge\n",
    "    else:\n",
    "        n = size\n",
    "    timerstart = time.time()\n",
    "    F,Vars = cinf_coeff(n)\n",
    "    resG = nx.DiGraph()\n",
    "    for edge in g.edges:\n",
    "        \n",
    "        start = edge[0]\n",
    "        end = edge[1]\n",
    "        poly = F(0)\n",
    "        \n",
    "        \n",
    "        for subweight in g[edge[0]][edge[1]]['diffweight']:\n",
    "            \n",
    "            i = 0\n",
    "            polychange = F(1)\n",
    "#             print(str(subweight) + str(edge))\n",
    "            for entry in subweight:\n",
    "                \n",
    "                polychange = polychange*(Vars[i])**entry\n",
    "                i = i + 1\n",
    "                \n",
    "            poly += polychange\n",
    "#             print(str(edge) + str(poly))\n",
    "        resG.add_edge(start,end,diffweight = poly)\n",
    "    \n",
    "    timerend = time.time()\n",
    "    elap = timerend - timerstart\n",
    "    print('Time to construct cinf '+ str(elap))\n",
    "    return grid_complex(resG, F, sigx, sigo)\n",
    "        \n",
    "    \n",
    "def cinf_coeff(size):\n",
    "    \n",
    "# Takes size as an argument and returns the Laurent polynomial ring over Z2 with coefficients U0,...Usize-1,V0,...Vsize-1\n",
    "    \n",
    "    n = size\n",
    "    varis = name_some_vars(['U','V'],n)\n",
    "    F = LaurentPolynomialRing(GF(2), varis)\n",
    "    F.inject_variables()\n",
    "  \n",
    "    return F,list(F.gens())\n",
    "\n",
    "\n",
    "def range_skip_entry(n, skip):\n",
    "    \n",
    "# Acts similarly to standard range(n) but omits the \"skip\"th entry\n",
    "\n",
    "    u = []\n",
    "    for i in range(0, skip): u.append(i)\n",
    "    for j in range(skip+1, n): u.append(j)       \n",
    "    return u\n",
    "\n",
    "\n",
    "def link_GFC(sigx, sigo, filename = None):\n",
    "    \n",
    "    if filename == None:\n",
    "        filename = \"X\"\n",
    "        for pos in sigx:\n",
    "            filename = filename + str(pos)\n",
    "        filename = filename + \"O\"\n",
    "        for pos in sigo:\n",
    "            filename = filename + str(pos)\n",
    "        filename = filename + \".gml\"\n",
    "    \n",
    "    components = link_components(sigx, sigo)\n",
    "    link_count = len(components)\n",
    "    raw_complex = gfk.build_cinf([sigx, sigo])\n",
    "    comp = construct_cinf(raw_complex, sigx, sigo)\n",
    "    \n",
    "    comp.grade_link_complex()\n",
    "    print(\"passing to parallel reducer\")\n",
    "    comp.ego_parallel_red_search(proc_count = PROCESSOR_COUNT)\n",
    "#     comp.parallel_graph_red_search(PROCESSOR_COUNT, split_key)\n",
    "    print(\"completed parallel reducer function\")\n",
    "    comp.gml_export(filename)\n",
    "\n",
    "    comp.link_normalize()\n",
    "    \n",
    "#     comp.parallel_graph_red_search(PROCESSOR_COUNT)\n",
    "    \n",
    "    filename = \"Normalized\" + filename\n",
    "    comp.gml_export(filename)\n",
    "    \n",
    "    for i in range(len(comp.components)):\n",
    "        comp.find_grading_ranges(f'AGrading{i}')\n",
    "    \n",
    "    return comp\n",
    "\n",
    "\n",
    "def link_components(sigx, sigo):\n",
    "    \n",
    "    xperm = pr.perm(sigx)\n",
    "    operm = pr.perm(sigo)\n",
    "    comps = xperm*operm**(-1)\n",
    "    result = comps.cycles()\n",
    "    \n",
    "    return result\n",
    "\n",
    "def link_U_deg(poly, ring, component_columns):\n",
    "\n",
    "    #Input: poly a laurent polynomial in field a laurent polynomial ring\n",
    "    #\n",
    "    #Output: The total sum of powers of Ui in poly\n",
    "    \n",
    "    gens = ring.gens()\n",
    "    size = len(gens)/2\n",
    "    degree = 0\n",
    "    \n",
    "    if type(poly) == sage.rings.finite_rings.integer_mod.IntegerMod_int: return 0\n",
    "    \n",
    "    powers = poly.exponents()   \n",
    "    \n",
    "    #len(powers) tells you how many terms the polynomial has\n",
    "#     if len(powers) > 1:\n",
    "        \n",
    "#         print(poly)\n",
    "        \n",
    "#         raise Exception(\"Ran into a non-homogoneous degree change - polynomial wasn't a monomial\")\n",
    "\n",
    "    if len(powers) == 0:\n",
    "        \n",
    "        return 0    \n",
    "    \n",
    "    #powers is a list of lists since its intended for more than just monomials, since we are only care about the leading\n",
    "    #term we pull that one out\n",
    "    powers = powers[0]\n",
    "    \n",
    "    for i in component_columns:\n",
    "        \n",
    "        degree = degree + powers[i-1]\n",
    "    \n",
    "    return degree\n",
    "\n",
    "\n",
    "def link_V_deg(poly, ring, component_columns):\n",
    "\n",
    "    #Input: poly a laurent polynomial in \"ring\" a laurent polynomial ring\n",
    "    #\n",
    "    #Output: The total sum of powers of Ui in poly    \n",
    "    \n",
    "    gens = ring.gens()\n",
    "    size = len(gens)/2\n",
    "    degree = 0\n",
    "    \n",
    "    if type(poly) == sage.rings.finite_rings.integer_mod.IntegerMod_int: return 0\n",
    "    \n",
    "    powers = poly.exponents()   \n",
    "    \n",
    "    #len(powers) tells you how many terms the polynomial has    \n",
    "#     if len(powers) > 1:\n",
    "        \n",
    "#         print(poly)\n",
    "#         raise Exception(\"Ran into a non-homogoneous degree change - polynomial wasn't a monomial\")\n",
    "\n",
    "    if len(powers) == 0:\n",
    "        \n",
    "        return 0    \n",
    "    \n",
    "    #powers is a list of lists since its intended for more than just monomials, since we are only care about the leading\n",
    "    #term we pull that one out\n",
    "    powers = powers[0]\n",
    "    for i in component_columns:\n",
    "        \n",
    "        degree = degree + powers[size + i-1]\n",
    "    \n",
    "    return degree\n",
    "\n",
    "def parallel_active_range(max_grading_step, lower_range, upper_range, split_count):\n",
    "    \n",
    "    block_size = math.floor((upper_range - lower_range)/split_count)\n",
    "    \n",
    "    result = block_size - 2*max_grading_step\n",
    "\n",
    "    return result\n",
    "    \n",
    "    \n",
    "def degree_partition(max_grading_step, lower_range, upper_range, split_count):\n",
    "    #output = list of lists\n",
    "       \n",
    "    if split_count == 0:\n",
    "        raise Exception(\"Cannot split the graph into 0 pieces - check function arguments\")\n",
    "    \n",
    "    first_round = []\n",
    "    \n",
    "    block_size = math.floor((upper_range - lower_range)/split_count)\n",
    "    \n",
    "    active_range = block_size - 2*max_grading_step\n",
    "    print(\"active range \" + str(active_range))\n",
    "    \n",
    "    if ((active_range <= 0) and (split_count > 1)) :\n",
    "        \n",
    "        print(str((max_grading_step, lower_range, upper_range, split_count - 1)))\n",
    "        print(\"Cannot partition the graph into this many pieces! Parititioning into a smaller number of pieces\")\n",
    "        return degree_partition(max_grading_step, lower_range, upper_range, split_count - 1)\n",
    "    \n",
    "    if split_count == 1:\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    block = []\n",
    "    \n",
    "    max_grading_step += -1\n",
    "    \n",
    "    trailing_edge = lower_range - 1 - max_grading_step\n",
    "    leading_edge = trailing_edge \n",
    "\n",
    "    while trailing_edge < upper_range:\n",
    "        \n",
    "        block = []\n",
    "        block.append(leading_edge)\n",
    "        leading_edge += 1\n",
    "        block.append(leading_edge)\n",
    "        leading_edge += max_grading_step\n",
    "        block.append(leading_edge)\n",
    "        leading_edge += active_range\n",
    "        block.append(leading_edge)\n",
    "        leading_edge += max_grading_step\n",
    "        block.append(leading_edge)\n",
    "        leading_edge += 1\n",
    "        block.append(leading_edge)\n",
    "        first_round.append(block)\n",
    "        trailing_edge = leading_edge\n",
    "        \n",
    "    print(first_round)\n",
    "    return first_round\n",
    "\n",
    "#End of main code block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6, 3, 4, 1, 2, 5], [4, 5, 2, 3, 6, 1]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_dict['L4a1_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructing cinf...\n",
      "Grid size is 8\n",
      "Defining U0, U1, U2, U3, U4, U5, U6, U7, V0, V1, V2, V3, V4, V5, V6, V7\n",
      "Time to construct cinf 31.302305221557617\n",
      "grading complex...\n",
      "Time to find arborescence:17.161284923553467\n",
      "Time to grade complex (given arborescence): 14.364071130752563\n",
      "passing to parallel reducer\n",
      "entering parallel reduction\n",
      "155856reducible edges remaining\n",
      "33346reducible edges remaining\n",
      "25299reducible edges remaining\n",
      "17654reducible edges remaining\n",
      "7033reducible edges remaining\n",
      "parallel reduction complete\n",
      "Reducing complex...\n",
      "4929\n",
      "Time to reduce complex: 94.42635369300842\n",
      "completed parallel reducer function\n",
      "writing to Outputs/X83465127O45237681.gml\n",
      "writing to Outputs/NormalizedX83465127O45237681.gml\n"
     ]
    }
   ],
   "source": [
    "comp = link_GFC(*link_dict['L6a1_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(comp.comp.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructing cinf...\n",
      "Grid size is 5\n",
      "Defining U0, U1, U2, U3, U4, V0, V1, V2, V3, V4\n",
      "Time to construct cinf 0.1646435260772705\n",
      "grading complex...\n",
      "Time to find arborescence:0.022339820861816406\n",
      "Time to grade complex (given arborescence): 0.01347494125366211\n",
      "passing to parallel reducer\n",
      "entering parallel reduction\n",
      "150reducible edges remaining\n",
      "66reducible edges remaining\n",
      "40reducible edges remaining\n",
      "36reducible edges remaining\n",
      "31reducible edges remaining\n",
      "18reducible edges remaining\n",
      "15reducible edges remaining\n",
      "10reducible edges remaining\n",
      "8reducible edges remaining\n",
      "parallel reduction complete\n",
      "Reducing complex...\n",
      "1\n",
      "Time to reduce complex: 0.00863337516784668\n",
      "completed parallel reducer function\n",
      "writing to Outputs/k3_1.gml\n",
      "writing to Outputs/Normalizedk3_1.gml\n",
      "constructing cinf...\n",
      "Grid size is 5\n",
      "Defining U0, U1, U2, U3, U4, V0, V1, V2, V3, V4\n",
      "Time to construct cinf 0.033597469329833984\n",
      "grading complex...\n",
      "Time to find arborescence:0.01670098304748535\n",
      "Time to grade complex (given arborescence): 0.010434150695800781\n",
      "passing to parallel reducer\n",
      "entering parallel reduction\n",
      "150reducible edges remaining\n",
      "50reducible edges remaining\n",
      "45reducible edges remaining\n",
      "29reducible edges remaining\n",
      "27reducible edges remaining\n",
      "7reducible edges remaining\n",
      "parallel reduction complete\n",
      "Reducing complex...\n",
      "4\n",
      "Time to reduce complex: 0.015305280685424805\n",
      "completed parallel reducer function\n",
      "writing to Outputs/mk3_1.gml\n",
      "writing to Outputs/Normalizedmk3_1.gml\n",
      "constructing cinf...\n",
      "Grid size is 6\n",
      "Defining U0, U1, U2, U3, U4, U5, V0, V1, V2, V3, V4, V5\n",
      "Time to construct cinf 0.2953352928161621\n",
      "grading complex...\n",
      "Time to find arborescence:0.12497520446777344\n",
      "Time to grade complex (given arborescence): 0.07997345924377441\n",
      "passing to parallel reducer\n",
      "entering parallel reduction\n",
      "1380reducible edges remaining\n",
      "789reducible edges remaining\n",
      "191reducible edges remaining\n",
      "79reducible edges remaining\n",
      "47reducible edges remaining\n",
      "41reducible edges remaining\n",
      "35reducible edges remaining\n",
      "20reducible edges remaining\n",
      "16reducible edges remaining\n",
      "14reducible edges remaining\n",
      "13reducible edges remaining\n",
      "12reducible edges remaining\n",
      "10reducible edges remaining\n",
      "7reducible edges remaining\n",
      "parallel reduction complete\n",
      "Reducing complex...\n",
      "4\n",
      "Time to reduce complex: 0.06471395492553711\n",
      "completed parallel reducer function\n",
      "writing to Outputs/k4_1.gml\n",
      "writing to Outputs/Normalizedk4_1.gml\n",
      "constructing cinf...\n",
      "Grid size is 7\n",
      "Defining U0, U1, U2, U3, U4, U5, U6, V0, V1, V2, V3, V4, V5, V6\n",
      "Time to construct cinf 2.839833974838257\n",
      "grading complex...\n",
      "Time to find arborescence:1.7379603385925293\n",
      "Time to grade complex (given arborescence): 0.7057662010192871\n",
      "passing to parallel reducer\n",
      "entering parallel reduction\n",
      "13176reducible edges remaining\n",
      "7569reducible edges remaining\n",
      "3298reducible edges remaining\n",
      "1167reducible edges remaining\n",
      "922reducible edges remaining\n",
      "625reducible edges remaining\n",
      "563reducible edges remaining\n",
      "515reducible edges remaining\n",
      "351reducible edges remaining\n",
      "282reducible edges remaining\n",
      "120reducible edges remaining\n",
      "114reducible edges remaining\n",
      "105reducible edges remaining\n",
      "103reducible edges remaining\n",
      "101reducible edges remaining\n",
      "100reducible edges remaining\n",
      "99reducible edges remaining\n",
      "96reducible edges remaining\n",
      "83reducible edges remaining\n",
      "82reducible edges remaining\n",
      "79reducible edges remaining\n",
      "78reducible edges remaining\n",
      "76reducible edges remaining\n",
      "75reducible edges remaining\n",
      "69reducible edges remaining\n",
      "68reducible edges remaining\n",
      "66reducible edges remaining\n",
      "63reducible edges remaining\n",
      "61reducible edges remaining\n",
      "60reducible edges remaining\n",
      "57reducible edges remaining\n",
      "52reducible edges remaining\n",
      "50reducible edges remaining\n",
      "48reducible edges remaining\n",
      "46reducible edges remaining\n",
      "44reducible edges remaining\n",
      "42reducible edges remaining\n",
      "41reducible edges remaining\n",
      "40reducible edges remaining\n",
      "29reducible edges remaining\n",
      "28reducible edges remaining\n",
      "26reducible edges remaining\n",
      "25reducible edges remaining\n",
      "23reducible edges remaining\n",
      "22reducible edges remaining\n",
      "20reducible edges remaining\n",
      "19reducible edges remaining\n",
      "18reducible edges remaining\n",
      "17reducible edges remaining\n",
      "16reducible edges remaining\n",
      "15reducible edges remaining\n",
      "13reducible edges remaining\n",
      "12reducible edges remaining\n",
      "10reducible edges remaining\n",
      "8reducible edges remaining\n",
      "7reducible edges remaining\n",
      "parallel reduction complete\n",
      "Reducing complex...\n",
      "5\n",
      "Time to reduce complex: 0.3397195339202881\n",
      "completed parallel reducer function\n",
      "writing to Outputs/k5_1.gml\n",
      "writing to Outputs/Normalizedk5_1.gml\n",
      "constructing cinf...\n",
      "Grid size is 7\n",
      "Defining U0, U1, U2, U3, U4, U5, U6, V0, V1, V2, V3, V4, V5, V6\n",
      "Time to construct cinf 2.9161360263824463\n",
      "grading complex...\n",
      "Time to find arborescence:1.499556541442871\n",
      "Time to grade complex (given arborescence): 0.6712350845336914\n",
      "passing to parallel reducer\n",
      "entering parallel reduction\n",
      "16632reducible edges remaining\n",
      "12192reducible edges remaining\n",
      "4733reducible edges remaining\n",
      "2506reducible edges remaining\n",
      "2296reducible edges remaining\n",
      "2265reducible edges remaining\n",
      "2224reducible edges remaining\n",
      "1195reducible edges remaining\n",
      "1045reducible edges remaining\n",
      "179reducible edges remaining\n",
      "168reducible edges remaining\n",
      "154reducible edges remaining\n",
      "117reducible edges remaining\n",
      "90reducible edges remaining\n",
      "82reducible edges remaining\n",
      "68reducible edges remaining\n",
      "51reducible edges remaining\n",
      "46reducible edges remaining\n",
      "43reducible edges remaining\n",
      "40reducible edges remaining\n",
      "39reducible edges remaining\n",
      "37reducible edges remaining\n",
      "32reducible edges remaining\n",
      "29reducible edges remaining\n",
      "26reducible edges remaining\n",
      "24reducible edges remaining\n",
      "22reducible edges remaining\n",
      "18reducible edges remaining\n",
      "15reducible edges remaining\n",
      "10reducible edges remaining\n",
      "9reducible edges remaining\n",
      "6reducible edges remaining\n",
      "parallel reduction complete\n",
      "Reducing complex...\n",
      "5\n",
      "Time to reduce complex: 0.3079226016998291\n",
      "completed parallel reducer function\n",
      "writing to Outputs/mk5_1.gml\n",
      "writing to Outputs/Normalizedmk5_1.gml\n",
      "constructing cinf...\n",
      "Grid size is 7\n",
      "Defining U0, U1, U2, U3, U4, U5, U6, V0, V1, V2, V3, V4, V5, V6\n",
      "Time to construct cinf 2.7892818450927734\n",
      "grading complex...\n",
      "Time to find arborescence:1.5667424201965332\n",
      "Time to grade complex (given arborescence): 0.6433289051055908\n",
      "passing to parallel reducer\n",
      "entering parallel reduction\n",
      "14712reducible edges remaining\n",
      "9786reducible edges remaining\n",
      "2709reducible edges remaining\n",
      "1228reducible edges remaining\n",
      "793reducible edges remaining\n",
      "401reducible edges remaining\n",
      "45reducible edges remaining\n",
      "38reducible edges remaining\n",
      "35reducible edges remaining\n",
      "33reducible edges remaining\n",
      "26reducible edges remaining\n",
      "17reducible edges remaining\n",
      "13reducible edges remaining\n",
      "11reducible edges remaining\n",
      "10reducible edges remaining\n",
      "9reducible edges remaining\n",
      "8reducible edges remaining\n",
      "7reducible edges remaining\n",
      "parallel reduction complete\n",
      "Reducing complex...\n",
      "5\n",
      "Time to reduce complex: 0.5306494235992432\n",
      "completed parallel reducer function\n",
      "writing to Outputs/k5_2.gml\n",
      "writing to Outputs/Normalizedk5_2.gml\n",
      "constructing cinf...\n",
      "Grid size is 7\n",
      "Defining U0, U1, U2, U3, U4, U5, U6, V0, V1, V2, V3, V4, V5, V6\n",
      "Time to construct cinf 2.57932448387146\n",
      "grading complex...\n",
      "Time to find arborescence:1.4575674533843994\n",
      "Time to grade complex (given arborescence): 0.6367480754852295\n",
      "passing to parallel reducer\n",
      "entering parallel reduction\n",
      "14712reducible edges remaining\n",
      "9448reducible edges remaining\n",
      "2943reducible edges remaining\n",
      "995reducible edges remaining\n",
      "493reducible edges remaining\n",
      "395reducible edges remaining\n",
      "395reducible edges remaining\n",
      "362reducible edges remaining\n",
      "240reducible edges remaining\n",
      "205reducible edges remaining\n",
      "194reducible edges remaining\n",
      "159reducible edges remaining\n",
      "111reducible edges remaining\n",
      "104reducible edges remaining\n",
      "81reducible edges remaining\n",
      "75reducible edges remaining\n",
      "68reducible edges remaining\n",
      "66reducible edges remaining\n",
      "59reducible edges remaining\n",
      "53reducible edges remaining\n",
      "51reducible edges remaining\n",
      "49reducible edges remaining\n",
      "47reducible edges remaining\n",
      "41reducible edges remaining\n",
      "37reducible edges remaining\n",
      "30reducible edges remaining\n",
      "28reducible edges remaining\n",
      "24reducible edges remaining\n",
      "22reducible edges remaining\n",
      "20reducible edges remaining\n",
      "19reducible edges remaining\n",
      "12reducible edges remaining\n",
      "11reducible edges remaining\n",
      "10reducible edges remaining\n",
      "9reducible edges remaining\n",
      "8reducible edges remaining\n",
      "7reducible edges remaining\n",
      "6reducible edges remaining\n",
      "parallel reduction complete\n",
      "Reducing complex...\n",
      "4\n",
      "Time to reduce complex: 0.47126245498657227\n",
      "completed parallel reducer function\n",
      "writing to Outputs/mk5_2.gml\n",
      "writing to Outputs/Normalizedmk5_2.gml\n",
      "constructing cinf...\n",
      "Grid size is 8\n",
      "Defining U0, U1, U2, U3, U4, U5, U6, U7, V0, V1, V2, V3, V4, V5, V6, V7\n",
      "Time to construct cinf 28.31872057914734\n",
      "grading complex...\n",
      "Time to find arborescence:15.932749509811401\n",
      "Time to grade complex (given arborescence): 7.497631072998047\n",
      "passing to parallel reducer\n",
      "entering parallel reduction\n",
      "168672reducible edges remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1171:\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cdstclair/anaconda3/envs/sage/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/cdstclair/anaconda3/envs/sage/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_26940/2062193317.py\", line 869, in subgraph_red_search\n",
      "    subgraph.graph_reduction(ed[Integer(0)], ed[Integer(1)])\n",
      "  File \"/tmp/ipykernel_26940/2062193317.py\", line 228, in graph_reduction\n",
      "    if self.comp.has_edge(x,y):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/cdstclair/anaconda3/envs/sage/lib/python3.11/site-packages/networkx/classes/graph.py\", line 1277, in has_edge\n",
      "    def has_edge(self, u, v):\n",
      "    \n",
      "  File \"src/cysignals/signals.pyx\", line 310, in cysignals.signals.python_check_interrupt\n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <sage.repl.ipython_kernel.kernel.SageKernel object at 0x7fae9f610610>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cdstclair/anaconda3/envs/sage/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 770, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "  File \"src/cysignals/signals.pyx\", line 310, in cysignals.signals.python_check_interrupt\n",
      "KeyboardInterrupt: \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for link in knot_dict:\n",
    "    comp = link_GFC(*knot_dict[link], link)\n",
    "#     gfk.pickle_it(comp, (link + \"gfk.p\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp.gml_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_partition(2, -3, 12, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp.find_max_difference(\"AGrading1\")\n",
    "comp.max_grading_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for knot in knot_dict:\n",
    "#     comp = link_GFC(*knot_dict[knot], knot)\n",
    "#     gfk.pickle_it(comp, (knot + \"gfk.p\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = link_GFC(*knot_dict['k4_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = comp.parallel_single_split('AGrading', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp.find_max_difference('AGrading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp.max_grading_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp.find_grading_ranges('AGrading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp.max_gradings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp.min_gradings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict = {}\n",
    "mydict[\"test\"] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge in comp.comp.nodes():\n",
    "    print(comp.comp.nodes()[edge])\n",
    "    input(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "comp.comp.nodes()['[8, 2, 3, 7, 1, 5, 4, 6]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testcomp = comp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testcomp.grade_link_complex()\n",
    "input(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next((source, target, weight) for source, target, weight in comp.comp.edges(data = 'agrading0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfk.pickle_it(comp, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comp.surgery()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = link_GFC([7,2,3,4,5,6,1],[2,3,4,5,6,7,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comp.surgery()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comp.to_minus()\n",
    "comp.graph_red_search()\n",
    "comp.remove_zeros()\n",
    "comp.gml_export(\"HopefullyS3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(trefoil_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for knot specific variations - should be unnecessary\n",
    "\n",
    "def gml_export_weighted(self, filename = 'PleaseNameMe.gml'):\n",
    "\n",
    "    nxG = self.comp.copy()\n",
    "\n",
    "    if filename == 'PleaseNameMe.gml':\n",
    "        print(\"You didn't name your output! It's been named PleaseNameMe.gml\")\n",
    "\n",
    "    if filename[-4:] != \".gml\":\n",
    "        filename += \".gml\"\n",
    "\n",
    "    for x,y in nxG.edges():\n",
    "\n",
    "        nxG[x][y]['diffweight'] = str(nxG[x][y]['diffweight'])\n",
    "\n",
    "    for node in nxG.nodes():\n",
    "\n",
    "        #print(str((nxG.nodes()[node]['UGrading'],nxG.nodes()[node]['VGrading'],nxG.nodes()[node]['AGrading'])))\n",
    "\n",
    "        try:\n",
    "            nxG.nodes[node]['AGrading'] = int(nxG.nodes[node]['AGrading']) \n",
    "            nxG.nodes[node]['UGrading'] = int(nxG.nodes[node]['UGrading'])\n",
    "            nxG.nodes[node]['VGrading'] = int(nxG.nodes[node]['VGrading'])\n",
    "        except:\n",
    "            nxG.nodes[node]['AGrading'] = int(-99)\n",
    "            nxG.nodes[node]['UGrading'] = int(-99)\n",
    "            nxG.nodes[node]['VGrading'] = int(-99)\n",
    "\n",
    "    nx.write_gml(nxG, filename)\n",
    "\n",
    "    return\n",
    "\n",
    "def grade_complex(given_graph, given_field, gridX = -1):\n",
    "    \n",
    "    #Input: given_graph a networkx directed graph with 'diffweight' attribute on edges\n",
    "    #       given_field the laurent polynomial field associated to the grid graph\n",
    "    #       gridX a list representing the vertex to be graded 0 in U V and Alexander gradings\n",
    "    #\n",
    "    #Output: given_graph with new attributes on the vertices for U V and Alexander gradings\n",
    "    #        also an attribute HasBeenGraded as an artifact\n",
    "    \n",
    "    \n",
    "    #If the positions of the Xs aren't provided we'll initialize around whatever\n",
    "    #state happens to appear first in the digraph structure\n",
    "    if gridX == -1:\n",
    "        \n",
    "        gridX = list(given_graph.nodes())[0]\n",
    "    \n",
    "    gens = given_field.gens()\n",
    "    size = len(gens)/2 \n",
    "\n",
    "    print(\"grading complex...\")\n",
    "    \n",
    "    #Adding an attribute to all nodes to keep track of if they've been assigned gradings\n",
    "    nx.set_node_attributes(given_graph, False, \"HasBeenGraded\")\n",
    "    \n",
    "    #The gradings are relative so we're declaring one to be in U, V, and Alexander grading 0\n",
    "    #this block initializes those balues\n",
    "    given_graph.nodes()[str(gridX)]['HasBeenGraded'] = True\n",
    "    given_graph.nodes()[str(gridX)]['AGrading'] = 0\n",
    "    given_graph.nodes()[str(gridX)]['UGrading'] = 0\n",
    "    given_graph.nodes()[str(gridX)]['VGrading'] = 0\n",
    "    \n",
    "    if TIMERS: timerstart = time.time()\n",
    "\n",
    "    #Built in function to find a spanning tree\n",
    "    #span = nx.algorithms.tree.branchings.greedy_branching(given_graph)\n",
    "    \n",
    "    tree = nx.algorithms.minimum_spanning_tree( given_graph.to_undirected()  )\n",
    "    eds = set(tree.edges())  # Issues with functions finding directed spanning set - insteada we find an undirected one then direct it\n",
    "    spanset = []\n",
    "    \n",
    "    for edge in eds:\n",
    "        \n",
    "        if edge in given_graph.edges():\n",
    "            spanset.append(edge)\n",
    "            \n",
    "        else:\n",
    "            spanset.append((edge[1],edge[0]))\n",
    "        \n",
    "    span = given_graph.edge_subgraph(spanset)\n",
    "        \n",
    "    if TIMERS:\n",
    "        \n",
    "        timerstop = time.time()\n",
    "        print(\"Time to find arborescence:\" + str(timerstop - timerstart))\n",
    "    \n",
    "    #Bit of baseball terminology for the following nested loops, the active data is essentially at bat, the list we're working\n",
    "    #through is called on_deck, and then we're building up the follow up as in_the_hole which will turn into\n",
    "    #on deck on the following loop\n",
    "    #\n",
    "    #On deck holds the edges to be iterated through\n",
    "    on_deck = [str(gridX)]\n",
    "    \n",
    "    #In the hole holds the ones to be iterated through once on_deck is cleared\n",
    "    in_the_hole = []\n",
    "    \n",
    "    if TIMERS: timerstart = time.time()\n",
    "    \n",
    "    while len(on_deck) > 0: \n",
    "               \n",
    "        for vert in on_deck:\n",
    "\n",
    "            #Every vertex in on_deck should be graded. The loops iterate through the neighbors of each of these\n",
    "            #vertices, grading them and then adding them to in_the_hole, ignoring vertices that have already been graded.\n",
    "            #\n",
    "            #The loop is broken into two halves since we have two flavors of neighbor in a directed graph, successors and\n",
    "            #predecessors, named accordingly. These flavors differ in relative grading change by a sign.\n",
    "            for succ in span.successors(vert): \n",
    "                \n",
    "                #skip the vertex if its already been graded\n",
    "                if given_graph.nodes()[succ]['HasBeenGraded']: continue\n",
    "                    \n",
    "                in_the_hole.append(succ)\n",
    "                \n",
    "                ed_weight = given_graph[vert][succ]['diffweight']\n",
    "                \n",
    "                #set the maslov (homological) gradings\n",
    "                Upows = U_deg(ed_weight, given_field)\n",
    "                given_graph.nodes()[succ]['UGrading'] = given_graph.nodes()[vert]['UGrading'] - 1 + 2*Upows\n",
    "\n",
    "                Vpows = V_deg(ed_weight, given_field)\n",
    "                given_graph.nodes()[succ]['VGrading'] = given_graph.nodes()[vert]['VGrading'] - 1 + 2*Vpows\n",
    "\n",
    "                #Alexander grading is a function of the U and V grading, set here\n",
    "                given_graph.nodes()[succ]['AGrading'] = (1/2)*(given_graph.nodes()[succ]['UGrading']-given_graph.nodes()[succ]['VGrading'])\n",
    "\n",
    "                given_graph.nodes()[succ]['HasBeenGraded'] = True\n",
    "\n",
    "            for pred in span.predecessors(vert):\n",
    "                \n",
    "                if given_graph.nodes()[pred]['HasBeenGraded']: continue\n",
    "                in_the_hole.append(pred)\n",
    "                ed_weight = given_graph[pred][vert]['diffweight']\n",
    "                \n",
    "                #set the maslov (homological) gradings, note the negative grading change since we're following an arrow backwards.\n",
    "                Upows = U_deg(ed_weight, given_field)\n",
    "                given_graph.nodes()[pred]['UGrading'] = given_graph.nodes()[vert]['UGrading'] + 1 - 2*Upows       \n",
    "\n",
    "                Vpows = V_deg(ed_weight, given_field)\n",
    "                given_graph.nodes()[pred]['VGrading'] = given_graph.nodes()[vert]['VGrading'] + 1 - 2*Vpows\n",
    "\n",
    "                given_graph.nodes()[pred]['AGrading'] = (1/2)*(given_graph.nodes()[pred]['UGrading']-given_graph.nodes()[pred]['VGrading'])\n",
    "                given_graph.nodes()[pred]['HasBeenGraded'] = True\n",
    "                \n",
    "        on_deck = in_the_hole\n",
    "        in_the_hole =[]\n",
    "        \n",
    "    if TIMERS:\n",
    "        \n",
    "        timerstop = time.time()\n",
    "        print('Time to grade complex (given arborescence): ' + str(timerstop - timerstart))\n",
    "    \n",
    "    return given_graph\n",
    "            \n",
    "\n",
    "    \n",
    "def U_deg(poly, field):\n",
    "    \n",
    "    #Input: poly a laurent polynomial (must be  a monomial) in field a laurent polynomial ring\n",
    "    #\n",
    "    #Output: The total sum of powers of Ui in poly\n",
    "    \n",
    "    gens = field.gens()\n",
    "    size = len(gens)/2\n",
    "    degree = 0\n",
    "    \n",
    "    if type(poly) == sage.rings.finite_rings.integer_mod.IntegerMod_int: return 0\n",
    "    \n",
    "    powers = poly.exponents()   \n",
    "    \n",
    "    #len(powers) tells you how many terms the polynomial has\n",
    "#     if len(powers) > 1:\n",
    "        \n",
    "#         print(poly)\n",
    "        \n",
    "#         raise Exception(\"Ran into a non-homogoneous degree change - polynomial wasn't a monomial\")\n",
    "\n",
    "    if len(powers) == 0:\n",
    "        \n",
    "        return 0    \n",
    "    \n",
    "    #powers is a list of lists since its intended for more than just monomials, since we are guaranteeing\n",
    "    #a monomial at this point we'll just lift that inner list out\n",
    "    powers = powers[0]\n",
    "    \n",
    "    for i in range(size):\n",
    "        \n",
    "        degree = degree + powers[i]\n",
    "    \n",
    "    return degree\n",
    "\n",
    "    \n",
    "def V_deg(poly, field):\n",
    "    \n",
    "    #Input: poly a laurent polynomial (must be  a monomial) in field a laurent polynomial ring\n",
    "    #\n",
    "    #Output: The total sum of powers of Ui in poly    \n",
    "    \n",
    "    gens = field.gens()\n",
    "    size = len(gens)/2\n",
    "    degree = 0\n",
    "    \n",
    "    if type(poly) == sage.rings.finite_rings.integer_mod.IntegerMod_int: return 0\n",
    "    \n",
    "    powers = poly.exponents()   \n",
    "    \n",
    "    #len(powers) tells you how many terms the polynomial has    \n",
    "#     if len(powers) > 1:\n",
    "        \n",
    "#         print(poly)\n",
    "#         raise Exception(\"Ran into a non-homogoneous degree change - polynomial wasn't a monomial\")\n",
    "\n",
    "    if len(powers) == 0:\n",
    "        \n",
    "        return 0    \n",
    "    \n",
    "    #powers is a list of lists since its intended for more than just monomials, since we are guaranteeing\n",
    "    #a monomial at this point we'll just lift that inner list out    \n",
    "    powers = powers[0]\n",
    "    for i in range(size):\n",
    "        \n",
    "        degree = degree + powers[size + i]\n",
    "    \n",
    "    return degree    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GFC(sigx, sigo, filename = None):\n",
    "    \n",
    "    if filename == None:\n",
    "        filename = \"X\"\n",
    "        for pos in sigx:\n",
    "            filename = filename + str(pos)\n",
    "        filename = filename + \"O\"\n",
    "        for pos in sigo:\n",
    "            filename = filename + str(pos)\n",
    "        filename = filename + \".gml\"\n",
    "    \n",
    "    components = link_components(sigx, sigo)\n",
    "    link_count = len(components)\n",
    "    if link_count != 1: raise Exception(\"!!!More than one component in this diagram - call the link version of ths function HFL!!!\")\n",
    "    raw_complex = gfk.build_cinf([sigx, sigo])\n",
    "    comp, defield = construct_cinf(raw_complex)\n",
    "    \n",
    "    grade_complex(comp, defield, sigo)\n",
    "    \n",
    "    graph_red_search(comp)\n",
    "    \n",
    "    gml_export_weighted(comp, filename)\n",
    "    \n",
    "    normalize(comp, defield)\n",
    "    graph_red_search(comp)\n",
    "    remove_zeros(comp)\n",
    "    \n",
    "    norm_filename = \"Normalized\" + filename\n",
    "    \n",
    "    gml_export_weighted(comp, norm_filename)\n",
    "    \n",
    "    minusinator = comp.copy()\n",
    "    \n",
    "    to_minus(minusinator, defield)\n",
    "    \n",
    "    graph_red_search(minusinator)\n",
    "    remove_zeros(minusinator)\n",
    "    minus_filename = \"Minus\" + filename\n",
    "    \n",
    "    gml_export_weighted(minusinator, minus_filename)\n",
    "    \n",
    "    return grid_complex(comp, defield)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Braid code - not necessary at present - will be nice later\n",
    "\n",
    "#converting braid notation to a grid --- this is not a unique choice in general so we're going to make some decisions\n",
    "\n",
    "class braid:\n",
    "    \n",
    "    def __init__(self, recipe, size = 0):\n",
    "        if size == 0:\n",
    "            candidate1 = max(recipe)\n",
    "            candidate2 = abs(min(recipe))\n",
    "            size = max([candidate1,candidate2])+1\n",
    "        self.strands = []\n",
    "        for i in range(1, size+1):\n",
    "            self.strands.append(i)\n",
    "        self.recipe = recipe\n",
    "        self.size = size    \n",
    "        \n",
    "def braid_to_cromwell(given):\n",
    "    n = given.size\n",
    "    closing_heights = []\n",
    "    for i in range(n):\n",
    "        closing_heights.append(i+1)\n",
    "    cromwell = [] #We're going to keep track of corners of the knot as a cromwell matrix (0's and 1's) and track the ones here by marking the two heights\n",
    "                  #for example [[3,1],[2,3],[1,2]] contains the information for a 3x3. The Cromwell matrix won't see the sub-ordering\n",
    "    strands = given.strands.copy()\n",
    "    for sig in given.recipe:\n",
    "        new_entry = crom_twist(sig, strands, cromwell, closing_heights)\n",
    "        cromwell.append(new_entry)\n",
    "    for i in range(len(strands)):\n",
    "        if strands[i] != closing_heights[i]:\n",
    "            cromwell.append([closing_heights[i],strands[i]])\n",
    "    return cromwell\n",
    "\n",
    "def crom_twist(bmove, strings, current_crom, closing_ht):\n",
    "    coord = []\n",
    "    n = len(strings)\n",
    "    if bmove > 0:\n",
    "        lower = strings[bmove-1]\n",
    "        upper = strings[bmove]\n",
    "        for i in range(len(current_crom)):     #move previous cromwell stuff up to make room as below\n",
    "            crom_twist_helper_pos(current_crom[i], lower, upper)\n",
    "        for i in range(bmove+1, n):            #move the strands up to make room for rectilinear braid move\n",
    "            strings[i] += 1\n",
    "        for i in range(len(closing_ht)):\n",
    "            if closing_ht[i] > upper:\n",
    "                closing_ht[i] += 1\n",
    "        cm1 = [strings[bmove-1],strings[bmove]+1] #\\/\\/\\/this is where the braid move actually \"happens\" \\/\\/\\/\n",
    "        strings[bmove-1] = strings[bmove]\n",
    "        strings[bmove] = strings[bmove] + 1\n",
    "    elif bmove < 0:\n",
    "        bmove = (-1)*bmove\n",
    "        lower = strings[bmove-1]\n",
    "        upper = strings[bmove]\n",
    "        for i in range(len(current_crom)):     #move previous cromwell stuff up to make room as below\n",
    "            crom_twist_helper_neg(current_crom[i], lower, upper)\n",
    "        for i in range(bmove-1, n):            #move the strands up to make room for rectilinear braid move\n",
    "            strings[i] += 1\n",
    "        for i in range(len(closing_ht)):\n",
    "            if closing_ht[i] >= lower:\n",
    "                closing_ht[i] += 1\n",
    "        cm1 = [strings[bmove],strings[bmove-1]-1] #\\/\\/\\/this is where the braid move actually \"happens\" \\/\\/\\/\n",
    "        strings[bmove] = strings[bmove - 1]\n",
    "        strings[bmove-1] = strings[bmove - 1] - 1\n",
    "    else:\n",
    "        print(\"invalid braid move\")\n",
    "    return cm1\n",
    "\n",
    "def crom_twist_helper_neg(crom_pair, lower, upper):\n",
    "    for i in range(2):\n",
    "        if crom_pair[i] >= lower:\n",
    "            crom_pair[i] += 1\n",
    "    return\n",
    "\n",
    "def crom_twist_helper_pos(crom_pair, lower, upper):\n",
    "    for i in range(2):\n",
    "        if crom_pair[i] > upper:\n",
    "            crom_pair[i] += 1\n",
    "    return\n",
    "\n",
    "def cromwell_to_grid(cromwell_pairs):\n",
    "    n = len(cromwell_pairs)\n",
    "    xhold = []\n",
    "    ohold = []\n",
    "    for i in range(n):\n",
    "        xhold.append(0)\n",
    "        ohold.append(0)\n",
    "#     print(cromwell_pairs)\n",
    "    xhold[0] = cromwell_pairs[0][0]\n",
    "    ohold[0] = cromwell_pairs[0][1]\n",
    "    count = 2\n",
    "    cromwell_pairs[0] = [-1,-1]\n",
    "    while count < 2*n:\n",
    "        for i in range(n):\n",
    "            for j in range(2):\n",
    "                if ((cromwell_pairs[i][j] in xhold)and (not(cromwell_pairs[i][j] in ohold))):\n",
    "                    ohold[i] = cromwell_pairs[i][j]\n",
    "                    xhold[i] = cromwell_pairs[i][j-1]\n",
    "                    cromwell_pairs[i] = [-1,-1]\n",
    "                    count += 2\n",
    "                elif ((cromwell_pairs[i][j] in ohold)and (not(cromwell_pairs[i][j] in xhold))):\n",
    "                    xhold[i] = cromwell_pairs[i][j]\n",
    "                    ohold[i] = cromwell_pairs[i][j-1]\n",
    "                    cromwell_pairs[i] = [-1,-1]\n",
    "                    count += 2\n",
    "    return (xhold,ohold)\n",
    "\n",
    "def grid_from_braid(bnotation):\n",
    "    \n",
    "    br = braid(bnotation)\n",
    "    crom = braid_to_cromwell(br)\n",
    "    xlist, olist = cromwell_to_grid(crom)\n",
    "    return xlist, olist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLD CODE\n",
    "\n",
    "# file = open(\"TrefoilComplex.csv\")\n",
    "# csvreader = csv.reader(file)\n",
    "# header = []\n",
    "# header = next(csvreader)\n",
    "\n",
    "# rows = []\n",
    "\n",
    "# for row in csvreader:\n",
    "#     rows.append(row)\n",
    "#     print(row)\n",
    "\n",
    "\n",
    "# file.close()\n",
    "\n",
    "# def comp_from_pickle(filename = 'DefaultPickleComp', grade = True):\n",
    "    \n",
    "# # GFK toolkit has the ability to export its raw complex as a pickle file, this imports those files, then constructs cinf. \n",
    "# # Largely unnecessary if calling from the imported GFK directly\n",
    "\n",
    "#     graph, size, knot = imp_from_pickle(filename)\n",
    "#     print(\"Grid complex imported with grid number = \" + str(size))\n",
    "#     nxg, defield = construct_cinf(graph, size)\n",
    "#     if grade:\n",
    "#         print('proceeding to grade complex.')\n",
    "#         nxg = grade_complex(nxg, defield)\n",
    "    \n",
    "#     return nxg, defield\n",
    "\n",
    "# def imp_from_pickle(filename = 'DefaultPickleComp'):\n",
    "    \n",
    "# # Imports pickle file and returns the object. Will import from DefaultPickleComp if no name is provided\n",
    "    \n",
    "#     if filename == 'DefaultPickleComp':\n",
    "#         print('No name provided for import - importing from DefaultPickleComp')\n",
    "    \n",
    "    \n",
    "#     try:\n",
    "#         file = open(filename,'rb')\n",
    "#         print(\"file opened\")\n",
    "#     except:\n",
    "#         print('Ran into an error: Make sure you\\'ve exported to the file you\\'re trying to import from')\n",
    "#     stuff = pickle.load(file)\n",
    "#     file.close()\n",
    "#     print('file closed')\n",
    "#     return stuff\n",
    "\n",
    "# def reduce_around(M, position): \n",
    "# #M isa matrix and position is a pair [a,b] where a 1 is located\n",
    "# #function does Gauss-Jordan-ish elimination on that column and in a symmetric way to the entry's row\n",
    "#     a,b = position\n",
    "#     #First step is to use the row to cancel the other entries, then we'll do a symmetric cancellation on\n",
    "#     #the columns as well\n",
    "#     column = M[:][b]\n",
    "#     for index, entry in enumerate(column):\n",
    "#         if ((index != 0) and (index != a) and (entry != 0)):\n",
    "#             M.add_multiple_of_row(index, entry, a)\n",
    "#     for index, entry in enumerate(column):\n",
    "#         if ((index != 0) and (index != a) and (entry != 0)):\n",
    "#             M.add_multiple_of_col(index, entry, b)\n",
    "#     #Now we'll repeat the process but with the row entries\n",
    "#     row = M[a][:]\n",
    "#     for index, entry in enumerate(row):\n",
    "#         if ((index != 0) and (index != b) and (entry != 0)):\n",
    "#             M.add_multiple_of_col(index, entry, b)\n",
    "#     for index, entry in enumerate(column):\n",
    "#         if ((index != 0) and (index != b) and (entry != 0)):\n",
    "#             M.add_multiple_of_row(index, entry, a)\n",
    "#     return\n",
    "\n",
    "# def hom_reduction(adj_mat):\n",
    "#     M = adj_mat\n",
    "#     row_position = 0\n",
    "#     for row in M:\n",
    "#         check, column_position = row_count(row)\n",
    "#         if row_count(check[0]) > 1:\n",
    "#             reduce_around(M, row_position, column_position)\n",
    "#         row_position = position + 1\n",
    "\n",
    "\n",
    "\n",
    "# def cinf_coeff(size):\n",
    "#     n = size\n",
    "#     varis = name_some_vars(['U','V'],n)\n",
    "#     F = LaurentPolynomialRing(GF(2), varis)\n",
    "#     F.inject_variables()\n",
    "# #     preF = LaurentPolynomialRing(GF(2), 'U', n) #F[Ui+-] which we'll then pair up with the Vi\n",
    "# #     preF.inject_variables()                     #Telling Sage we have Ui's as variables\n",
    "# #     Vars = preF.gens()                          #storing the variables in a list - not currently implemented anywhere\n",
    "# #     for vari in preF.gens():\n",
    "# #         preF.<vari> = preF\n",
    "# #     F = LaurentPolynomialRing(preF, 'V', n)     #Takes our preF (F[Ui+-]) and adjoins Vi\n",
    "# #     F.inject_variables()                        #F only thinks it has Vi as variables, we tell Sage about it\n",
    "# #     Vars = Vars + F.gens()\n",
    "# #     for vari in F.gens():\n",
    "# #        F.<vari> = F\n",
    "# #     for vari in Vars: \n",
    "# #         F.<vari> = F    \n",
    "#     return F,list(F.gens())\n",
    "\n",
    "# def find_one(targetlist): #Searches a list for first 1 - will be used for reduction\n",
    "# #     print(\"searching for 1 in\" + str(targetlist))\n",
    "#     if 1 in list(targetlist):\n",
    "        \n",
    "# #         print(\"found 1 in the list at\" + str(list(targetlist).index(1)))\n",
    "#         return list(targetlist).index(1)\n",
    "\n",
    "#     return -1\n",
    "\n",
    "# def find_col_with_one(matrix, startc=0):\n",
    "    \n",
    "#     endc = len(matrix[0])\n",
    "#     print(str(endc))\n",
    "#     for n in range(startc, endc):\n",
    "        \n",
    "#         search_result = find_one(matrix[:][n])\n",
    "#         if search_result != -1: return (search_result, n)\n",
    "        \n",
    "#     return (-1, -1)\n",
    "\n",
    "\n",
    "# def reduction_remap(matrix, row, col):\n",
    "#     n = len(matrix[0])\n",
    "#     range1 = range_skip_entry(n, row)\n",
    "# #     print(\"searching through \" + str(range1))\n",
    "#     for count, target_row in enumerate(range1):\n",
    "        \n",
    "#         entry = matrix[target_row][col]\n",
    "#         if entry != 0: my_row_add(matrix, row, target_row, entry)\n",
    "            \n",
    "#     return matrix\n",
    "\n",
    "# def row_col_del(matrix, loc):\n",
    "#     newrange = list(range(len(matrix[0])))\n",
    "#     del newrange[loc]\n",
    "#     return matrix[newrange,newrange]\n",
    "\n",
    "# def construct_sageG_cinf(g, size = -1): #Construct CFKinf complex from graph data - essentially just changing weights to polynomials\n",
    "#                                   #Only works for grid diagrams *not* Latin Squares\n",
    "#     #DEPRECATED None of the current pipelines are using sage graphs\n",
    "#     if size == -1:\n",
    "#         size = len(g.get_edge_data(list(g.edges())[0][0],list(g.edges())[0][1])['diffweight'])  #kind of a mess - just turning the edges\n",
    "#     n = size/2                                                                              #into a list and checking the length of\n",
    "#                                                                                             #the weight of the first edge\n",
    "#     F,Vars = cinf_coeff(n)\n",
    "#     resG = DiGraph()\n",
    "#     for edge in g.edges:\n",
    "        \n",
    "#         start = edge[0]\n",
    "#         end = edge[1]\n",
    "#         poly = F(1)\n",
    "#         i = 0\n",
    "#         for entry in g[edge[0]][edge[1]]['diffweight']:\n",
    "            \n",
    "#             poly = poly*(Vars[i])**entry\n",
    "#             i = i + 1\n",
    "            \n",
    "#         resG.add_edge(start, end, poly)\n",
    "        \n",
    "#     return resG\n",
    "\n",
    "# def convert_gml(fileName): #GridToolsTBD exports to a text file - this grabs it and converts the edges back to lists\n",
    "#                            #super inneficient - should convert to pickle file system or something\n",
    "#     g = nx.read_gml(fileName)\n",
    "#     for edge in g.edges:\n",
    "#         g[edge[0]][edge[1]]['diffweight'] = ast.literal_eval(g[edge[0]][edge[1]]['weight'])\n",
    "#         g[edge[0]][edge[1]]['diffweight'] = g[edge[0]][edge[1]]['diffweight'][0]+g[edge[0]][edge[1]]['diffweight'][1] #end result is edge weights as list of\n",
    "#                                                                                                           #multiplicities [U1,U2...,Un,V1,...,Vn]\n",
    "#     return g\n",
    "\n",
    "# def imp_and_construct_complex(filename):\n",
    "    \n",
    "#     #Input: Filename string for a file\n",
    "    \n",
    "#     print('importing complex...')\n",
    "#     g = convert_gml(filename)\n",
    "#     return construct_cinf(g)\n",
    "\n",
    "# def reduction(matrix):\n",
    "#     col, row = find_col_with_one(matrix)\n",
    "# #     print(\"reducing around entry \" +str(row) + \",\" +str(col))\n",
    "#     if col == -1:\n",
    "        \n",
    "#         print(\"completed reduction\")\n",
    "#         print(matrix)\n",
    "#         print (type(matrix))\n",
    "#         return matrix\n",
    "    \n",
    "#     print(\"reduction in progress\")\n",
    "#     remapped_matrix = reduction_remap(matrix, row, col)\n",
    "#     if row < col:\n",
    "        \n",
    "#         remapped_matrix = row_col_del(remapped_matrix, col)\n",
    "#         remapped_matrix = row_col_del(remapped_matrix, row)\n",
    "        \n",
    "#     else:\n",
    "        \n",
    "#         remapped_matrix = row_col_del(remapped_matrix, row)\n",
    "#         remapped_matrix = row_col_del(remapped_matrix, col)\n",
    "        \n",
    "#     return reduction(remapped_matrix)\n",
    "    \n",
    "# def my_row_add(matrix, row, targetrow, multiple):\n",
    "#     n = len(matrix[0])\n",
    "#     for i in range(n):\n",
    "#         current_src = matrix[row][i]\n",
    "#         if current_src != 0:\n",
    "# #             print(\"adding copies times \" + str(current_src))\n",
    "# #             print(\"multiple\" + str(multiple))\n",
    "# #             print(\"target entry \" + str(matrix[targetrow][i]))\n",
    "#             matrix[targetrow,i] = matrix[targetrow][i] + multiple*current_src\n",
    "# #         print(matrix)\n",
    "#     return matrix\n",
    "\n",
    "\n",
    "# def alex_power_change(poly, field):\n",
    "    \n",
    "#     gens = field.gens()\n",
    "#     size = len(gens)/2\n",
    "#     grade = 0\n",
    "#     powers = poly.exponents()\n",
    "#     if len(powers) > 1:\n",
    "        \n",
    "#         raise Exception(\"Ran into a non-homogoneous degree change - polynomial wasn't a monomial\")\n",
    "\n",
    "#     if len(powers) == 0:\n",
    "        \n",
    "#         return 0\n",
    "        \n",
    "#     powers = powers[0]\n",
    "#     for i in range(size):\n",
    "        \n",
    "#         grade = grade - powers[i] + powers[i+size]\n",
    "        \n",
    "#     return grade\n",
    "\n",
    "# def mod_out_uv(chain_comp, field):\n",
    "#     gens = field.gens()\n",
    "#     size = len(gens)/2    \n",
    "#     for edge in chain_comp.edges():\n",
    "    \n",
    "#         for i in range(size):\n",
    "            \n",
    "#             src = edge[0]\n",
    "#             tar = edge[1]\n",
    "# #             print(gens[0])\n",
    "# #             print(gens[size])\n",
    "# #             print(chain_comp[src][tar]['diffweight'])\n",
    "#             chain_comp[src][tar]['diffweight'] = chain_comp[src][tar]['diffweight'].subs({gens[i]:gens[0]})\n",
    "#             chain_comp[src][tar]['diffweight'] = chain_comp[src][tar]['diffweight'].subs({gens[size+i]:gens[size]})\n",
    "#         print(chain_comp[src][tar]['diffweight'])\n",
    "\n",
    "            \n",
    "#     return 1\n",
    "\n",
    "# def U_to_zero(chain_comp, field):\n",
    "# #Substitutes 0 for all the Ui\n",
    "    \n",
    "#     print(\"normalizing Vi's to i = 0 and Ui = 0\")\n",
    "#     gens = field.gens()\n",
    "#     size = len(gens)/2    \n",
    "#     for edge in chain_comp.edges():\n",
    "    \n",
    "#         for i in range(size):\n",
    "            \n",
    "#             src = edge[0]\n",
    "#             tar = edge[1]\n",
    "#             chain_comp[src][tar]['diffweight'] = chain_comp[src][tar]['diffweight'].subs({gens[i]:0})\n",
    "#             chain_comp[src][tar]['diffweight'] = chain_comp[src][tar]['diffweight'].subs({gens[i+size]:gens[size]})\n",
    "            \n",
    "#     remove_zeros(chain_comp)\n",
    "#     return 1\n",
    "\n",
    "# def remove_loops(givengraph, overwrite = True):\n",
    "    \n",
    "#     if overwrite:\n",
    "#         graph = givengraph\n",
    "#     else:\n",
    "#         graph = givengraph.copy()\n",
    "    \n",
    "#     for ed in list(graph.edges()):\n",
    "#         try:\n",
    "#             out = graph.edges()(ed[0],ed[1])\n",
    "#             back = graph.edges()[ed[1],ed[0]]\n",
    "#             graph.remove_edge(ed[0],ed[1])\n",
    "#             graph.remove_edge(ed[1],ed[0])\n",
    "#         except KeyError:\n",
    "#             continue\n",
    "            \n",
    "#     return graph\n",
    "\n",
    "# def remove_NU_loops(givengraph, overwrite = True):\n",
    "    \n",
    "#     if overwrite:\n",
    "#         graph = givengraph\n",
    "#     else:\n",
    "#         graph = givengraph.copy()\n",
    "    \n",
    "#     for ed in list(graph.edges()):\n",
    "#         try:\n",
    "#             out = graph.edges()(ed[0],ed[1])\n",
    "#             back = graph.edges()[ed[1],ed[0]]\n",
    "#             if graph[ed[0]][ed[1]]['diffweight'] == 1:\n",
    "#                 continue\n",
    "#             if graph[ed[1]][ed[0]]['diffweight'] == 1:\n",
    "#                 continue\n",
    "#             graph.remove_edge(ed[0],ed[1])\n",
    "#             graph.remove_edge(ed[1],ed[0])\n",
    "#         except KeyError:\n",
    "#             continue\n",
    "            \n",
    "#     return graph\n",
    "\n",
    "# def mod_out_nonVar0(chain_comp, field):\n",
    "\n",
    "# #     print(\"setting Ui's and Vi's = 0\")\n",
    "#     gens = field.gens()\n",
    "#     size = len(gens)/2    \n",
    "#     for edge in chain_comp.edges():\n",
    "    \n",
    "#         for i in range(1,size):\n",
    "            \n",
    "#             src = edge[0]\n",
    "#             tar = edge[1]\n",
    "#             chain_comp[src][tar]['diffweight'] = chain_comp[src][tar]['diffweight'].subs({gens[i]:0})\n",
    "\n",
    "#         for i in range(size+1,2*size):\n",
    "\n",
    "#             src = edge[0]\n",
    "#             tar = edge[1]\n",
    "#             chain_comp[src][tar]['diffweight'] = chain_comp[src][tar]['diffweight'].subs({gens[i]:0})\n",
    "\n",
    "#     return 1\n",
    "\n",
    "\n",
    "# iterate through dictionary keys(dict)\n",
    "#     tracker = -1\n",
    "#     for target in keydic\n",
    "#         if target weight == 1\n",
    "#             graph reduction alg\n",
    "#             tracker = 1\n",
    "#     if tracker == 1\n",
    "#         return rerun\n",
    "#     else\n",
    "#         return\n",
    "        \n",
    "# graph reduction(dict, key, target)\n",
    "#     for x in predecessors(target)\n",
    "#         if x == key: continue\n",
    "#         for y in successors(key)\n",
    "#             if y == target: continue\n",
    "#             x_weight = thegraph[x][targ]['weight']\n",
    "#             y_weight = thegraph[key][y]['weight']\n",
    "#             W = x_weight x y_weight\n",
    "#             add edge to graph from x to y weight = W\n",
    "#     delete key\n",
    "#     delete target\n",
    "#     return graph\n",
    "\n",
    "    \n",
    "    \n",
    "#     def surgery_helper(self, grading_levels, target_levels):\n",
    "# #REWRITE IN PROGRESS - CURRENTLY 90% OF ORIGINAL KNOT VERSION. UPDATING TO LINK AND SELF REFERENCE VERSION.\n",
    "#         #Input: grading_levels ex: [2,3,1,1] would be asking for the subcomplex of GFC with A0 <= 2, A1 <=3 etc.\n",
    "\n",
    "#         if len(grading_levels) != len(self.components)\n",
    "#             raise(\"!!Cannot compute surgered complex without grading cutoff information for each Alexander multigrading!!\")\n",
    "#         working_comp = self.comp.copy()\n",
    "\n",
    "#         surgery_collection = []\n",
    "\n",
    "#         if ((min_grading == None) or (max_grading == None)):\n",
    "\n",
    "#             min_grading, max_grading = grading_range(chain_comp)\n",
    "\n",
    "#         for grading in range(max_grading+1,min_grading-1, -1): #Theres room to improve here - likely don't need +-2 buffer\n",
    "\n",
    "#             surgery_collection.append([f\"surgery{grading}\",working_comp.copy()])\n",
    "#             comp_truncate(!!!!!)\n",
    "\n",
    "#         for name, comp in surgery_collection:\n",
    "\n",
    "#             to_minus(comp, !!!!!)\n",
    "#             remove_zeros(comp)\n",
    "#             graph_red_search(comp)\n",
    "\n",
    "#         return surgery_collection \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     comp.find_max_difference(\"AGrading\")\n",
    "    \n",
    "    \n",
    "#     for key in comp.max_grading_changes.keys():\n",
    "        \n",
    "#         comp.find_max_difference(key)\n",
    "    \n",
    "#     split_key = \"AGrading\"\n",
    "    \n",
    "#     for key in comp.max_grading_changes.keys():\n",
    "        \n",
    "#         if comp.max_grading_changes[key] < comp.max_grading_changes[split_key]:\n",
    "            \n",
    "#             split_key = key\n",
    "#     print(comp.max_grading_changes)\n",
    "#     print(\"splitting along \" + split_key + \" with max step = \" + str(comp.max_grading_changes[split_key]))\n",
    "# #     comp.graph_red_search()\n",
    "\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "SageMath 10.2",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
